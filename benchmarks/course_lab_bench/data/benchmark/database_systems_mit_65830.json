[
    {
        "instance_id": 1,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 1: GoDB",
        "part_name": "2.3. Fields and Tuples",
        "exercise": "Exercise 1",
        "introduction": "## 2. GoDB Architecture and Implementation Guide\n\nGoDB consists of:\n\n* Structures that represent fields, tuples, and tuple schemas;\n* Methods that apply predicates and conditions to tuples;\n* One or more access methods (e.g., heap files) that store relations on disk and\n  provide a way to iterate through tuples of those relations;\n* A collection of operator classes (e.g., select, join, insert, delete, etc.)\n  that process tuples;\n* A buffer pool that caches active tuples and pages in memory and handles\n  concurrency control and transactions (neither of which you need to worry about\n  for this lab); and,\n* A catalog that stores information about available tables and their schemas.\n\nGoDB does not include many things that you may think of as being a part of a\n\"database system.\" In particular, GoDB does not have:\n\n* (In this lab), a SQL front end or parser that allows you to type queries\n  directly into GoDB. Instead, queries are built up by chaining a set of\n  operators together into a hand-built query plan (see [Section\n  2.6](#query_walkthrough)). We will provide a simple parser for use in later\n  labs.\n* Views.\n* Data types except integers and fixed length strings.\n* (In this lab) Query optimizer.\n* (In this lab) Indices.\n\nIn the rest of this Section, we describe each of the main components of GoDB\nthat you will need to implement in this lab. You should use the exercises in\nthis discussion to guide your implementation. This document is by no means a\ncomplete specification for GoDB; you will need to make decisions about how\nto design and implement various parts of the system. Note that for Lab 1 you do\nnot need to implement any operators (e.g., select, join, project) except\nsequential scan as a part of the `heap_file.go` file.\nYou will add support for additional operators in future labs.",
        "Description": "### 2.3. Fields and Tuples\n\nThe `Tuple` struct in GoDB is used to store the in-memory value of a database tuple.  \nThey consist of a collection of fields implementing the `DBValue`\ninterface.  Different\ndata types (e.g., `IntField`, `StringField`) implement `DBValue`.  `Tuple` objects are created by\nthe underlying access methods (e.g., heap files, or B-trees), as described in\nthe next section.  Tuples also have a type (or schema), called a _tuple\ndescriptor_, represented by a `TupleDesc` struct, which consists of a\ncollection of `FieldType` objects, one per field in the tuple, each of which\ndescribes the type of the corresponding field.\n\n\n\n### Exercise 1\n\n**Implement the skeleton methods in:**\n\n---\n* tuple.go\n---\n\nAt this point, your code should pass the unit tests in `tuple_test.go`.",
        "repo/location": "go get main\ncd godb\ngo get ../godb\ngo test",
        "dependency": [],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab1.md",
        "codes": [
            {
                "code_path": "godb/tuple.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/tuple.go",
                "code_content": "package godb\n\n//This file defines methods for working with tuples, including defining\n// the types DBType, FieldType, TupleDesc, DBValue, and Tuple\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"strings\"\n\n)\n\n// DBType is the type of a tuple field, in GoDB, e.g., IntType or StringType\ntype DBType int\n\nconst (\n\tIntType     DBType = iota\n\tStringType  DBType = iota\n\tUnknownType DBType = iota //used internally, during parsing, because sometimes the type is unknown\n)\n\nfunc (t DBType) String() string {\n\tswitch t {\n\tcase IntType:\n\t\treturn \"int\"\n\tcase StringType:\n\t\treturn \"string\"\n\t}\n\treturn \"unknown\"\n}\n\n// FieldType is the type of a field in a tuple, e.g., its name, table, and [godb.DBType].\n// TableQualifier may or may not be an empty string, depending on whether the table\n// was specified in the query\ntype FieldType struct {\n\tFname          string\n\tTableQualifier string\n\tFtype          DBType\n}\n\n// TupleDesc is \"type\" of the tuple, e.g., the field names and types\ntype TupleDesc struct {\n\tFields []FieldType\n}\n\n// Compare two tuple descs, and return true iff\n// all of their field objects are equal and they\n// are the same length\nfunc (d1 *TupleDesc) equals(d2 *TupleDesc) bool {\n\t// TODO: some code goes here\n\treturn true\n\n}\n\n// Given a FieldType f and a TupleDesc desc, find the best\n// matching field in desc for f.  A match is defined as\n// having the same Ftype and the same name, preferring a match\n// with the same TableQualifier if f has a TableQualifier\n// We have provided this implementation because it's details are\n// idiosyncratic to the behavior of the parser, which we are not\n// asking you to write\nfunc findFieldInTd(field FieldType, desc *TupleDesc) (int, error) {\n\tbest := -1\n\tfor i, f := range desc.Fields {\n\t\tif f.Fname == field.Fname && (f.Ftype == field.Ftype || field.Ftype == UnknownType) {\n\t\t\tif field.TableQualifier == \"\" && best != -1 {\n\t\t\t\treturn 0, GoDBError{AmbiguousNameError, fmt.Sprintf(\"select name %s is ambiguous\", f.Fname)}\n\t\t\t}\n\t\t\tif f.TableQualifier == field.TableQualifier || best == -1 {\n\t\t\t\tbest = i\n\t\t\t}\n\t\t}\n\t}\n\tif best != -1 {\n\t\treturn best, nil\n\t}\n\treturn -1, GoDBError{IncompatibleTypesError, fmt.Sprintf(\"field %s.%s not found\", field.TableQualifier, field.Fname)}\n\n}\n\n// Make a copy of a tuple desc.  Note that in go, assignment of a slice to\n// another slice object does not make a copy of the contents of the slice.\n// Look at the built-in function \"copy\".\nfunc (td *TupleDesc) copy() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} //replace me\n}\n\n// Assign the TableQualifier of every field in the TupleDesc to be the\n// supplied alias.  We have provided this function as it is only used\n// by the parser.\nfunc (td *TupleDesc) setTableAlias(alias string) {\n\tfields := make([]FieldType, len(td.Fields))\n\tcopy(fields, td.Fields)\n\tfor i := range fields {\n\t\tfields[i].TableQualifier = alias\n\t}\n\ttd.Fields = fields\n}\n\n// Merge two TupleDescs together.  The resulting TupleDesc\n// should consist of the fields of desc2\n// appended onto the fields of desc.\nfunc (desc *TupleDesc) merge(desc2 *TupleDesc) *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{}  //replace me\n}\n\n// ================== Tuple Methods ======================\n\n// Interface for tuple field values\ntype DBValue interface {\n\tEvalPred(v DBValue, op BoolOp) bool\n}\n\n// Integer field value\ntype IntField struct {\n\tValue int64\n}\n\n// String field value\ntype StringField struct {\n\tValue string\n}\n\n// Tuple represents the contents of a tuple read from a database\n// It includes the tuple descriptor, and the value of the fields\ntype Tuple struct {\n\tDesc   TupleDesc\n\tFields []DBValue\n\tRid    recordID //used to track the page and position this page was read from\n}\n\ntype recordID interface {\n}\n\n// Serialize the contents of the tuple into a byte array Since all tuples are of\n// fixed size, this method should simply write the fields in sequential order\n// into the supplied buffer.\n//\n// See the function [binary.Write].  Objects should be serialized in little\n// endian oder.\n//\n// Strings can be converted to byte arrays by casting to []byte. Note that all\n// strings need to be padded to StringLength bytes (set in types.go). For\n// example if StringLength is set to 5, the string 'mit' should be written as\n// 'm', 'i', 't', 0, 0\n//\n// May return an error if the buffer has insufficient capacity to store the\n// tuple.\nfunc (t *Tuple) writeTo(b *bytes.Buffer) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"writeTo not implemented\") //replace me\n}\n\n// Read the contents of a tuple with the specified [TupleDesc] from the\n// specified buffer, returning a Tuple.\n//\n// See [binary.Read]. Objects should be deserialized in little endian oder.\n//\n// All strings are stored as StringLength byte objects.\n//\n// Strings with length < StringLength will be padded with zeros, and these\n// trailing zeros should be removed from the strings.  A []byte can be cast\n// directly to string.\n//\n// May return an error if the buffer has insufficient data to deserialize the\n// tuple.\nfunc readTupleFrom(b *bytes.Buffer, desc *TupleDesc) (*Tuple, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"readTupleFrom not implemented\") //replace me\n}\n\n// Compare two tuples for equality.  Equality means that the TupleDescs are equal\n// and all of the fields are equal.  TupleDescs should be compared with\n// the [TupleDesc.equals] method, but fields can be compared directly with equality\n// operators.\nfunc (t1 *Tuple) equals(t2 *Tuple) bool {\n\t// TODO: some code goes here\n\treturn true\n}\n\n// Merge two tuples together, producing a new tuple with the fields of t2\n// appended to t1. The new tuple should have a correct TupleDesc that is created\n// by merging the descriptions of the two input tuples.\nfunc joinTuples(t1 *Tuple, t2 *Tuple) *Tuple {\n\t// TODO: some code goes here\n\treturn &Tuple{}\n}\n\ntype orderByState int\n\nconst (\n\tOrderedLessThan    orderByState = iota\n\tOrderedEqual       orderByState = iota\n\tOrderedGreaterThan orderByState = iota\n)\n\n// Apply the supplied expression to both t and t2, and compare the results,\n// returning an orderByState value.\n//\n// Takes an arbitrary expressions rather than a field, because, e.g., for an\n// ORDER BY SQL may ORDER BY arbitrary expressions, e.g., substr(name, 1, 2)\n//\n// Note that in most cases Expr will be a [godb.FieldExpr], which simply\n// extracts a named field from a supplied tuple.\n//\n// Calling the [Expr.EvalExpr] method on a tuple will return the value of the\n// expression on the supplied tuple.\n//\n// Note that EvalExpr uses the [Tuple.project] method, so you will need\n// to implement projection before testing compareField.\nfunc (t *Tuple) compareField(t2 *Tuple, field Expr) (orderByState, error) {\n\t// TODO: some code goes here\n\treturn OrderedEqual, fmt.Errorf(\"compareField not implemented\") // replace me\n}\n\n// Project out the supplied fields from the tuple. Should return a new Tuple\n// with just the fields named in fields.\n//\n// Should not require a match on TableQualifier, but should prefer fields that\n// do match on TableQualifier (e.g., a field  t1.name in fields should match an\n// entry t2.name in t, but only if there is not an entry t1.name in t)\nfunc (t *Tuple) project(fields []FieldType) (*Tuple, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"project not implemented\")  //replace me\n}\n\n// Compute a key for the tuple to be used in a map structure\nfunc (t *Tuple) tupleKey() any {\n\tvar buf bytes.Buffer\n\tt.writeTo(&buf)\n\treturn buf.String()\n}\n\nvar winWidth int = 120\n\nfunc fmtCol(v string, ncols int) string {\n\tcolWid := winWidth / ncols\n\tnextLen := len(v) + 3\n\tremLen := colWid - nextLen\n\tif remLen > 0 {\n\t\tspacesRight := remLen / 2\n\t\tspacesLeft := remLen - spacesRight\n\t\treturn strings.Repeat(\" \", spacesLeft) + v + strings.Repeat(\" \", spacesRight) + \" |\"\n\t} else {\n\t\treturn \" \" + v[0:colWid-4] + \" |\"\n\t}\n}\n\n// Return a string representing the header of a table for a tuple with the\n// supplied TupleDesc.\n//\n// Aligned indicates if the tuple should be foramtted in a tabular format\nfunc (d *TupleDesc) HeaderString(aligned bool) string {\n\toutstr := \"\"\n\tfor i, f := range d.Fields {\n\t\ttableName := \"\"\n\t\tif f.TableQualifier != \"\" {\n\t\t\ttableName = f.TableQualifier + \".\"\n\t\t}\n\n\t\tif aligned {\n\t\t\toutstr = fmt.Sprintf(\"%s %s\", outstr, fmtCol(tableName+f.Fname, len(d.Fields)))\n\t\t} else {\n\t\t\tsep := \",\"\n\t\t\tif i == 0 {\n\t\t\t\tsep = \"\"\n\t\t\t}\n\t\t\toutstr = fmt.Sprintf(\"%s%s%s\", outstr, sep, tableName+f.Fname)\n\t\t}\n\t}\n\treturn outstr\n}\n\n// Return a string representing the tuple\n// Aligned indicates if the tuple should be formatted in a tabular format\nfunc (t *Tuple) PrettyPrintString(aligned bool) string {\n\toutstr := \"\"\n\tfor i, f := range t.Fields {\n\t\tstr := \"\"\n\t\tswitch f := f.(type) {\n\t\tcase IntField:\n\t\t\tstr = strconv.FormatInt(f.Value, 10)\n\t\tcase StringField:\n\t\t\tstr = f.Value\n\t\t}\n\t\tif aligned {\n\t\t\toutstr = fmt.Sprintf(\"%s %s\", outstr, fmtCol(str, len(t.Fields)))\n\t\t} else {\n\t\t\tsep := \",\"\n\t\t\tif i == 0 {\n\t\t\t\tsep = \"\"\n\t\t\t}\n\t\t\toutstr = fmt.Sprintf(\"%s%s%s\", outstr, sep, str)\n\t\t}\n\t}\n\treturn outstr\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "tuple_test.go",
                "code_path": "godb/tuple_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/tuple_test.go",
                "code_content": "package godb\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc CheckIfOutputMatches(f func() (*Tuple, error), ts []*Tuple) error {\n\tn := 0\n\tfor {\n\t\tt1, err := f()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif t1 == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tif n >= len(ts) {\n\t\t\treturn fmt.Errorf(\"too many tuples returned. expected %d\", len(ts))\n\t\t}\n\n\t\tt2 := ts[n]\n\t\tif !t1.equals(t2) {\n\t\t\treturn fmt.Errorf(\"tuple %d did not match expected tuple. expected %v, got %v\", n, t2, t1)\n\t\t}\n\t\tn++\n\t}\n\tif n < len(ts) {\n\t\treturn fmt.Errorf(\"too few tuples returned. expected %d, got %d\", len(ts), n)\n\t}\n\treturn nil\n}\n\nfunc CheckIfOutputMatchesUnordered(f func() (*Tuple, error), ts []*Tuple) error {\n\tn := len(ts)\n\tfound := make([]bool, n)\n\n\ti := 0\n\tfor {\n\t\tt1, err := f()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif t1 == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tif i >= n {\n\t\t\treturn fmt.Errorf(\"too many tuples returned. expected %d\", n)\n\t\t}\n\n\t\tfound_this := false\n\t\tfor j, t2 := range ts {\n\t\t\tif !found[j] && t1.equals(t2) {\n\t\t\t\tfound[j] = true\n\t\t\t\tfound_this = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !found_this {\n\t\t\treturn fmt.Errorf(\"received unexpected tuple %v\", t1)\n\t\t}\n\t\ti++\n\t}\n\tif i < n {\n\t\treturn fmt.Errorf(\"too few tuples returned. expected %d, got %d\", n, i)\n\t}\n\tfor j, f := range found {\n\t\tif !f {\n\t\t\treturn fmt.Errorf(\"missing tuple %v\", ts[j])\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc makeTupleTestVars() (TupleDesc, Tuple, Tuple) {\n\tvar td = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name\", Ftype: StringType},\n\t\t{Fname: \"age\", Ftype: IntType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc: td,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tvar t2 = Tuple{\n\t\tDesc: td,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"george jones\"},\n\t\t\tIntField{999},\n\t\t}}\n\n\treturn td, t1, t2\n}\n\n// Unit test for Tuple.writeTo() and Tuple.readTupleFrom()\nfunc TestTupleSerialization(t *testing.T) {\n\ttd, t1, _ := makeTupleTestVars()\n\tb := new(bytes.Buffer)\n\tt1.writeTo(b)\n\tt3, err := readTupleFrom(b, &td)\n\tif err != nil {\n\t\tt.Fatalf(\"Error loading tuple from saved buffer: %v\", err.Error())\n\t}\n\tif !t3.equals(&t1) {\n\t\tt.Errorf(\"Serialization / deserialization doesn't result in identical tuple.\")\n\t}\n}\n\n// Unit test for Tuple.compareField()\nfunc TestTupleExpr(t *testing.T) {\n\ttd, t1, t2 := makeTupleTestVars()\n\tft := td.Fields[0]\n\tf := FieldExpr{ft}\n\tresult, err := t1.compareField(&t2, &f) // compare \"sam\" to \"george jones\"\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif result != OrderedGreaterThan {\n\t\tt.Errorf(\"comparison of fields did not return expected result\")\n\t}\n}\n\n// Unit test for Tuple.project()\nfunc TestTupleProject(t *testing.T) {\n\t_, t1, _ := makeTupleTestVars()\n\ttNew, err := t1.project([]FieldType{t1.Desc.Fields[0]})\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tNew == nil {\n\t\tt.Fatalf(\"new tuple was nil\")\n\t}\n\tif len(tNew.Fields) != 1 {\n\t\tt.Fatalf(\"unexpected number of fields after project\")\n\t}\n\tf, ok := tNew.Fields[0].(StringField)\n\tif !ok || f.Value != \"sam\" {\n\t\tt.Errorf(\"unexpected value after project\")\n\t}\n}\n\n// Unit test for Tuple.project()\nfunc TestTupleProjectQualifier(t *testing.T) {\n\ttd1 := TupleDesc{Fields: []FieldType{{Fname: \"f\", TableQualifier: \"t1\", Ftype: IntType}, {Fname: \"f\", TableQualifier: \"t2\", Ftype: IntType}}}\n\tt1 := Tuple{td1, []DBValue{IntField{1}, IntField{2}}, nil}\n\n\ttNew, err := t1.project([]FieldType{t1.Desc.Fields[1]})\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tNew == nil {\n\t\tt.Fatalf(\"new tuple was nil\")\n\t}\n\tif len(tNew.Fields) != 1 {\n\t\tt.Fatalf(\"unexpected number of fields after project\")\n\t}\n\tf, ok := tNew.Fields[0].(IntField)\n\tif !ok || f.Value != 2 {\n\t\tt.Errorf(\"failed to select t2.f\")\n\t}\n\n\ttd2 := TupleDesc{Fields: []FieldType{{Fname: \"g\", TableQualifier: \"t1\", Ftype: IntType}, {Fname: \"f\", TableQualifier: \"t2\", Ftype: IntType}}}\n\tt2 := Tuple{td2, []DBValue{IntField{1}, IntField{2}}, nil}\n\n\ttNew, err = t2.project([]FieldType{{Fname: \"f\", TableQualifier: \"t1\", Ftype: IntType}})\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tNew == nil {\n\t\tt.Fatalf(\"new tuple was nil\")\n\t}\n\tif len(tNew.Fields) != 1 {\n\t\tt.Fatalf(\"unexpected number of fields after project\")\n\t}\n\tf, ok = tNew.Fields[0].(IntField)\n\tif !ok || f.Value != 2 {\n\t\tt.Errorf(\"failed to select t2.f\")\n\t}\n}\n\n// Unit test for Tuple.joinTuples()\nfunc TestTupleJoin(t *testing.T) {\n\t_, t1, t2 := makeTupleTestVars()\n\ttNew := joinTuples(&t1, &t2)\n\tif len(tNew.Fields) != 4 {\n\t\tt.Fatalf(\"unexpected number of fields after join\")\n\t}\n\tif len(tNew.Desc.Fields) != 4 {\n\t\tt.Fatalf(\"unexpected number of fields in description after join\")\n\t}\n\tf, ok := tNew.Fields[0].(StringField)\n\tif !ok || f.Value != \"sam\" {\n\t\tt.Fatalf(\"unexpected value after join\")\n\t}\n\tf, ok = tNew.Fields[2].(StringField)\n\tif !ok || f.Value != \"george jones\" {\n\t\tt.Errorf(\"unexpected value after join\")\n\t}\n\n}\n\nfunc TDAssertEquals(t *testing.T, expected, actual TupleDesc) {\n\tif !(expected.equals(&actual)) {\n\t\tt.Errorf(\"Expected EQUAL, found NOT EQUAL\")\n\t}\n}\n\nfunc TDAssertNotEquals(t *testing.T, expected, actual TupleDesc) {\n\tif expected.equals(&actual) {\n\t\tt.Errorf(\"Expected EQUAL, found NOT EQUAL\")\n\t}\n}\n\nfunc TAssertEquals(t *testing.T, expected, actual Tuple) {\n\tif !(expected.equals(&actual)) {\n\t\tt.Errorf(\"Expected EQUAL, found NOT EQUAL\")\n\t}\n}\n\nfunc TAssertNotEquals(t *testing.T, expected, actual Tuple) {\n\tif expected.equals(&actual) {\n\t\tt.Errorf(\"Expected NOT EQUAL, found EQUAL\")\n\t}\n}\n\nfunc TestTupleDescEquals(t *testing.T) {\n\tsingleInt := TupleDesc{Fields: []FieldType{{Ftype: IntType}}}\n\tsingleInt2 := TupleDesc{Fields: []FieldType{{Ftype: IntType}}}\n\tintString := TupleDesc{Fields: []FieldType{{Ftype: IntType}, {Ftype: StringType}}}\n\tintString2 := TupleDesc{Fields: []FieldType{{Ftype: IntType}, {Ftype: StringType}}}\n\n\tTDAssertEquals(t, singleInt, singleInt)\n\tTDAssertEquals(t, singleInt, singleInt2)\n\tTDAssertEquals(t, singleInt2, singleInt)\n\tTDAssertEquals(t, intString, intString)\n\n\tTDAssertNotEquals(t, singleInt, intString)\n\tTDAssertNotEquals(t, singleInt2, intString)\n\tTDAssertNotEquals(t, intString, singleInt)\n\tTDAssertNotEquals(t, intString, singleInt2)\n\tTDAssertEquals(t, intString, intString2)\n\tTDAssertEquals(t, intString2, intString)\n\n\tstringInt := TupleDesc{Fields: []FieldType{{Ftype: StringType}, {Ftype: IntType}}}\n\t_, t1, _ := makeTupleTestVars()\n\tTDAssertNotEquals(t, t1.Desc, stringInt) // diff in only Fname\n}\n\n// Unit test for TupleDesc.copy()\nfunc TestTupleDescCopy(t *testing.T) {\n\tsingleInt := TupleDesc{Fields: []FieldType{{Ftype: IntType}}}\n\tintString := TupleDesc{Fields: []FieldType{{Ftype: IntType}, {Ftype: StringType}}}\n\n\tTDAssertEquals(t, singleInt, *singleInt.copy())\n\tTDAssertEquals(t, intString, *intString.copy())\n\tTDAssertEquals(t, *intString.copy(), *intString.copy())\n\tTDAssertNotEquals(t, *intString.copy(), *singleInt.copy())\n\n\t// tests deep copy\n\ttdCpy := intString.copy()\n\ttdCpy2 := tdCpy.copy()\n\tif tdCpy == nil || len(tdCpy.Fields) == 0 {\n\t\tt.Fatalf(\"tdCpy is nil or fields are empty\")\n\t}\n\tif tdCpy2 == nil || len(tdCpy2.Fields) == 0 {\n\t\tt.Fatalf(\"tdCpy2 is nil or fields are empty\")\n\t}\n\ttdCpy.Fields[0] = intString.Fields[1]\n\tTDAssertNotEquals(t, *tdCpy, *tdCpy2)\n\ttdCpy.Fields[0] = intString.Fields[0]\n\tTDAssertEquals(t, *tdCpy, *tdCpy2)\n}\n\n// Unit test for TupleDesc.merge()\nfunc TestTupleDescMerge(t *testing.T) {\n\tsingleInt := TupleDesc{Fields: []FieldType{{Ftype: IntType}}}\n\tstringInt := TupleDesc{Fields: []FieldType{{Ftype: StringType}, {Ftype: IntType}}}\n\ttd1, td2 := stringInt, stringInt.copy()\n\n\ttdNew := td1.merge(&singleInt).merge(td2)\n\tfinal := TupleDesc{Fields: []FieldType{{Ftype: StringType}, {Ftype: IntType}, {Ftype: IntType}, {Ftype: StringType}, {Ftype: IntType}}}\n\n\tTDAssertEquals(t, final, *tdNew)\n\tTDAssertNotEquals(t, td1, *tdNew)\n}\n\n// Unit test for Tuple.equals()\nfunc TestTupleEquals(t *testing.T) {\n\t_, t1, t2 := makeTupleTestVars()\n\t_, t1Dup, _ := makeTupleTestVars()\n\n\tvar stringTup = Tuple{\n\t\tDesc: TupleDesc{Fields: []FieldType{{Ftype: StringType}}},\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t},\n\t}\n\n\tTAssertEquals(t, t1, t1)\n\tTAssertEquals(t, t1, t1Dup)\n\n\tTAssertNotEquals(t, t1, t2)\n\tTAssertNotEquals(t, t1, stringTup)\n\tTAssertNotEquals(t, stringTup, t2)\n}\n\nfunc TestJoinTuplesDesc(t *testing.T) {\n\t_, t1, t2 := makeTupleTestVars()\n\ttNew := joinTuples(&t1, &t2)\n\tif len(tNew.Desc.Fields) != 4 {\n\t\tt.Fatalf(\"Expected 4 fields in desc after join\")\n\t}\n\tfields := []string{\"name\", \"age\", \"name\", \"age\"}\n\tfor i, fname := range fields {\n\t\tif tNew.Desc.Fields[i].Fname != fname {\n\t\t\tt.Fatalf(\"expected %dth field to be named %s\", i, fname)\n\t\t}\n\t}\n}\n\nfunc TestTupleJoinDesc(t *testing.T) {\n\tvar td1 = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name\", Ftype: StringType},\n\t\t{Fname: \"age\", Ftype: IntType},\n\t}}\n\n\tvar td2 = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"age2\", Ftype: IntType},\n\t\t{Fname: \"name2\", Ftype: StringType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc: td1,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tvar t2 = Tuple{\n\t\tDesc: td2,\n\t\tFields: []DBValue{\n\t\t\tIntField{999},\n\t\t\tStringField{\"george jones\"},\n\t\t}}\n\n\ttNew := joinTuples(&t1, &t2)\n\tif len(tNew.Desc.Fields) != 4 {\n\t\tt.Fatalf(\"unexpected number of desc fields after join\")\n\t}\n\n\tvar tdAns = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name\", Ftype: StringType},\n\t\t{Fname: \"age\", Ftype: IntType},\n\t\t{Fname: \"age2\", Ftype: IntType},\n\t\t{Fname: \"name2\", Ftype: StringType},\n\t}}\n\n\tif !tNew.Desc.equals(&tdAns) {\n\t\tt.Fatalf(\"unexpected desc after join\")\n\t}\n}\n\nfunc TestTupleProject2(t *testing.T) {\n\tvar td = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"tq2\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq2\", Ftype: StringType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc: td,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"SFname1tq1\"},\n\t\t\tStringField{\"SFname2tq2\"},\n\t\t\tStringField{\"SFname1tq2\"},\n\t\t}}\n\n\tt2, err := t1.project([]FieldType{\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"tq2\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq2\", Ftype: StringType},\n\t})\n\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tif t2.Fields[0].(StringField).Value != \"SFname1tq1\" {\n\t\tt.Errorf(\"wrong match 0\")\n\t}\n\tif t2.Fields[1].(StringField).Value != \"SFname2tq2\" {\n\t\tt.Errorf(\"wrong match 1\")\n\t}\n\tif t2.Fields[2].(StringField).Value != \"SFname1tq1\" {\n\t\tt.Errorf(\"wrong match 2\")\n\t}\n\tif t2.Fields[3].(StringField).Value != \"SFname2tq2\" {\n\t\tt.Errorf(\"wrong match 3\")\n\t}\n\tif t2.Fields[4].(StringField).Value != \"SFname1tq2\" {\n\t\tt.Errorf(\"wrong match 4\")\n\t}\n}\n\nfunc TestTupleProject3(t *testing.T) {\n\ttd1 := TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"a\", Ftype: StringType},\n\t\t{Fname: \"b\", Ftype: IntType},\n\t}}\n\n\tt1 := Tuple{\n\t\tDesc: td1,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tft1 := FieldType{\"a\", \"\", StringType}\n\tft2 := FieldType{\"b\", \"\", IntType}\n\toutTup, err := t1.project([]FieldType{ft1})\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif (len(outTup.Fields)) != 1 {\n\t\tt.Fatalf(\"project returned %d fields, expected 1\", len(outTup.Fields))\n\t}\n\tv, ok := outTup.Fields[0].(StringField)\n\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return string\")\n\t}\n\tif v.Value != \"sam\" {\n\t\tt.Fatalf(\"project didn't return sam\")\n\n\t}\n\toutTup, _ = t1.project([]FieldType{ft2})\n\tif (len(outTup.Fields)) != 1 {\n\t\tt.Fatalf(\"project returned %d fields, expected 1\", len(outTup.Fields))\n\t}\n\tv2, ok := outTup.Fields[0].(IntField)\n\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return int\")\n\t}\n\tif v2.Value != 25 {\n\t\tt.Fatalf(\"project didn't return 25\")\n\t}\n\n\toutTup, _ = t1.project([]FieldType{ft2, ft1})\n\tif (len(outTup.Fields)) != 2 {\n\t\tt.Fatalf(\"project returned %d fields, expected 2\", len(outTup.Fields))\n\t}\n\tv, ok = outTup.Fields[1].(StringField)\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return string in second field\")\n\t}\n\tif v.Value != \"sam\" {\n\t\tt.Fatalf(\"project didn't return sam\")\n\n\t}\n\n\tv2, ok = outTup.Fields[0].(IntField)\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return int in first field\")\n\t}\n\tif v2.Value != 25 {\n\t\tt.Fatalf(\"project didn't return 25\")\n\t}\n}\n\nfunc TestTupleJoinNil(t *testing.T) {\n\t_, t1, t2 := makeTupleTestVars()\n\ttNew := joinTuples(&t1, nil)\n\tif !tNew.equals(&t1) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n\tif tNew.equals(&t2) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n\ttNew2 := joinTuples(nil, &t2)\n\tif !tNew2.equals(&t2) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n\tif tNew2.equals(&t1) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n}\n\nfunc TestTupleJoinDesc2(t *testing.T) {\n\t_, t1, t2 := makeTupleTestVars()\n\ttNew := joinTuples(&t1, &t2)\n\tif len(tNew.Desc.Fields) != 4 {\n\t\tt.Fatalf(\"Expected 4 fields in desc after join\")\n\t}\n\tfields := []string{\"name\", \"age\", \"name\", \"age\"}\n\tfor i, fname := range fields {\n\t\tif tNew.Desc.Fields[i].Fname != fname {\n\t\t\tt.Fatalf(\"expected %dth field to be named %s\", i, fname)\n\t\t}\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test tuple_test.go"
        ]
    },
    {
        "instance_id": 2,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 1: GoDB",
        "part_name": "2.4. BufferPool",
        "exercise": "Exercise 2",
        "introduction": "## 2. GoDB Architecture and Implementation Guide\n\nGoDB consists of:\n\n* Structures that represent fields, tuples, and tuple schemas;\n* Methods that apply predicates and conditions to tuples;\n* One or more access methods (e.g., heap files) that store relations on disk and\n  provide a way to iterate through tuples of those relations;\n* A collection of operator classes (e.g., select, join, insert, delete, etc.)\n  that process tuples;\n* A buffer pool that caches active tuples and pages in memory and handles\n  concurrency control and transactions (neither of which you need to worry about\n  for this lab); and,\n* A catalog that stores information about available tables and their schemas.\n\nGoDB does not include many things that you may think of as being a part of a\n\"database system.\" In particular, GoDB does not have:\n\n* (In this lab), a SQL front end or parser that allows you to type queries\n  directly into GoDB. Instead, queries are built up by chaining a set of\n  operators together into a hand-built query plan (see [Section\n  2.6](#query_walkthrough)). We will provide a simple parser for use in later\n  labs.\n* Views.\n* Data types except integers and fixed length strings.\n* (In this lab) Query optimizer.\n* (In this lab) Indices.\n\nIn the rest of this Section, we describe each of the main components of GoDB\nthat you will need to implement in this lab. You should use the exercises in\nthis discussion to guide your implementation. This document is by no means a\ncomplete specification for GoDB; you will need to make decisions about how\nto design and implement various parts of the system. Note that for Lab 1 you do\nnot need to implement any operators (e.g., select, join, project) except\nsequential scan as a part of the `heap_file.go` file.\nYou will add support for additional operators in future labs.",
        "Description": "### 2.4. BufferPool\n\nThe buffer pool (class `BufferPool` in GoDB) is responsible for caching\npages in memory that have been recently read from disk. All operators read and\nwrite pages from various files on disk through the buffer pool. It consists of a\nfixed number of pages, defined by the `numPages` parameter to the `BufferPool`\nconstructor `NewBufferPool`.  \n\nFor this lab,\nyou need to implement the constructor and the `BufferPool.getPage()` method\nused by the `HeapFile` iterator, as well as the `BufferPool.flushAllPages()` method.\nThe buffer pool stores structs that implement the `Page` interface;  these pages can be read from\nunderlying database files (such as a heap file) which implement the `DBFile` interface using the\n`readPage` method.\nThe BufferPool should store up to `numPages`\npages. `numPages` is passed to the constructor as a parameter. If more than `numPages` requests are made for different\npages, you should evict one of them according to an eviction policy of your choice (nothing sophisticated needed).\nNote that you *should not* evict dirty pages (pages where the `Page` method `isDirty()` returns true), for\nreasons we will explain when we discuss transactions later in the class. For Lab 1, if all pages are dirty, return an error.\n\n\n\n### Exercise 2\n\n**Implement the `getPage()`, `flushAllPages`, and constructor method in:**\n\n---\n* `buffer_pool.go`\n---\nThere is a unit test suite  `buffer_pool_test.go`, but you will not be able to pass this test\nuntil you implement the heap file and heap page methods below.  You will also test the functionality\nof the buffer pool when you implement your heap file iterator.\n\n<!--\nWhen more than this many pages are in the buffer pool, one page should be\nevicted from the pool before the next is loaded.  The choice of eviction\npolicy is up to you; it is not necessary to do something sophisticated.\n-->\n\n<!--\n<p>\n\nNotice that `BufferPool` asks you to implement\na `flush_all_pages()` method.  This is not something you would ever\nneed in a real implementation of a buffer pool.  However, we need this method\nfor testing purposes.  You really should never call this method from anywhere\nin your code.\n-->",
        "repo/location": "go get main\ncd godb\ngo get ../godb\ngo test",
        "dependency": [
            "3",
            "4"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab1.md",
        "codes": [
            {
                "code_path": "godb/buffer_pool.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/buffer_pool.go",
                "code_content": "package godb\n\n//BufferPool provides methods to cache pages that have been read from disk.\n//It has a fixed capacity to limit the total amount of memory used by GoDB.\n//It is also the primary way in which transactions are enforced, by using page\n//level locking (you will not need to worry about this until lab3).\n\nimport (\n\t\"fmt\"\n)\n\n// Permissions used to when reading / locking pages\ntype RWPerm int\n\nconst (\n\tReadPerm  RWPerm = iota\n\tWritePerm RWPerm = iota\n)\n\ntype BufferPool struct {\n\t// TODO: some code goes here\n}\n\n// Create a new BufferPool with the specified number of pages\nfunc NewBufferPool(numPages int) (*BufferPool, error) {\n\treturn &BufferPool{}, fmt.Errorf(\"NewBufferPool not implemented\")\n}\n\n// Testing method -- iterate through all pages in the buffer pool\n// and flush them using [DBFile.flushPage]. Does not need to be thread/transaction safe.\n// Mark pages as not dirty after flushing them.\nfunc (bp *BufferPool) FlushAllPages() {\n\t// TODO: some code goes here\n}\n\n// Abort the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk so it is sufficient to just\n// release locks to abort. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) AbortTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Commit the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk, so prior to releasing locks you\n// should iterate through pages and write them to disk.  In GoDB lab3 we assume\n// that the system will not crash while doing this, allowing us to avoid using a\n// WAL. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) CommitTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Begin a new transaction. You do not need to implement this for lab 1.\n//\n// Returns an error if the transaction is already running.\nfunc (bp *BufferPool) BeginTransaction(tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// Retrieve the specified page from the specified DBFile (e.g., a HeapFile), on\n// behalf of the specified transaction. If a page is not cached in the buffer pool,\n// you can read it from disk uing [DBFile.readPage]. If the buffer pool is full (i.e.,\n// already stores numPages pages), a page should be evicted.  Should not evict\n// pages that are dirty, as this would violate NO STEAL. If the buffer pool is\n// full of dirty pages, you should return an error. Before returning the page,\n// attempt to lock it with the specified permission.  If the lock is\n// unavailable, should block until the lock is free. If a deadlock occurs, abort\n// one of the transactions in the deadlock. For lab 1, you do not need to\n// implement locking or deadlock detection. You will likely want to store a list\n// of pages in the BufferPool in a map keyed by the [DBFile.pageKey].\nfunc (bp *BufferPool) GetPage(file DBFile, pageNo int, tid TransactionID, perm RWPerm) (Page, error) {\n\treturn nil, fmt.Errorf(\"GetPage not implemented\")\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "buffer_pool_test.go",
                "code_path": "godb/buffer_pool_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/buffer_pool_test.go",
                "code_content": "package godb\n\nimport (\n\t\"os\"\n\t\"testing\"\n)\n\nfunc TestBufferPoolGetPage(t *testing.T) {\n\t_, t1, t2, hf, bp, _ := makeTestVars(t)\n\ttid := NewTID()\n\tfor i := 0; i < 300; i++ {\n\t\tbp.BeginTransaction(tid)\n\t\terr := hf.insertTuple(&t1, tid)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"%v\", err)\n\t\t}\n\t\terr = hf.insertTuple(&t2, tid)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"%v\", err)\n\t\t}\n\n\t\t// Force dirty pages to disk. CommitTransaction may not be implemented\n\t\t// yet if this is called in lab 1 or 2.\n\t\tbp.FlushAllPages()\n\n\t\t// commit transaction\n\t\tbp.CommitTransaction(tid)\n\t}\n\tbp.BeginTransaction(tid)\n\t//expect 6 pages\n\tfor i := 0; i < 6; i++ {\n\t\tpg, err := bp.GetPage(hf, i, tid, ReadPerm)\n\t\tif pg == nil || err != nil {\n\t\t\tt.Fatalf(\"failed to get page %d (err = %v)\", i, err)\n\t\t}\n\t}\n\t_, err := bp.GetPage(hf, 7, tid, ReadPerm)\n\tif err == nil {\n\t\tt.Fatalf(\"No error when getting page 7 from a file with 6 pages.\")\n\t}\n}\n\nfunc TestSetDirty(t *testing.T) {\n\t_, t1, _, hf, bp, _ := makeTestVars(t)\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\tfor i := 0; i < 308; i++ {\n\t\terr := hf.insertTuple(&t1, tid)\n\t\tif err != nil && (i == 306 || i == 307) {\n\t\t\treturn\n\t\t} else if err != nil {\n\t\t\tt.Fatalf(\"%v\", err)\n\t\t}\n\t}\n\tbp.CommitTransaction(tid)\n\tt.Fatalf(\"Expected error due to all pages in BufferPool being dirty\")\n}\n\n// Test is only valid up to Lab 4. In Lab 5 we switch from FORCE/NOSTEAL to NOFORCE/STEAL.\nfunc TestBufferPoolHoldsMultipleHeapFiles(t *testing.T) {\n\tif os.Getenv(\"LAB\") == \"5\" {\n\t\tt.Skip(\"This test is only valid up to Lab 4. Skipping\")\n\t}\n\n\ttd, t1, t2, hf, bp, tid := makeTestVars(t)\n\tos.Remove(TestingFile2)\n\thf2, err := NewHeapFile(TestingFile2, &td, bp)\n\tif err != nil {\n\t\tprint(\"ERROR MAKING TEST VARS, BLARGH\")\n\t\tpanic(err)\n\t}\n\n\terr1 := hf.insertTuple(&t1, tid)\n\terr2 := hf.insertTuple(&t1, tid)\n\terr3 := hf2.insertTuple(&t2, tid)\n\n\tif err1 != nil || err2 != nil || err3 != nil {\n\t\tt.Errorf(\"The BufferPool should be able to handle multiple files\")\n\t}\n\t// bp contains 2 dirty pages at this point\n\n\thf2TupCntPerPage := 0\n\tfor hf2.NumPages() <= 1 {\n\t\tif err := hf2.insertTuple(&t2, tid); err != nil {\n\t\t\tt.Errorf(\"%v\", err)\n\t\t}\n\t\thf2TupCntPerPage++\n\t}\n\t// bp contains 3 dirty pages at this point\n\n\tfor i := 0; i < hf2TupCntPerPage-1; i++ {\n\t\tif err := hf2.insertTuple(&t2, tid); err != nil {\n\t\t\tt.Errorf(\"%v\", err)\n\t\t}\n\t}\n\n\t// bp contains 3 dirty pages at this point, including 2 full pages of hf2\n\t_ = hf2.insertTuple(&t2, tid)\n\tif err := hf2.insertTuple(&t2, tid); err == nil {\n\t\tt.Errorf(\"should cause bufferpool dirty page overflow here\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test buffer_pool_test.go"
        ]
    },
    {
        "instance_id": 3,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 1: GoDB",
        "part_name": "2.5. HeapFile access method",
        "exercise": "Exercise 3",
        "introduction": "## 2. GoDB Architecture and Implementation Guide\n\nGoDB consists of:\n\n* Structures that represent fields, tuples, and tuple schemas;\n* Methods that apply predicates and conditions to tuples;\n* One or more access methods (e.g., heap files) that store relations on disk and\n  provide a way to iterate through tuples of those relations;\n* A collection of operator classes (e.g., select, join, insert, delete, etc.)\n  that process tuples;\n* A buffer pool that caches active tuples and pages in memory and handles\n  concurrency control and transactions (neither of which you need to worry about\n  for this lab); and,\n* A catalog that stores information about available tables and their schemas.\n\nGoDB does not include many things that you may think of as being a part of a\n\"database system.\" In particular, GoDB does not have:\n\n* (In this lab), a SQL front end or parser that allows you to type queries\n  directly into GoDB. Instead, queries are built up by chaining a set of\n  operators together into a hand-built query plan (see [Section\n  2.6](#query_walkthrough)). We will provide a simple parser for use in later\n  labs.\n* Views.\n* Data types except integers and fixed length strings.\n* (In this lab) Query optimizer.\n* (In this lab) Indices.\n\nIn the rest of this Section, we describe each of the main components of GoDB\nthat you will need to implement in this lab. You should use the exercises in\nthis discussion to guide your implementation. This document is by no means a\ncomplete specification for GoDB; you will need to make decisions about how\nto design and implement various parts of the system. Note that for Lab 1 you do\nnot need to implement any operators (e.g., select, join, project) except\nsequential scan as a part of the `heap_file.go` file.\nYou will add support for additional operators in future labs.",
        "Description": "### 2.5. `HeapFile` access method\n\nAccess methods provide a way to read or write data from disk that is arranged in\na specific way. Common access methods include heap files (unsorted files of\ntuples) and B-trees; for this assignment, you will only implement a heap file\naccess method, and we have written some of the code for you.\n\nA `HeapFile` object is arranged into a set of pages, each of which consists of a\nfixed number of bytes for storing tuples, (defined by the constant\n`PageSize`), including a header. In GoDB, there is one\n`HeapFile` object for each table in the database. Each page in a `HeapFile` is\narranged as a set of slots, each of which can hold one tuple (tuples for a given\ntable in GoDB are all of the same size).   \nPages of `HeapFile` objects are of type `HeapPage` which\nimplements the `Page` interface. Pages are stored in the buffer pool but are\nread and written by the `HeapFile` class. Because pages are fixed size, and tuple are fixed\nsize, in GoDB, all pages store the same number of tuples. You are free to choose your\nin-memory implementation of `HeapPage` but a reasonable choice would be a slice\nof `Tuple`s.  \n\nGoDB stores heap files on disk as pages of data arranged consecutively on\ndisk. On disk, each page consists of a header, followed\nby the `PageSize` - _header size_ bytes of actual page content.\n The header consists of a 32 bit\n integer with the number of slots (tuples), and a second 32 bit integer with\nthe number of used slots.   See the comments at the beginning of `heap_page.go` for\nmore details on the representation.\n\n\n\n### Exercise 3\n\n**Implement the skeleton methods in:**\n\n---\n* heap_page.go\n---\n\nAlthough you are not required to use exactly our interface for `heap_page.go`,\nyou will likely find the methods we have provided to be useful and we recommend\nfollowing our skeleton.   \n\nAssuming you follow our outline, there are five non-trivial methods to implement:\n\n1. `insertTuple()` : This method should add a tuple to the page if there is space.  Because a heap file is unordered, it\ncan be inserted in any free slot.  After inserting a tuple on a page, you should mark it dirty.\n\n2. `deleteTuple()` : Delete a specific tuple from the page.\nNote that this method takes a specific recordID (or \"rid\") to delete.  recordID is an empty interface; you are free\nto use any struct you like for the rid, but for a heap file a rid would typically include the page number and the slot number on the page.\nThe page number would typically be the offset in the heap file of the page, and the slot number would likely by the position of the tuple\nin the in-memory slice of tuples on the page. You will set the rid field of the tuples you return from your iterator.  Your heap file implementation should use this rid to identify the specific page to delete from, and then pass the rid into this method so that you can delete the appropriate tuple.   Note that if you choose to represent a page in memory as a slice of tuples, and the slot in the rid is the position in the slice, you should take care to not cause the rid to change when you perform the deletion.  One way to achieve this is to set the position in the slice to nil (rather than creating a new slice with the deleted tuple removed from it), but many implementations are possible.  After deleting a tuple from a page, you should mark it dirty.\n\n3. `toBuffer()` : Serialize the pages to a `bytes.Buffer` object for saving to disk, using the `binary.Write()` method to encode the header and the `writeTo()` method from your tuple implementation.   Note that the header includes the number of used slots, but does not encode which slots are empty and which are not.  This is ok, because, in GoDB you do not need to preserve the record ids of records when they are written out (so a particular tuple's rid may change after it is written and then read back.)  \n\n4. `initFromBuffer()` : Read the page from the specified buffer by reading the header with the `binary.Read()` method and then the tuples using the `readTupleFrom()` method.\n\n5. `tupleIter()` : Return a function that can be invoked to interate through the tuples of the page.   See the note about iterators in [2.2](#22-operators-and-iterators) above.\n\nThere are a few other relatively simpler methods (`setDirty()`, `isDirty()`, `getNumSlots()`, and the `newHeapPage()` constructor) that you will need to implement\n\nAt this point, your code should pass the unit tests in `heap_page_test.go`.\n\nAfter you have implemented `HeapPage`, you will write methods for `HeapFile` that\nread pages from the file, iterate through pages, and insert and delete\nrecords.  ",
        "repo/location": "go get main\ncd godb\ngo get ../godb\ngo test",
        "dependency": [],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab1.md",
        "codes": [
            {
                "code_path": "godb/heap_page.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/heap_page.go",
                "code_content": "package godb\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n)\n\n/* HeapPage implements the Page interface for pages of HeapFiles. We have\nprovided our interface to HeapPage below for you to fill in, but you are not\nrequired to implement these methods except for the three methods that the Page\ninterface requires.  You will want to use an interface like what we provide to\nimplement the methods of [HeapFile] that insert, delete, and iterate through\ntuples.\n\nIn GoDB all tuples are fixed length, which means that given a TupleDesc it is\npossible to figure out how many tuple \"slots\" fit on a given page.\n\nIn addition, all pages are PageSize bytes.  They begin with a header with a 32\nbit integer with the number of slots (tuples), and a second 32 bit integer with\nthe number of used slots.\n\nEach tuple occupies the same number of bytes.  You can use the go function\nunsafe.Sizeof() to determine the size in bytes of an object.  So, a GoDB integer\n(represented as an int64) requires unsafe.Sizeof(int64(0)) bytes.  For strings,\nwe encode them as byte arrays of StringLength, so they are size\n((int)(unsafe.Sizeof(byte('a')))) * StringLength bytes.  The size in bytes  of a\ntuple is just the sum of the size in bytes of its fields.\n\nOnce you have figured out how big a record is, you can determine the number of\nslots on on the page as:\n\nremPageSize = PageSize - 8 // bytes after header\nnumSlots = remPageSize / bytesPerTuple //integer division will round down\n\nTo serialize a page to a buffer, you can then:\n\nwrite the number of slots as an int32\nwrite the number of used slots as an int32\nwrite the tuples themselves to the buffer\n\nYou will follow the inverse process to read pages from a buffer.\n\nNote that to process deletions you will likely delete tuples at a specific\nposition (slot) in the heap page.  This means that after a page is read from\ndisk, tuples should retain the same slot number. Because GoDB will never evict a\ndirty page, it's OK if tuples are renumbered when they are written back to disk.\n\n*/\n\ntype heapPage struct {\n\t// TODO: some code goes here\n}\n\n// Construct a new heap page\nfunc newHeapPage(desc *TupleDesc, pageNo int, f *HeapFile) (*heapPage, error) {\n\t// TODO: some code goes here\n\treturn &heapPage{}, fmt.Errorf(\"newHeapPage is not implemented\") //replace me\n}\n\nfunc (h *heapPage) getNumSlots() int {\n\t// TODO: some code goes here\n\treturn 0 //replace me\n}\n\n// Insert the tuple into a free slot on the page, or return an error if there are\n// no free slots.  Set the tuples rid and return it.\nfunc (h *heapPage) insertTuple(t *Tuple) (recordID, error) {\n\t// TODO: some code goes here\n\treturn 0, fmt.Errorf(\"insertTuple not implemented\") //replace me\n}\n\n// Delete the tuple at the specified record ID, or return an error if the ID is\n// invalid.\nfunc (h *heapPage) deleteTuple(rid recordID) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"deleteTuple not implemented\") //replace me\n}\n\n// Page method - return whether or not the page is dirty\nfunc (h *heapPage) isDirty() bool {\n\t// TODO: some code goes here\n\treturn false //replace me\n}\n\n// Page method - mark the page as dirty\nfunc (h *heapPage) setDirty(tid TransactionID, dirty bool) {\n\t// TODO: some code goes here\n}\n\n// Page method - return the corresponding HeapFile\n// for this page.\nfunc (p *heapPage) getFile() DBFile {\n\t// TODO: some code goes here\n\treturn nil //replace me\n}\n\n// Allocate a new bytes.Buffer and write the heap page to it. Returns an error\n// if the write to the the buffer fails. You will likely want to call this from\n// your [HeapFile.flushPage] method.  You should write the page header, using\n// the binary.Write method in LittleEndian order, followed by the tuples of the\n// page, written using the Tuple.writeTo method.\nfunc (h *heapPage) toBuffer() (*bytes.Buffer, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"heap_page.toBuffer not implemented\") //replace me\n}\n\n// Read the contents of the HeapPage from the supplied buffer.\nfunc (h *heapPage) initFromBuffer(buf *bytes.Buffer) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"initFromBuffer not implemented\") //replace me\n}\n\n// Return a function that iterates through the tuples of the heap page.  Be sure\n// to set the rid of the tuple to the rid struct of your choosing beforing\n// return it. Return nil, nil when the last tuple is reached.\nfunc (p *heapPage) tupleIter() func() (*Tuple, error) {\n\t// TODO: some code goes here\n\treturn func() (*Tuple, error) {\n\treturn nil, fmt.Errorf(\"heap_file.Iterator not implemented\") // replace me\n\t}\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "heap_page_test.go",
                "code_path": "godb/heap_page_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/heap_page_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n\t\"unsafe\"\n)\n\nfunc TestHeapPageInsert(t *testing.T) {\n\ttd, t1, t2, hf, _, _ := makeTestVars(t)\n\tpg, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tvar expectedSlots = (PageSize - 8) / (StringLength + int(unsafe.Sizeof(int64(0))))\n\tif pg.getNumSlots() != expectedSlots {\n\t\tt.Fatalf(\"Incorrect number of slots, expected %d, got %d\", expectedSlots, pg.getNumSlots())\n\t}\n\n\t_, err = pg.insertTuple(&t1)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\t_, err = pg.insertTuple(&t2)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer := pg.tupleIter()\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\n\tcnt := 0\n\tfor {\n\t\ttup, err := iter()\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcnt += 1\n\t}\n\tif cnt != 2 {\n\t\tt.Errorf(\"Expected 2 tuples in interator, got %d\", cnt)\n\t}\n}\n\nfunc TestHeapPageDelete(t *testing.T) {\n\ttd, t1, t2, hf, _, _ := makeTestVars(t)\n\tpg, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tpg.insertTuple(&t1)\n\tslotNo, _ := pg.insertTuple(&t2)\n\tpg.deleteTuple(slotNo)\n\n\titer := pg.tupleIter()\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\tcnt := 0\n\tfor {\n\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tcnt += 1\n\t}\n\tif cnt != 1 {\n\t\tt.Errorf(\"Expected 1 tuple in interator, got %d\", cnt)\n\t}\n}\n\n// Unit test for insertTuple\nfunc TestHeapPageInsertTuple(t *testing.T) {\n\ttd, t1, _, hf, _, _ := makeTestVars(t)\n\tpage, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tfree := page.getNumSlots()\n\n\tfor i := 0; i < free; i++ {\n\t\tvar addition = Tuple{\n\t\t\tDesc: td,\n\t\t\tFields: []DBValue{\n\t\t\t\tStringField{\"sam\"},\n\t\t\t\tIntField{int64(i)},\n\t\t\t},\n\t\t}\n\t\tpage.insertTuple(&addition)\n\n\t\titer := page.tupleIter()\n\t\tif iter == nil {\n\t\t\tt.Fatalf(\"Iterator was nil\")\n\t\t}\n\t\tcnt, found := 0, false\n\t\tfor {\n\n\t\t\ttup, _ := iter()\n\t\t\tfound = found || addition.equals(tup)\n\t\t\tif tup == nil {\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\tcnt += 1\n\t\t}\n\t\tif cnt != i+1 {\n\t\t\tt.Errorf(\"Expected %d tuple in interator, got %d\", i+1, cnt)\n\t\t}\n\t\tif !found {\n\t\t\tt.Errorf(\"Expected inserted tuple to be FOUND, got NOT FOUND\")\n\t\t}\n\t}\n\n\t_, err = page.insertTuple(&t1)\n\n\tif err == nil {\n\t\tt.Errorf(\"Expected error due to full page\")\n\t}\n}\n\n// Unit test for deleteTuple\nfunc TestHeapPageDeleteTuple(t *testing.T) {\n\ttd, _, _, hf, _, _ := makeTestVars(t)\n\tpage, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tfree := page.getNumSlots()\n\n\tlist := make([]recordID, free)\n\tfor i := 0; i < free; i++ {\n\t\tvar addition = Tuple{\n\t\t\tDesc: td,\n\t\t\tFields: []DBValue{\n\t\t\t\tStringField{\"sam\"},\n\t\t\t\tIntField{int64(i)},\n\t\t\t},\n\t\t}\n\t\tlist[i], _ = page.insertTuple(&addition)\n\t}\n\tif len(list) == 0 {\n\t\tt.Fatalf(\"Rid list is empty.\")\n\t}\n\tfor i, rnd := free-1, 0xdefaced; i > 0; i, rnd = i-1, (rnd*0x7deface1+12354)%0x7deface9 {\n\t\t// Generate a random index j such that 0 <= j <= i.\n\t\tj := rnd % (i + 1)\n\n\t\t// Swap arr[i] and arr[j].\n\t\tlist[i], list[j] = list[j], list[i]\n\t}\n\n\tfor _, rid := range list {\n\t\terr := page.deleteTuple(rid)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Found error %s\", err.Error())\n\t\t}\n\t}\n\n\terr = page.deleteTuple(list[0])\n\tif err == nil {\n\t\tt.Errorf(\"page should be empty; expected error\")\n\t}\n}\n\n// Unit test for isDirty, setDirty\nfunc TestHeapPageDirty(t *testing.T) {\n\ttd, _, _, hf, _, _ := makeTestVars(t)\n\tpage, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tpage.setDirty(0, true)\n\tif !page.isDirty() {\n\t\tt.Errorf(\"page should be dirty\")\n\t}\n\tpage.setDirty(0, true)\n\tif !page.isDirty() {\n\t\tt.Errorf(\"page should be dirty\")\n\t}\n\tpage.setDirty(-1, false)\n\tif page.isDirty() {\n\t\tt.Errorf(\"page should be not dirty\")\n\t}\n}\n\n// Unit test for toBuffer and initFromBuffer\nfunc TestHeapPageSerialization(t *testing.T) {\n\ttd, _, _, hf, _, _ := makeTestVars(t)\n\tpage, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tfree := page.getNumSlots()\n\n\tfor i := 0; i < free-1; i++ {\n\t\tvar addition = Tuple{\n\t\t\tDesc: td,\n\t\t\tFields: []DBValue{\n\t\t\t\tStringField{\"sam\"},\n\t\t\t\tIntField{int64(i)},\n\t\t\t},\n\t\t}\n\t\tpage.insertTuple(&addition)\n\t}\n\n\tbuf, _ := page.toBuffer()\n\tpage2, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = page2.initFromBuffer(buf)\n\tif err != nil {\n\t\tt.Fatalf(\"Error loading heap page from buffer.\")\n\t}\n\n\titer, iter2 := page.tupleIter(), page2.tupleIter()\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil.\")\n\t}\n\tif iter2 == nil {\n\t\tt.Fatalf(\"iter2 was nil.\")\n\t}\n\n\tfindEqCount := func(t0 *Tuple, iter3 func() (*Tuple, error)) int {\n\t\tcnt := 0\n\t\tfor tup, _ := iter3(); tup != nil; tup, _ = iter3() {\n\t\t\tif t0.equals(tup) {\n\t\t\t\tcnt += 1\n\t\t\t}\n\t\t}\n\t\treturn cnt\n\t}\n\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tif findEqCount(tup, page.tupleIter()) != findEqCount(tup, page2.tupleIter()) {\n\t\t\tt.Errorf(\"Serialization / deserialization doesn't result in identical heap page.\")\n\t\t}\n\t}\n}\n\nfunc TestHeapPageBufferLen(t *testing.T) {\n\ttd, _, _, hf, _, _ := makeTestVars(t)\n\tpage, err := newHeapPage(&td, 0, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tfree := page.getNumSlots()\n\n\tfor i := 0; i < free-1; i++ {\n\t\tvar addition = Tuple{\n\t\t\tDesc: td,\n\t\t\tFields: []DBValue{\n\t\t\t\tStringField{\"sam\"},\n\t\t\t\tIntField{int64(i)},\n\t\t\t},\n\t\t}\n\t\tpage.insertTuple(&addition)\n\t}\n\n\tbuf, _ := page.toBuffer()\n\n\tif buf.Len() != PageSize {\n\t\tt.Fatalf(\"HeapPage.toBuffer returns buffer of unexpected size;  NOTE:  This error may be OK, but many implementations that don't write full pages break.\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test heap_page_test.go"
        ]
    },
    {
        "instance_id": 4,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 1: GoDB",
        "part_name": "2.5. HeapFile access method",
        "exercise": "Exercise 4",
        "introduction": "## 2. GoDB Architecture and Implementation Guide\n\nGoDB consists of:\n\n* Structures that represent fields, tuples, and tuple schemas;\n* Methods that apply predicates and conditions to tuples;\n* One or more access methods (e.g., heap files) that store relations on disk and\n  provide a way to iterate through tuples of those relations;\n* A collection of operator classes (e.g., select, join, insert, delete, etc.)\n  that process tuples;\n* A buffer pool that caches active tuples and pages in memory and handles\n  concurrency control and transactions (neither of which you need to worry about\n  for this lab); and,\n* A catalog that stores information about available tables and their schemas.\n\nGoDB does not include many things that you may think of as being a part of a\n\"database system.\" In particular, GoDB does not have:\n\n* (In this lab), a SQL front end or parser that allows you to type queries\n  directly into GoDB. Instead, queries are built up by chaining a set of\n  operators together into a hand-built query plan (see [Section\n  2.6](#query_walkthrough)). We will provide a simple parser for use in later\n  labs.\n* Views.\n* Data types except integers and fixed length strings.\n* (In this lab) Query optimizer.\n* (In this lab) Indices.\n\nIn the rest of this Section, we describe each of the main components of GoDB\nthat you will need to implement in this lab. You should use the exercises in\nthis discussion to guide your implementation. This document is by no means a\ncomplete specification for GoDB; you will need to make decisions about how\nto design and implement various parts of the system. Note that for Lab 1 you do\nnot need to implement any operators (e.g., select, join, project) except\nsequential scan as a part of the `heap_file.go` file.\nYou will add support for additional operators in future labs.",
        "Description": "### 2.5. `HeapFile` access method\n\nAccess methods provide a way to read or write data from disk that is arranged in\na specific way. Common access methods include heap files (unsorted files of\ntuples) and B-trees; for this assignment, you will only implement a heap file\naccess method, and we have written some of the code for you.\n\nA `HeapFile` object is arranged into a set of pages, each of which consists of a\nfixed number of bytes for storing tuples, (defined by the constant\n`PageSize`), including a header. In GoDB, there is one\n`HeapFile` object for each table in the database. Each page in a `HeapFile` is\narranged as a set of slots, each of which can hold one tuple (tuples for a given\ntable in GoDB are all of the same size).   \nPages of `HeapFile` objects are of type `HeapPage` which\nimplements the `Page` interface. Pages are stored in the buffer pool but are\nread and written by the `HeapFile` class. Because pages are fixed size, and tuple are fixed\nsize, in GoDB, all pages store the same number of tuples. You are free to choose your\nin-memory implementation of `HeapPage` but a reasonable choice would be a slice\nof `Tuple`s.  \n\nGoDB stores heap files on disk as pages of data arranged consecutively on\ndisk. On disk, each page consists of a header, followed\nby the `PageSize` - _header size_ bytes of actual page content.\n The header consists of a 32 bit\n integer with the number of slots (tuples), and a second 32 bit integer with\nthe number of used slots.   See the comments at the beginning of `heap_page.go` for\nmore details on the representation.\n\n\n### Exercise 4\n\n**Implement the skeleton methods in:**\n\n---\n\n* heap_file.go\n\n---\n\nThere are a number of methods you need to implement; we have provided additional implementation tips in the comments in `heap_file.go`.\n\n1. `NewHeapFile()` - The constructor.  It takes a file name that contains the binary encoding of the file (we name these `table.dat` by convention), as well as the TupleDesc that can be used to determine the expected format of the file and a buffer pool object that you will use to retrieve cached pages.\n2. `NumPages()` - Return the number of pages in the heap file;  you can use the `File.Stat()` method to determine the size of the heap file in bytes.  \n3. `readPage()` - Read a specific page from storage. To read a page from disk, you will first need to calculate the correct offset in\n   the file. Hint: you will need random access to the file in order to read and\n   write pages at arbitrary offsets -- check out the golang `os.File` type and its `ReadAt()` method.\n   You should not call `BufferPool` methods when reading a page from disk in the `readPage()` method, but you will\n   use the buffer pool `getPage()` method in your implementations of the heap file `iterator`.  Once you have read in the bytes of the page you can create the page using the heap page method `newHeapPage()`.  You can convert bytes read from a file to a buffer via the `bytes.NewBuffer()` method.\n4. `flushPage()` - Force a given page object back to disk.  The supplied page will be a `HeapPage`;  you should cast it and retrieve its bytes via the heap page method `toBuffer()`.  You can then write these bytes back to the appropriate location on disk by opening the backing file and using a method like `os.File.WriteAt()`.\n5. `insertTuple()` - Add a tuple to the heap file;  because the heap file is unordered, it can be inserted in any free slot in the file\n6. `deleteTuple()` - Remove a specific tuple from the heap file.  You should use the rid field of the tuple to determine which page the\n   tuple is in, and call the heap page method `deleteTuple()` on the appropriage page.\n7. `Descriptor()`\n8. `Iterator()` - Return a function that iterates through the tuples of the heap file one at a time.  You should iterate through the pages and use the `tupleIter()` to iterate through the the tuples of each heap page.  See the note above about iterators in GoDB in [2.2](#22-operators-and-iterators) above.\n   This method should read pages using the buffer pool method `getPage()` which will eventually be used (in\n   a later lab) to implement locking-based concurrency control and recovery. Do\n   not load the entire table into memory when the iterator is instantiated -- this will cause an\n   out of memory error for very large tables.  Instead, you will just load one page at a\n   time as the buffer pool accesses them via calls to `readPage()`.\n9. `pageKey()` - Return a struct that can be used as a key for the page.  The buffer pool uses this to determine whether the page is cached or not.  We have provided an implementation hint in the comment of this function.\n\n\nAt this point, your code should pass the unit tests in `heap_file_test.go` and `buffer_pool_test.go`.  This completes the unit tests for this lab.  You should complete the final exercises in the next section.",
        "repo/location": "go get main\ncd godb\ngo get ../godb\ngo test",
        "dependency": [],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab1.md",
        "codes": [
            {
                "code_path": "godb/heap_file.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/heap_file.go",
                "code_content": "package godb\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// A HeapFile is an unordered collection of tuples.\n//\n// HeapFile is a public class because external callers may wish to instantiate\n// database tables using the method [LoadFromCSV]\ntype HeapFile struct {\n\t// TODO: some code goes here\n\t// HeapFile should include the fields below;  you may want to add\n\t// additional fields\n\tbufPool *BufferPool\n}\n\n// Create a HeapFile.\n// Parameters\n// - fromFile: backing file for the HeapFile.  May be empty or a previously created heap file.\n// - td: the TupleDesc for the HeapFile.\n// - bp: the BufferPool that is used to store pages read from the HeapFile\n// May return an error if the file cannot be opened or created.\nfunc NewHeapFile(fromFile string, td *TupleDesc, bp *BufferPool) (*HeapFile, error) {\n\t// TODO: some code goes here\n\treturn &HeapFile{}, fmt.Errorf(\"NewHeapFile not implemented\") //replace me\n}\n\n// Return the name of the backing file\nfunc (f *HeapFile) BackingFile() string {\n\t// TODO: some code goes here\n\treturn \"\" //replace me\n}\n\n// Return the number of pages in the heap file\nfunc (f *HeapFile) NumPages() int {\n\t// TODO: some code goes here\n\treturn 0 //replace me\n}\n\n// Load the contents of a heap file from a specified CSV file.  Parameters are as follows:\n// - hasHeader:  whether or not the CSV file has a header\n// - sep: the character to use to separate fields\n// - skipLastField: if true, the final field is skipped (some TPC datasets include a trailing separator on each line)\n// Returns an error if the field cannot be opened or if a line is malformed\n// We provide the implementation of this method, but it won't work until\n// [HeapFile.insertTuple] and some other utility functions are implemented\nfunc (f *HeapFile) LoadFromCSV(file *os.File, hasHeader bool, sep string, skipLastField bool) error {\n\tscanner := bufio.NewScanner(file)\n\tcnt := 0\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tfields := strings.Split(line, sep)\n\t\tif skipLastField {\n\t\t\tfields = fields[0 : len(fields)-1]\n\t\t}\n\t\tnumFields := len(fields)\n\t\tcnt++\n\t\tdesc := f.Descriptor()\n\t\tif desc == nil || desc.Fields == nil {\n\t\t\treturn GoDBError{MalformedDataError, \"Descriptor was nil\"}\n\t\t}\n\t\tif numFields != len(desc.Fields) {\n\t\t\treturn GoDBError{MalformedDataError, fmt.Sprintf(\"LoadFromCSV:  line %d (%s) does not have expected number of fields (expected %d, got %d)\", cnt, line, len(f.Descriptor().Fields), numFields)}\n\t\t}\n\t\tif cnt == 1 && hasHeader {\n\t\t\tcontinue\n\t\t}\n\t\tvar newFields []DBValue\n\t\tfor fno, field := range fields {\n\t\t\tswitch f.Descriptor().Fields[fno].Ftype {\n\t\t\tcase IntType:\n\t\t\t\tfield = strings.TrimSpace(field)\n\t\t\t\tfloatVal, err := strconv.ParseFloat(field, 64)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn GoDBError{TypeMismatchError, fmt.Sprintf(\"LoadFromCSV: couldn't convert value %s to int, tuple %d\", field, cnt)}\n\t\t\t\t}\n\t\t\t\tintValue := int(floatVal)\n\t\t\t\tnewFields = append(newFields, IntField{int64(intValue)})\n\t\t\tcase StringType:\n\t\t\t\tif len(field) > StringLength {\n\t\t\t\t\tfield = field[0:StringLength]\n\t\t\t\t}\n\t\t\t\tnewFields = append(newFields, StringField{field})\n\t\t\t}\n\t\t}\n\t\tnewT := Tuple{*f.Descriptor(), newFields, nil}\n\t\ttid := NewTID()\n\t\tbp := f.bufPool\n\t\tf.insertTuple(&newT, tid)\n\n\t\t// Force dirty pages to disk. CommitTransaction may not be implemented\n\t\t// yet if this is called in lab 1 or 2.\n\t\tbp.FlushAllPages()\n\n\t}\n\treturn nil\n}\n\n// Read the specified page number from the HeapFile on disk. This method is\n// called by the [BufferPool.GetPage] method when it cannot find the page in its\n// cache.\n//\n// This method will need to open the file supplied to the constructor, seek to\n// the appropriate offset, read the bytes in, and construct a [heapPage] object,\n// using the [heapPage.initFromBuffer] method.\nfunc (f *HeapFile) readPage(pageNo int) (Page, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"readPage not implemented\")\n}\n\n// Add the tuple to the HeapFile. This method should search through pages in the\n// heap file, looking for empty slots and adding the tuple in the first empty\n// slot if finds.\n//\n// If none are found, it should create a new [heapPage] and insert the tuple\n// there, and write the heapPage to the end of the HeapFile (e.g., using the\n// [flushPage] method.)\n//\n// To iterate through pages, it should use the [BufferPool.GetPage method]\n// rather than directly reading pages itself. For lab 1, you do not need to\n// worry about concurrent transactions modifying the Page or HeapFile. We will\n// add support for concurrent modifications in lab 3.\n//\n// The page the tuple is inserted into should be marked as dirty.\nfunc (f *HeapFile) insertTuple(t *Tuple, tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"insertTuple not implemented\") //replace me\n}\n\n// Remove the provided tuple from the HeapFile.\n//\n// This method should use the [Tuple.Rid] field of t to determine which tuple to\n// remove. The Rid field should be set when the tuple is read using the\n// [Iterator] method, or is otherwise created (as in tests). Note that Rid is an\n// empty interface, so you can supply any object you wish. You will likely want\n// to identify the heap page and slot within the page that the tuple came from.\n//\n// The page the tuple is deleted from should be marked as dirty.\nfunc (f *HeapFile) deleteTuple(t *Tuple, tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"deleteTuple not implemented\") //replace me\n}\n\n// Method to force the specified page back to the backing file at the\n// appropriate location. This will be called by BufferPool when it wants to\n// evict a page. The Page object should store information about its offset on\n// disk (e.g., that it is the ith page in the heap file), so you can determine\n// where to write it back.\nfunc (f *HeapFile) flushPage(p Page) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"flushPage not implemented\") //replace me\n}\n\n// [Operator] descriptor method -- return the TupleDesc for this HeapFile\n// Supplied as argument to NewHeapFile.\nfunc (f *HeapFile) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn nil //replace me\n\n}\n\n// [Operator] iterator method\n// Return a function that iterates through the records in the heap file\n// Note that this method should read pages from the HeapFile using the\n// BufferPool method GetPage, rather than reading pages directly,\n// since the BufferPool caches pages and manages page-level locking state for\n// transactions\n// You should esnure that Tuples returned by this method have their Rid object\n// set appropriate so that [deleteTuple] will work (see additional comments there).\n// Make sure to set the returned tuple's TupleDescriptor to the TupleDescriptor of\n// the HeapFile. This allows it to correctly capture the table qualifier.\nfunc (f *HeapFile) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn func() (*Tuple, error) {\n\treturn nil, fmt.Errorf(\"heap_file.Iterator not implemented\")\n\t}, nil\n}\n\n// internal strucuture to use as key for a heap page\ntype heapHash struct {\n\tFileName string\n\tPageNo   int\n}\n\n// This method returns a key for a page to use in a map object, used by\n// BufferPool to determine if a page is cached or not.  We recommend using a\n// heapHash struct as the key for a page, although you can use any struct that\n// does not contain a slice or a map that uniquely identifies the page.\nfunc (f *HeapFile) pageKey(pgNo int) any {\n\t// TODO: some code goes here\n\treturn nil\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "heap_file_test.go",
                "code_path": "godb/heap_file_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/heap_file_test.go",
                "code_content": "package godb\n\nimport (\n\t\"os\"\n\t\"testing\"\n)\n\nconst TestingFile string = \"test.dat\"\nconst TestingFile2 string = \"test2.dat\"\n\nfunc makeTestFile(t *testing.T, bufferPoolSize int) (*BufferPool, *HeapFile) {\n\tos.Remove(TestingFile)\n\n\tbp, c, err := MakeTestDatabase(bufferPoolSize, \"catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttd, _, _ := makeTupleTestVars()\n\ttbl, err := c.addTable(\"test\", td)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\treturn bp, tbl.(*HeapFile)\n}\n\nfunc makeTestVars(t *testing.T) (TupleDesc, Tuple, Tuple, *HeapFile, *BufferPool, TransactionID) {\n\tbp, hf := makeTestFile(t, 3)\n\ttd, t1, t2 := makeTupleTestVars()\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\treturn td, t1, t2, hf, bp, tid\n}\n\nfunc TestHeapFileCreateAndInsert(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\n\thf.insertTuple(&t2, tid)\n\titer, err := hf.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ti := 0\n\tfor {\n\t\ttup, err := iter()\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\ti = i + 1\n\t}\n\tif i != 2 {\n\t\tt.Fatalf(\"HeapFile iterator expected 2 tuples, got %d\", i)\n\t}\n}\n\nfunc TestHeapFileDelete(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\terr = hf.deleteTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer, err := hf.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tt3, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif t3 == nil {\n\t\tt.Fatalf(\"HeapFile iterator expected 1 tuple\")\n\t}\n\n\terr = hf.deleteTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer, err = hf.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tt3, err = iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tif t3 != nil {\n\t\tt.Fatalf(\"HeapFile iterator expected 0 tuple\")\n\t}\n}\n\nfunc testSerializeN(t *testing.T, n int) {\n\tbp, hf := makeTestFile(t, max(1, n/50))\n\t_, t1, t2 := makeTupleTestVars()\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\tfor i := 0; i < n; i++ {\n\t\tif err := hf.insertTuple(&t1, tid); err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\n\t\tif err := hf.insertTuple(&t2, tid); err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t}\n\tbp.CommitTransaction(tid)\n\tbp.FlushAllPages()\n\n\tbp2, catalog, err := MakeTestDatabase(1, \"catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\thf2, err := catalog.addTable(\"test\", *hf.Descriptor())\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttid = NewTID()\n\tbp2.BeginTransaction(tid)\n\n\titer, err := hf2.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ti := 0\n\tfor tup, err := iter(); tup != nil; tup, err = iter() {\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t\ti = i + 1\n\t}\n\tif i != 2*n {\n\t\tt.Fatalf(\"HeapFile iterator expected %d tuples, got %d\", 2*n, i)\n\t}\n\n}\nfunc TestHeapFileSerializeSmall(t *testing.T) {\n\ttestSerializeN(t, 2)\n}\n\nfunc TestHeapFileSerializeLarge(t *testing.T) {\n\ttestSerializeN(t, 2000)\n}\n\nfunc TestHeapFileSerializeVeryLarge(t *testing.T) {\n\ttestSerializeN(t, 4000)\n}\n\nfunc TestHeapFileLoadCSV(t *testing.T) {\n\t_, _, _, hf, _, tid := makeTestVars(t)\n\tf, err := os.Open(\"test_heap_file.csv\")\n\tif err != nil {\n\t\tt.Fatalf(\"Couldn't open test_heap_file.csv\")\n\t}\n\terr = hf.LoadFromCSV(f, true, \",\", false)\n\tif err != nil {\n\t\tt.Fatalf(\"Load failed, %s\", err)\n\t}\n\t//should have 384 records\n\titer, _ := hf.Iterator(tid)\n\ti := 0\n\tfor {\n\t\tt, _ := iter()\n\t\tif t == nil {\n\t\t\tbreak\n\t\t}\n\t\ti = i + 1\n\t}\n\tif i != 384 {\n\t\tt.Fatalf(\"HeapFile iterator expected 384 tuples, got %d\", i)\n\t}\n}\n\nfunc TestHeapFilePageKey(t *testing.T) {\n\ttd, t1, _, hf, bp, tid := makeTestVars(t)\n\n\tos.Remove(TestingFile2)\n\thf2, err := NewHeapFile(TestingFile2, &td, bp)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tfor hf.NumPages() < 2 {\n\t\terr = hf.insertTuple(&t1, tid)\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\n\t\terr = hf2.insertTuple(&t1, tid)\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\n\t\tif hf.NumPages() == 0 {\n\t\t\tt.Fatalf(\"Heap file should have at least one page after insertion.\")\n\t\t}\n\n\t\tbp.FlushAllPages()\n\t}\n\n\tif hf.NumPages() != hf2.NumPages() || hf.NumPages() != 2 {\n\t\tt.Fatalf(\"Should be two pages here\")\n\t}\n\n\tfor i := 0; i < hf.NumPages(); i++ {\n\t\tif hf.pageKey(i) != hf.pageKey(i) {\n\t\t\tt.Fatalf(\"Expected equal pageKey\")\n\t\t}\n\t\tif hf.pageKey(i) == hf.pageKey((i+1)%hf.NumPages()) {\n\t\t\tt.Fatalf(\"Expected non-equal pageKey for different pages\")\n\t\t}\n\t\tif hf.pageKey(i) == hf2.pageKey(i) {\n\t\t\tt.Fatalf(\"Expected non-equal pageKey for different heapfiles\")\n\t\t}\n\t}\n}\n\nfunc TestHeapFileSize(t *testing.T) {\n\t_, t1, _, hf, bp, _ := makeTestVars(t)\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf.insertTuple(&t1, tid)\n\tpage, err := bp.GetPage(hf, 0, tid, ReadPerm)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error, getPage, %s\", err.Error())\n\t}\n\thf.flushPage(page)\n\tinfo, err := os.Stat(TestingFile)\n\tif err != nil {\n\t\tt.Fatalf(\"unexpected error, stat, %s\", err.Error())\n\t}\n\tif info.Size() != int64(PageSize) {\n\t\tt.Fatalf(\"heap file page is not %d bytes;  NOTE:  This error may be OK, but many implementations that don't write full pages break.\", PageSize)\n\t}\n}\n\nfunc TestHeapFileSetDirty(t *testing.T) {\n\tif os.Getenv(\"LAB\") == \"5\" {\n\t\tt.Skip(\"This test is only valid up to Lab 4. Skipping\")\n\t}\n\n\t_, t1, _, hf, bp, tid := makeTestVars(t)\n\tfor i := 0; i < 308; i++ {\n\t\terr := hf.insertTuple(&t1, tid)\n\t\tif err != nil && (i == 306 || i == 307) {\n\t\t\treturn\n\t\t} else if err != nil {\n\t\t\tt.Fatalf(\"%v\", err)\n\t\t}\n\t}\n\tbp.CommitTransaction(tid)\n\tt.Fatalf(\"Expected error due to all pages in BufferPool being dirty\")\n}\n\nfunc TestHeapFileDirtyBit(t *testing.T) {\n\t_, t1, _, hf, bp, _ := makeTestVars(t)\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t1, tid)\n\tpage, _ := bp.GetPage(hf, 0, tid, ReadPerm)\n\tif !page.isDirty() {\n\t\tt.Fatalf(\"Expected page to be dirty\")\n\t}\n}\n\nfunc TestHeapFileIteratorExtra(t *testing.T) {\n\t_, t1, _, hf, bp, _ := makeTestVars(t)\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\n\tit, err := hf.Iterator(tid)\n\t_, err = it()\n\tif err != nil {\n\t\tt.Fatalf(\"Empty heap file iterator should return nil,nil\")\n\t}\n\thf.insertTuple(&t1, tid)\n\tit, err = hf.Iterator(tid)\n\tpg, err := it()\n\tif err != nil {\n\t\tt.Fatalf(\"Iterating over heap file with one tuple returned error %s\", err.Error())\n\t}\n\tif pg == nil {\n\t\tt.Fatalf(\"Should have gotten 1 page in heap file iterator\")\n\t}\n\tpg, err = it()\n\tif pg != nil {\n\t\tt.Fatalf(\"More than 1 page in heap file iterator!\")\n\t}\n\tif err != nil {\n\t\tt.Fatalf(\"Iterator returned error at end, expected nil, nil, got nil, %s\", err.Error())\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test heap_file_test.go"
        ]
    },
    {
        "instance_id": 5,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 1: GoDB",
        "part_name": "2.6. A simple query",
        "exercise": "Exercise 5",
        "introduction": "## 2. GoDB Architecture and Implementation Guide\n\nGoDB consists of:\n\n* Structures that represent fields, tuples, and tuple schemas;\n* Methods that apply predicates and conditions to tuples;\n* One or more access methods (e.g., heap files) that store relations on disk and\n  provide a way to iterate through tuples of those relations;\n* A collection of operator classes (e.g., select, join, insert, delete, etc.)\n  that process tuples;\n* A buffer pool that caches active tuples and pages in memory and handles\n  concurrency control and transactions (neither of which you need to worry about\n  for this lab); and,\n* A catalog that stores information about available tables and their schemas.\n\nGoDB does not include many things that you may think of as being a part of a\n\"database system.\" In particular, GoDB does not have:\n\n* (In this lab), a SQL front end or parser that allows you to type queries\n  directly into GoDB. Instead, queries are built up by chaining a set of\n  operators together into a hand-built query plan (see [Section\n  2.6](#query_walkthrough)). We will provide a simple parser for use in later\n  labs.\n* Views.\n* Data types except integers and fixed length strings.\n* (In this lab) Query optimizer.\n* (In this lab) Indices.\n\nIn the rest of this Section, we describe each of the main components of GoDB\nthat you will need to implement in this lab. You should use the exercises in\nthis discussion to guide your implementation. This document is by no means a\ncomplete specification for GoDB; you will need to make decisions about how\nto design and implement various parts of the system. Note that for Lab 1 you do\nnot need to implement any operators (e.g., select, join, project) except\nsequential scan as a part of the `heap_file.go` file.\nYou will add support for additional operators in future labs.",
        "Description": "### 2.6. A simple query\n\nIn the next lab, you will implement \"Operators\" that will allow you to run actual SQL queries against GoDB.  For the final test in this lab, we ask you to implement a simple query in go logic.  This method takes the name of a CSV file and a `TupleDesc` and a field name and return the sum of the supplied field name.  You can use the `HeapFile.LoadFromCSV` method to load the CSV file, and the `findFieldInTd` method\nto find the field number in the `TupleDesc`, if it exists.\n\n### Exercise 5\n\n**Implement the skeleton method in:**\n\n---\n* lab1_query.go\n---\n\nWe have supplied a simple test case for you for this method in `lab1_query_test.go`, although we will also test it with other files to confirm your implementation is working.",
        "repo/location": "go get main\ncd godb\ngo get ../godb\ngo test",
        "dependency": [],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab1.md",
        "codes": [
            {
                "code_path": "godb/lab1_query.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/lab1_query.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n)\n\n/*\ncomputeFieldSum should (1) load the csv file named fileName into a heap file\n(see [HeapFile.LoadFromCSV]), (2) compute the sum of the integer field named\nsumField string and, (3) return its value as an int.\n\nThe supplied csv file is comma delimited and has a header.\n\nIf the file doesn't exist, can't be opened, the field doesn't exist, or the\nfield is not an integer, you should return an error.\n\nNote that when you create a HeapFile, you will need to supply a file name;\nyou can supply a non-existent file, in which case it will be created.\nHowever, subsequent invocations of this method will result in tuples being\nreinserted into this file unless you delete (e.g., with [os.Remove] it before\ncalling NewHeapFile.\n\nNote that you should NOT pass fileName into NewHeapFile -- fileName is a CSV\nfile that you should call LoadFromCSV on.\n*/\nfunc computeFieldSum(bp *BufferPool, fileName string, td TupleDesc, sumField string) (int, error) {\n\treturn 0, fmt.Errorf(\"computeFieldSum not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "lab1_query_test.go",
                "code_path": "godb/lab1_query_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/lab1_query_test.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n)\n\nfunc TestLab1Query(t *testing.T) {\n\tif os.Getenv(\"LAB\") == \"5\" {\n\t\tt.Skip(\"This test is only valid up to Lab 4. Skipping\")\n\t}\n\tbp, _, err := MakeTestDatabase(10, \"catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to initialize test database\")\n\t}\n\tf1 := FieldType{\"name\", \"\", StringType}\n\tf2 := FieldType{\"age\", \"\", IntType}\n\ttd := TupleDesc{[]FieldType{f1, f2}}\n\tsum, err := computeFieldSum(bp, \"lab1_test.csv\", td, \"age\")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\tif sum != 1111 {\n\t\tt.Fatalf(\"expected sum of 1111, got %d\", sum)\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test lab1_query_test.go"
        ]
    },
    {
        "instance_id": 6,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.1. Filter and Join",
        "exercise": "Exercise 1",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.1. Filter and Join\n\nRecall that GoDB OpIterator classes implement the operations of the\nrelational algebra. You will now implement two operators that will enable you to\nperform queries that are slightly more interesting than a table scan.\n\n* *Filter*: This operator only returns tuples that satisfy a predicate that is\n  specified at construction.  Hence, it filters out any tuples that\n  do not match the predicate.\n\n* *Join*: This operator joins tuples from its two children according to an equality predicate that is specified at construction. Our current version of godb only supports joining with equality predicates `EqualityJoin`.\nWe only require\n  a simple nested loop join, but you may explore more interesting join\n  implementations. In particular, we will give a small amount of extra credit to those satisfying a stricter time-out requirement. Describe your implementation in your lab writeup.\n\nFor both of these operators, we have given you constructors so that you don't have to deal with the complexities of Go generics\nand constructors for both integer and string fields.  You will need to implement the `Descriptor()` and `Iterator()` methods.\n\nNote that both filters and joins take `Expr` objects that, in the case of joins or the left side of a filter, extract the field to be compared, or in the case of the right side of a filter, evaluate to a constant value.  We saw expressions in lab 1, but as a reminder, \nthe idea here is that either side of a predicate can be an arbitrary arithmetic expression, e.g. a join expression can be:\n\n`(t1.x + 7) = (t2.y * 4)`\n\nTo handle this, you will need to evaluate\nthe expression over the tuple and then use the  `getter` function to extract the value.\nHere the getter takes a `DBValue` type and extracts either an `int64` or a `string`, depending\non the type of the filter or join (this way, you don't need to have different Iterator() implementations\nfor different types.)\nFor example, for the right field of the `joinOp` of type in the EqualityJoin's `Iterator()` implementation, you can get\nthe value for the right side of the join using:\n\n```\nv, _ := joinOp.rightField.EvalExpr(curT)\nrightFieldVal := joinOp.getter(v)\n```\n\n**Exercise 1.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/filter_op.go\n* godb/join_op.go\n\n------\n\nNote that the implementation of `Iterator()`, particularly for join, is a bit tricky because your iterator will have to store the current progress of the iterator after returning each tuple.  You had to deal with this a bit in your heap file iterator in lab 1, but it is more complicated here.  Your implementation should not pre-compute the entire join or filter result;  instead, it should resume iterating through the child operator(s) at the point it left off after returning the previous tuple.\n\nRecall that the result of a call to an `Iterator()` is a function that does the iteration and that this function can \"capture\" variables that are defined in the outer portion of the iterator.  To understand this, it may be helpful to look at the discussion of iterators and closures in lab 1, or review code such as [this example](https://go.dev/tour/moretypes/25).  Note that in this example, the `adder()`\nfunction returns a function that captures a unique value of `sum` for each invocation of `adder()` -- so the to `adder` objects in `main()` will operate on different `sum` objects.  Your `Iterator()` implementation will want to capture the state of the iterator (how far it has iterated through the child iterators) outside of the function you return in a similar way.\n\nAt this point, your code should pass the unit tests in `filter_op_test.go` and the test `TestJoin` in `join_op_test.go`. You do not need to pass the test `TestBigJoinOptional` (this test will timeout and fail internally after 10 seconds).",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/filter_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/filter_op.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\ntype Filter struct {\n\top    BoolOp\n\tleft  Expr\n\tright Expr\n\tchild Operator\n}\n\n// Construct a filter operator on ints.\nfunc NewFilter(constExpr Expr, op BoolOp, field Expr, child Operator) (*Filter, error) {\n\treturn &Filter{op, field, constExpr, child}, nil\n}\n\n// Return a TupleDescriptor for this filter op.\nfunc (f *Filter) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\n// Filter operator implementation. This function should iterate over the results\n// of the child iterator and return a tuple if it satisfies the predicate.\n//\n// HINT: you can use [types.evalPred] to compare two values.\nfunc (f *Filter) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"Filter.Iterator not implemented\") // replace me\n}\n"
            },
            {
                "code_path": "godb/join_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/join_op.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\ntype EqualityJoin struct {\n\t// Expressions that when applied to tuples from the left or right operators,\n\t// respectively, return the value of the left or right side of the join\n\tleftField, rightField Expr\n\n\tleft, right *Operator // Operators for the two inputs of the join\n\n\t// The maximum number of records of intermediate state that the join should\n\t// use (only required for optional exercise).\n\tmaxBufferSize int\n}\n\n// Constructor for a join of integer expressions.\n//\n// Returns an error if either the left or right expression is not an integer.\nfunc NewJoin(left Operator, leftField Expr, right Operator, rightField Expr, maxBufferSize int) (*EqualityJoin, error) {\n\treturn &EqualityJoin{leftField, rightField, &left, &right, maxBufferSize}, nil\n}\n\n// Return a TupleDesc for this join. The returned descriptor should contain the\n// union of the fields in the descriptors of the left and right operators.\n//\n// HINT: use [TupleDesc.merge].\nfunc (hj *EqualityJoin) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\n// Join operator implementation. This function should iterate over the results\n// of the join. The join should be the result of joining joinOp.left and\n// joinOp.right, applying the joinOp.leftField and joinOp.rightField expressions\n// to the tuples of the left and right iterators respectively, and joining them\n// using an equality predicate.\n//\n// HINT: When implementing the simple nested loop join, you should keep in mind\n// that you only iterate through the left iterator once (outer loop) but iterate\n// through the right iterator once for every tuple in the left iterator (inner\n// loop).\n//\n// HINT: You can use [Tuple.joinTuples] to join two tuples.\n//\n// OPTIONAL EXERCISE: the operator implementation should not use more than\n// maxBufferSize records, and should pass the testBigJoin test without timing\n// out. To pass this test, you will need to use something other than a nested\n// loops join.\nfunc (joinOp *EqualityJoin) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"EqualityJoin.Iterator not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "filter_op_test.go",
                "code_path": "godb/filter_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/filter_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n)\n\n// This function is for _testing only_!  It is not part of the godb API.\nfunc insertTupleForTest(t *testing.T, hf DBFile, tup *Tuple, tid TransactionID) {\n\tt.Helper()\n\terr := hf.insertTuple(tup, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n}\n\nfunc TestFilterInt(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\n\tinsertTupleForTest(t, hf, &t1, tid)\n\tinsertTupleForTest(t, hf, &t2, tid)\n\n\tvar f FieldType = FieldType{\"age\", \"\", IntType}\n\tfilt, err := NewFilter(&ConstExpr{IntField{25}, IntType}, OpGt, &FieldExpr{f}, hf)\n\tif err != nil {\n\t\tt.Errorf(err.Error())\n\t}\n\titer, err := filt.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\n\tcnt := 0\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tt.Logf(\"filter passed tup %d: %v\\n\", cnt, tup)\n\t\tcnt++\n\t}\n\tif cnt != 1 {\n\t\tt.Errorf(\"unexpected number of results\")\n\t}\n}\n\nfunc TestFilterString(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\tinsertTupleForTest(t, hf, &t1, tid)\n\tinsertTupleForTest(t, hf, &t2, tid)\n\tvar f FieldType = FieldType{\"name\", \"\", StringType}\n\tfilt, err := NewFilter(&ConstExpr{StringField{\"sam\"}, StringType}, OpEq, &FieldExpr{f}, hf)\n\tif err != nil {\n\t\tt.Errorf(err.Error())\n\t}\n\titer, err := filt.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\n\tcnt := 0\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tt.Logf(\"filter passed tup %d: %v\\n\", cnt, tup)\n\t\tcnt++\n\t}\n\tif cnt != 1 {\n\t\tt.Errorf(\"unexpected number of results\")\n\t}\n}\n"
            },
            {
                "code_name": "join_op_test.go",
                "code_path": "godb/join_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/join_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n)\n\nconst JoinTestFile string = \"JoinTestFile.dat\"\n\nfunc TestJoin(t *testing.T) {\n\ttd, t1, t2, hf, bp, tid := makeTestVars(t)\n\tinsertTupleForTest(t, hf, &t1, tid)\n\tinsertTupleForTest(t, hf, &t2, tid)\n\tinsertTupleForTest(t, hf, &t2, tid)\n\n\tos.Remove(JoinTestFile)\n\thf2, _ := NewHeapFile(JoinTestFile, &td, bp)\n\tinsertTupleForTest(t, hf2, &t1, tid)\n\tinsertTupleForTest(t, hf2, &t2, tid)\n\tinsertTupleForTest(t, hf2, &t2, tid)\n\n\toutT1 := joinTuples(&t1, &t1)\n\toutT2 := joinTuples(&t2, &t2)\n\n\tleftField := FieldExpr{td.Fields[1]}\n\tjoin, err := NewJoin(hf, &leftField, hf2, &leftField, 100)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error initializing join\")\n\t\treturn\n\t}\n\titer, err := join.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\tcnt := 0\n\tcntOut1 := 0\n\tcntOut2 := 0\n\tfor {\n\t\tt, _ := iter()\n\t\tif t == nil {\n\t\t\tbreak\n\t\t}\n\t\tif t.equals(outT1) {\n\t\t\tcntOut1++\n\t\t} else if t.equals(outT2) {\n\t\t\tcntOut2++\n\t\t}\n\t\t//fmt.Printf(\"got tuple %v: %v\\n\", cnt, t)\n\t\tcnt++\n\t}\n\tif cnt != 5 {\n\t\tt.Errorf(\"unexpected number of join results (%d, expected 5)\", cnt)\n\t}\n\tif cntOut1 != 1 {\n\t\tt.Errorf(\"unexpected number of t1 results (%d, expected 1)\", cntOut1)\n\t}\n\tif cntOut2 != 4 {\n\t\tt.Errorf(\"unexpected number of t2 results (%d, expected 4)\", cntOut2)\n\t}\n\n}\n\nconst BigJoinFile1 string = \"jointest1.dat\"\nconst BigJoinFile2 string = \"jointest2.dat\"\n\n//This test joins two large heap files (each containing ntups tuples). A simple\n//nested loops join will take a LONG time to complete this join, so we've added\n//a timeout that will cause the join to fail after 10 seconds.\n//\n//Note that this test is optional;  passing it will give extra credit, as\n//describe in the lab 2 assignment.\n\nfunc TestJoinBigOptional(t *testing.T) {\n\ttimeout := time.After(20 * time.Second)\n\n\tdone := make(chan bool)\n\n\tgo func() {\n\t\tfail := func(err error) {\n\t\t\tdone <- true\n\t\t\tt.Errorf(err.Error())\n\t\t}\n\t\tntups := 314159\n\n\t\tif err := os.Remove(BigJoinFile1); err != nil && !os.IsNotExist(err) {\n\t\t\tfail(fmt.Errorf(\"removing file1: %w\", err))\n\t\t\treturn\n\t\t}\n\t\tif err := os.Remove(BigJoinFile2); err != nil && !os.IsNotExist(err) {\n\t\t\tfail(fmt.Errorf(\"removing file2: %w\", err))\n\t\t}\n\n\t\tbp, c, err := MakeTestDatabase(100, \"big_join_catalog.txt\")\n\t\tif err != nil {\n\t\t\tfail(fmt.Errorf(\"making database: %w\", err))\n\t\t\treturn\n\t\t}\n\n\t\thf1, err := c.GetTable(\"jointest1\")\n\t\tif err != nil {\n\t\t\tfail(fmt.Errorf(\"getting jointest1: %w\", err))\n\t\t\treturn\n\t\t}\n\t\thf2, err := c.GetTable(\"jointest2\")\n\t\tif err != nil {\n\t\t\tfail(fmt.Errorf(\"getting jointest2: %w\", err))\n\t\t\treturn\n\t\t}\n\n\t\ttid := NewTID()\n\t\tbp.BeginTransaction(tid)\n\t\tfor i := 0; i < ntups; i++ {\n\n\t\t\tif i > 0 && i%5000 == 0 {\n\t\t\t\tbp.FlushAllPages()\n\t\t\t\t// commit transaction\n\t\t\t\tbp.CommitTransaction(tid)\n\n\t\t\t\ttid = NewTID()\n\t\t\t\tbp.BeginTransaction(tid)\n\t\t\t}\n\n\t\t\ttup := Tuple{*hf1.Descriptor(), []DBValue{IntField{int64(i)}}, nil}\n\t\t\terr := hf1.insertTuple(&tup, tid)\n\t\t\tif err != nil {\n\t\t\t\tfail(fmt.Errorf(\"inserting tuple1: %w\", err))\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\terr = hf2.insertTuple(&tup, tid)\n\t\t\tif err != nil {\n\t\t\t\tfail(fmt.Errorf(\"inserting tuple2: %w\", err))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tbp.CommitTransaction(tid)\n\n\t\ttid = NewTID()\n\t\tbp.BeginTransaction(tid)\n\t\tleftField := FieldExpr{hf1.Descriptor().Fields[0]}\n\t\tjoin, err := NewJoin(hf1, &leftField, hf2, &leftField, 100000)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"unexpected error initializing join\")\n\t\t\tdone <- true\n\t\t\treturn\n\t\t}\n\t\titer, err := join.Iterator(tid)\n\t\tif err != nil {\n\t\t\tfail(err)\n\t\t\treturn\n\t\t}\n\n\t\tif iter == nil {\n\t\t\tt.Errorf(\"iter was nil\")\n\t\t\tdone <- true\n\t\t\treturn\n\t\t}\n\t\tcnt := 0\n\t\tfor {\n\t\t\ttup, err := iter()\n\t\t\tif err != nil {\n\t\t\t\tfail(err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif tup == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcnt++\n\t\t}\n\t\tif cnt != ntups {\n\t\t\tt.Errorf(\"unexpected number of join results (%d, expected %d)\", cnt, ntups)\n\t\t}\n\t\tdone <- true\n\t}()\n\n\tselect {\n\tcase <-timeout:\n\t\tt.Fatal(\"Test didn't finish in time\")\n\tcase <-done:\n\t}\n}\n\nfunc makeJoinOrderingVars(t *testing.T) (*HeapFile, *HeapFile, Tuple, Tuple, *BufferPool) {\n\tvar td1 = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"a\", Ftype: StringType},\n\t\t{Fname: \"b\", Ftype: IntType},\n\t}}\n\tvar td2 = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"c\", Ftype: StringType},\n\t\t{Fname: \"d\", Ftype: IntType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc: td1,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tvar t2 = Tuple{\n\t\tDesc: td2,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"george jones\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tbp, err := NewBufferPool(3)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tos.Remove(TestingFile)\n\thf1, err := NewHeapFile(TestingFile, &td1, bp)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tos.Remove(TestingFile2)\n\thf2, err := NewHeapFile(TestingFile2, &td2, bp)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\treturn hf1, hf2, t1, t2, bp\n}\n\nfunc TestJoinFieldOrder(t *testing.T) {\n\tbp, c, err := MakeTestDatabase(3, \"join_test_catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\thf1, err := c.GetTable(\"test\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\thf2, err := c.GetTable(\"test2\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tvar t1 = Tuple{\n\t\tDesc: *hf1.Descriptor(),\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\tvar t2 = Tuple{\n\t\tDesc: *hf2.Descriptor(),\n\t\tFields: []DBValue{\n\t\t\tStringField{\"george jones\"},\n\t\t\tIntField{25},\n\t\t}}\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\n\tinsertTupleForTest(t, hf1, &t1, tid)\n\tinsertTupleForTest(t, hf2, &t2, tid)\n\n\tleftField := FieldExpr{t1.Desc.Fields[1]}\n\trightField := FieldExpr{t2.Desc.Fields[1]}\n\n\tjoin, err := NewJoin(hf1, &leftField, hf2, &rightField, 100)\n\tif err != nil {\n\t\tt.Errorf(\"unexpected error initializing join\")\n\t\treturn\n\t}\n\titer, err := join.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\n\tvar tdExpected = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"a\", Ftype: StringType},\n\t\t{Fname: \"b\", Ftype: IntType},\n\t\t{Fname: \"c\", Ftype: StringType},\n\t\t{Fname: \"d\", Ftype: IntType},\n\t}}\n\n\ttj, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tif !tdExpected.equals(&tj.Desc) {\n\t\tt.Fatalf(\"Unexpected descriptor of joined tuple\")\n\t}\n}\n\nfunc TestJoinTupleNil(t *testing.T) {\n\t_, t1, t2, _, _, _ := makeTestVars(t)\n\ttNew := joinTuples(&t1, nil)\n\tif !tNew.equals(&t1) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n\ttNew2 := joinTuples(nil, &t2)\n\tif !tNew2.equals(&t2) {\n\t\tt.Fatalf(\"Unexpected output of joinTuple with nil\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test filter_op_test.go",
            "go test join_op_test.go"
        ]
    },
    {
        "instance_id": 7,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.2. Aggregates",
        "exercise": "Exercise 2",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.2. Aggregates\n\nThe aggregate operator implements basic SQL aggregates with a `GROUP BY` clause. You will need to implement the five SQL aggregates (`COUNT`, `SUM`, `AVG`,\n`MIN`, `MAX`) and support grouping over zero or more fields.\n\nIn order to calculate aggregates, we use an `AggState` interface, which merges\na new tuple into the existing calculation of an aggregate. The `AggState` is\ntold during construction what operation it should use for aggregation.\nSubsequently, the client code should call `AggState.addTuple()` for\nevery tuple in the child iterator. After all tuples have been merged, the client\ncan retrieve an iterator of aggregation results. Each tuple in the result is a\npair of the form `(groupValue, aggregateValue)` unless the value of the group\nby field was `Aggregator.groupByFields = nil`, in which case the result is a single\ntuple of the form `(aggregateValue)`.\n\nNote that this implementation requires space linear in the number of distinct\ngroups. For the purposes of this lab, you do not need to worry about the\nsituation where the number of groups exceeds available memory.\n\nSimilar to Exercise 1, we have provided the construction methods and fields for the `Aggregator` operator so that you only have to worry about the `Descriptor()` and `Iterator()` methods. \n\nNotice that in the fields of the `Aggregator` operator, `groupByFields` is an array of `Expr` objects. This is to support grouping by more than one `Expr`. Analogously, `newAggState` being an array of `AggState` is to support multiple aggregations per group at the same time (think `SELECT MAX(salary), AVG(salary), MIN(salary) FROM employees GROUP BY office_location;`).\n\nAs for `AggState`, the purpose is to maintain some running value for the aggregation operation (one of `COUNT`, `SUM`, `AVG`,\n`MIN`, or `MAX`) when you go through the child iterators. For example, for the `SUM` operator, you will probably want to maintain some number representing the running sum up to the current tuple. Every aggregation operation needs to implement the interface methods: `Init`, `Copy`, `AddTuple`, `Finalize`, and `GetTupleDesc`. In general, we `Init`-ialize the aggregation state at the beginning, `AddTuple` of all relevant child tuples, and then call `Finalize` at the end to retrieve the aggregation results. This intuition should hint at how to implement the five aggregation operations and which fields to maintain. Furthermore, we have provided our implementation of the `COUNT` aggregation state, which may help you understand how some methods work. You will need to complete the implementation of other aggregation states.\n\n\n**Exercise 2.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/agg_state.go\n* godb/agg_op.go\n\n------\n\nAgain, for implementing the `Iterator()` method, you will want to make use of the \"capture\" functionality to store internal states such as how many result tuples have been iterated through. The logic of one possible implementation, of which we have provided a skeleton code, is as follows: on the first iterator call, firstly, we iterate through all the child tuples to collect aggregation results of all groups. Then, we create a `finalizedIter` iterator for iterating through the results of each group. Subsequent calls to the function will then simply be all redirected to `finalizedIter`. Our implementation uses three helper functions which you will have to implement: `extractGroupByKeyTuple` (given a tuple `t` from a child, return a tuple that identifies `t`'s group;  this tuple may contain multiple fields, one per group by attribute), `addTupleToGrpAggState` (given a tuple `t` from child and a pointer to an array of AggState `grpAggState`, add `t` into all aggregation states in the array), and `getFinalizedTuplesIterator` (given that all child tuples have been added, create an iterator that iterates through the finalized aggregate result of each group). We also handled the no group-by case for you, so you can assume there's always grouping when these helper functions are called. If you prefer, you may implement `Iterator()` in some other way that doesn't use our overall skeleton; we don't test the three helper methods, only the overall `Iterator()` method.\n\nAt this point, your code should pass the unit tests in `agg_op_test.go`.",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/agg_state.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/agg_state.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\n// interface for an aggregation state\ntype AggState interface {\n\t// Initializes an aggregation state. Is supplied with an alias, an expr to\n\t// evaluate an input tuple into a DBValue, and a getter to extract from the\n\t// DBValue its int or string field's value.\n\tInit(alias string, expr Expr) error\n\n\t// Makes an copy of the aggregation state.\n\tCopy() AggState\n\n\t// Adds an tuple to the aggregation state.\n\tAddTuple(*Tuple)\n\n\t// Returns the final result of the aggregation as a tuple.\n\tFinalize() *Tuple\n\n\t// Gets the tuple description of the tuple that Finalize() returns.\n\tGetTupleDesc() *TupleDesc\n}\n\n// Implements the aggregation state for COUNT\n// We are supplying the implementation of CountAggState as an example. You need to\n// implement the rest of the aggregation states.\ntype CountAggState struct {\n\talias string\n\texpr  Expr\n\tcount int\n}\n\nfunc (a *CountAggState) Copy() AggState {\n\treturn &CountAggState{a.alias, a.expr, a.count}\n}\n\nfunc (a *CountAggState) Init(alias string, expr Expr) error {\n\ta.count = 0\n\ta.expr = expr\n\ta.alias = alias\n\treturn nil\n}\n\nfunc (a *CountAggState) AddTuple(t *Tuple) {\n\ta.count++\n}\n\nfunc (a *CountAggState) Finalize() *Tuple {\n\ttd := a.GetTupleDesc()\n\tf := IntField{int64(a.count)}\n\tfs := []DBValue{f}\n\tt := Tuple{*td, fs, nil}\n\treturn &t\n}\n\nfunc (a *CountAggState) GetTupleDesc() *TupleDesc {\n\tft := FieldType{a.alias, \"\", IntType}\n\tfts := []FieldType{ft}\n\ttd := TupleDesc{}\n\ttd.Fields = fts\n\treturn &td\n}\n\n// Implements the aggregation state for SUM\ntype SumAggState struct {\n\t// TODO: some code goes here\n}\n\nfunc (a *SumAggState) Copy() AggState {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc intAggGetter(v DBValue) any {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc stringAggGetter(v DBValue) any {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc (a *SumAggState) Init(alias string, expr Expr) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"SumAggState.Init not implemented\") // replace me\n}\n\nfunc (a *SumAggState) AddTuple(t *Tuple) {\n\t// TODO: some code goes here\n}\n\nfunc (a *SumAggState) GetTupleDesc() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\nfunc (a *SumAggState) Finalize() *Tuple {\n\t// TODO: some code goes here\n\treturn &Tuple{} // replace me\n}\n\n// Implements the aggregation state for AVG\n// Note that we always AddTuple() at least once before Finalize()\n// so no worries for divide-by-zero\ntype AvgAggState struct {\n\t// TODO: some code goes here\n}\n\nfunc (a *AvgAggState) Copy() AggState {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc (a *AvgAggState) Init(alias string, expr Expr) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"AvgAggState.Init not implemented\") // replace me\n}\n\nfunc (a *AvgAggState) AddTuple(t *Tuple) {\n\t// TODO: some code goes here\n}\n\nfunc (a *AvgAggState) GetTupleDesc() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\nfunc (a *AvgAggState) Finalize() *Tuple {\n\t// TODO: some code goes here\n\treturn &Tuple{} // replace me\n}\n\n// Implements the aggregation state for MAX\n// Note that we always AddTuple() at least once before Finalize()\n// so no worries for NaN max\ntype MaxAggState struct {\n\t// TODO: some code goes here\n}\n\nfunc (a *MaxAggState) Copy() AggState {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc (a *MaxAggState) Init(alias string, expr Expr) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"MaxAggState.Init not implemented\") // replace me\n}\n\nfunc (a *MaxAggState) AddTuple(t *Tuple) {\n\t// TODO: some code goes here\n}\n\nfunc (a *MaxAggState) GetTupleDesc() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\nfunc (a *MaxAggState) Finalize() *Tuple {\n\t// TODO: some code goes here\n\treturn &Tuple{} // replace me\n}\n\n// Implements the aggregation state for MIN\n// Note that we always AddTuple() at least once before Finalize()\n// so no worries for NaN min\ntype MinAggState struct {\n\t// TODO: some code goes here\n}\n\nfunc (a *MinAggState) Copy() AggState {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\nfunc (a *MinAggState) Init(alias string, expr Expr) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"MinAggState.Init not implemented\") // replace me\n}\n\nfunc (a *MinAggState) AddTuple(t *Tuple) {\n\t// TODO: some code goes here\n}\n\nfunc (a *MinAggState) GetTupleDesc() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\nfunc (a *MinAggState) Finalize() *Tuple {\n\t// TODO: some code goes here\n\treturn &Tuple{} // replace me\n}\n"
            },
            {
                "code_path": "godb/agg_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/agg_op.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\ntype Aggregator struct {\n\t// Expressions that when applied to tuples from the child operators,\n\t// respectively, return the value of the group by key tuple\n\tgroupByFields []Expr\n\n\t// Aggregation states that serves as a template as to which types of\n\t// aggregations in which order are to be computed for every group.\n\tnewAggState []AggState\n\n\tchild Operator // the child operator for the inputs to aggregate\n}\n\ntype AggType int\n\nconst (\n\tIntAggregator    AggType = iota\n\tStringAggregator AggType = iota\n)\n\nconst DefaultGroup int = 0 // for handling the case of no group-by\n\n// Construct an aggregator with a group-by.\nfunc NewGroupedAggregator(emptyAggState []AggState, groupByFields []Expr, child Operator) *Aggregator {\n\treturn &Aggregator{groupByFields, emptyAggState, child}\n}\n\n// Construct an aggregator with no group-by.\nfunc NewAggregator(emptyAggState []AggState, child Operator) *Aggregator {\n\treturn &Aggregator{nil, emptyAggState, child}\n}\n\n// Return a TupleDescriptor for this aggregation.\n//\n// If the aggregator has no group-by, the returned descriptor should contain the\n// union of the fields in the descriptors of the aggregation states. If the\n// aggregator has a group-by, the returned descriptor will additionally start\n// with the group-by fields, and then the aggregation states descriptors like\n// that without group-by.\n//\n// HINT: for groupByFields, you can use [Expr.GetExprType] to get the FieldType.\n//\n// HINT: use [TupleDesc.merge] to merge the two [TupleDesc]s.\nfunc (a *Aggregator) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} //replace me\n}\n\n// Returns an iterator over the results of the aggregate. The aggregate should\n// be the result of aggregating each group's tuples and the iterator should\n// iterate through each group's result. In the case where there is no group-by,\n// the iterator simply iterates through only one tuple, representing the\n// aggregation of all child tuples.\nfunc (a *Aggregator) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// the child iterator\n\tchildIter, err := a.child.Iterator(tid)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif childIter == nil {\n\t\treturn nil, GoDBError{MalformedDataError, \"child iter unexpectedly nil\"}\n\t}\n\n\t// the map that stores the aggregation state of each group\n\taggState := make(map[any]*[]AggState)\n\tif a.groupByFields == nil {\n\t\tvar newAggState []AggState\n\t\tfor _, as := range a.newAggState {\n\t\t\tcopy := as.Copy()\n\t\t\tif copy == nil {\n\t\t\t\treturn nil, GoDBError{MalformedDataError, \"aggState Copy unexpectedly returned nil\"}\n\t\t\t}\n\t\t\tnewAggState = append(newAggState, copy)\n\t\t}\n\n\t\taggState[DefaultGroup] = &newAggState\n\t}\n\n\t// the list of group key tuples\n\tvar groupByList []*Tuple\n\t// the iterator for iterating thru the finalized aggregation results for each group\n\tvar finalizedIter func() (*Tuple, error)\n\n\treturn func() (*Tuple, error) {\n\t\t// iterates thru all child tuples\n\t\tfor t, err := childIter(); t != nil || err != nil; t, err = childIter() {\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif t == nil {\n\t\t\t\treturn nil, nil\n\t\t\t}\n\n\t\t\tif a.groupByFields == nil { // adds tuple to the aggregation in the case of no group-by\n\t\t\t\tfor i := 0; i < len(a.newAggState); i++ {\n\t\t\t\t\t(*aggState[DefaultGroup])[i].AddTuple(t)\n\t\t\t\t}\n\t\t\t} else { // adds tuple to the aggregation with grouping\n\t\t\t\tkeygenTup, err := extractGroupByKeyTuple(a, t)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\tkey := keygenTup.tupleKey()\n\t\t\t\tif aggState[key] == nil {\n\t\t\t\t\tasNew := make([]AggState, len(a.newAggState))\n\t\t\t\t\taggState[key] = &asNew\n\t\t\t\t\tgroupByList = append(groupByList, keygenTup)\n\t\t\t\t}\n\n\t\t\t\taddTupleToGrpAggState(a, t, aggState[key])\n\t\t\t}\n\t\t}\n\n\t\tif finalizedIter == nil { // builds the iterator for iterating thru the finalized aggregation results for each group\n\t\t\tif a.groupByFields == nil {\n\t\t\t\tvar tup *Tuple\n\t\t\t\tfor i := 0; i < len(a.newAggState); i++ {\n\t\t\t\t\tnewTup := (*aggState[DefaultGroup])[i].Finalize()\n\t\t\t\t\ttup = joinTuples(tup, newTup)\n\t\t\t\t}\n\t\t\t\tfinalizedIter = func() (*Tuple, error) { return nil, nil }\n\t\t\t\treturn tup, nil\n\t\t\t} else {\n\t\t\t\tfinalizedIter = getFinalizedTuplesIterator(a, groupByList, aggState)\n\t\t\t}\n\t\t}\n\t\treturn finalizedIter()\n\t}, nil\n}\n\n// Given a tuple t from a child iterator, return a tuple that identifies t's\n// group. The returned tuple should contain the fields from the groupByFields\n// list passed into the aggregator constructor. The ith field can be extracted\n// from the supplied tuple using the EvalExpr method on the ith expression of\n// groupByFields.\n//\n// If there is any error during expression evaluation, return the error.\nfunc extractGroupByKeyTuple(a *Aggregator, t *Tuple) (*Tuple, error) {\n\t// TODO: some code goes here\n\treturn &Tuple{}, fmt.Errorf(\"extractGroupByKeyTuple not implemented.\") // replace me\n}\n\n// Given a tuple t from child and (a pointer to) the array of partially computed\n// aggregates grpAggState, add t into all partial aggregations using\n// [AggState.AddTuple]. If any of the array elements is of grpAggState is null\n// (i.e., because this is the first invocation of this method, create a new\n// aggState using [aggState.Copy] on appropriate element of the a.newAggState\n// field and add the new aggState to grpAggState.\nfunc addTupleToGrpAggState(a *Aggregator, t *Tuple, grpAggState *[]AggState) {\n\t// TODO: some code goes here\n}\n\n// Given that all child tuples have been added, return an iterator that iterates\n// through the finalized aggregate result one group at a time. The returned\n// tuples should be structured according to the TupleDesc returned from the\n// Descriptor() method.\n//\n// HINT: you can call [aggState.Finalize] to get the field for each AggState.\n// Then, you should get the groupByTuple and merge it with each of the AggState\n// tuples using the joinTuples function in tuple.go you wrote in lab 1.\nfunc getFinalizedTuplesIterator(a *Aggregator, groupByList []*Tuple, aggState map[any]*[]AggState) func() (*Tuple, error) {\n\t// TODO: some code goes here\n\treturn func() (*Tuple, error) {\n\t\t// TODO: some code goes here\n\t\treturn nil, fmt.Errorf(\"getFinalizedTuplesIterator not implemented.\") // replace me\n\t}\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "agg_op_test.go",
                "code_path": "godb/agg_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/agg_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n)\n\nfunc TestAggSimpleSum(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tsa := SumAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[1]}\n\terr = sa.Init(\"sum\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&sa}, hf)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tsum := tup.Fields[0].(IntField).Value\n\tif sum != 1024 {\n\t\tt.Errorf(\"unexpected sum\")\n\t}\n}\n\nfunc TestAggMinStringAgg(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tsa := MinAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = sa.Init(\"min\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&sa}, hf)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tmin := tup.Fields[0].(StringField).Value\n\tif min != \"george jones\" {\n\t\tt.Errorf(\"incorrect min\")\n\t}\n}\n\nfunc TestAggSimpleCount(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tsa := CountAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = sa.Init(\"count\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&sa}, hf)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tcnt := tup.Fields[0].(IntField).Value\n\tif cnt != 2 {\n\t\tt.Errorf(\"unexpected count\")\n\t}\n}\n\nfunc TestAggMulti(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tca := CountAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = ca.Init(\"count\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tsa := SumAggState{}\n\texpr = FieldExpr{t1.Desc.Fields[1]}\n\terr = sa.Init(\"sum\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&ca, &sa}, hf)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tcnt := tup.Fields[0].(IntField).Value\n\tif cnt != 2 {\n\t\tt.Errorf(\"unexpected count\")\n\t}\n\tsum := tup.Fields[1].(IntField).Value\n\tif sum != 1024 {\n\t\tt.Errorf(\"unexpected sum\")\n\t}\n}\n\nfunc TestAggGbyCount(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tgbyFields := []Expr{&FieldExpr{hf.Descriptor().Fields[0]}}\n\tsa := CountAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = sa.Init(\"count\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tagg := NewGroupedAggregator([]AggState{&sa}, gbyFields, hf)\n\titer, _ := agg.Iterator(tid)\n\tfields := []FieldType{\n\t\t{\"name\", \"\", StringType},\n\t\t{\"count\", \"\", IntType},\n\t}\n\toutt1 := Tuple{TupleDesc{fields},\n\t\t[]DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{1},\n\t\t},\n\t\tnil,\n\t}\n\toutt2 := Tuple{\n\t\tTupleDesc{fields},\n\t\t[]DBValue{\n\t\t\tStringField{\"george jones\"},\n\t\t\tIntField{3},\n\t\t},\n\t\tnil,\n\t}\n\tts := []*Tuple{&outt1, &outt2}\n\terr = CheckIfOutputMatches(iter, ts)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n}\n\nfunc TestAggGbySum(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\t//gbyFields := hf.td.Fields[0:1]\n\tgbyFields := []Expr{&FieldExpr{hf.Descriptor().Fields[0]}}\n\n\tsa := SumAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[1]}\n\terr = sa.Init(\"sum\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tagg := NewGroupedAggregator([]AggState{&sa}, gbyFields, hf)\n\titer, _ := agg.Iterator(tid)\n\n\tfields := []FieldType{\n\t\t{\"name\", \"\", StringType},\n\t\t{\"sum\", \"\", IntType},\n\t}\n\toutt1 := Tuple{TupleDesc{fields},\n\t\t[]DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{50},\n\t\t}, nil,\n\t}\n\toutt2 := Tuple{\n\t\tTupleDesc{fields},\n\t\t[]DBValue{\n\t\t\tStringField{\"george jones\"},\n\t\t\tIntField{1998},\n\t\t}, nil,\n\t}\n\tts := []*Tuple{&outt1, &outt2}\n\terr = CheckIfOutputMatches(iter, ts)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n}\n\nfunc TestAggFilterCount(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tvar f FieldType = FieldType{\"age\", \"\", IntType}\n\tfilt, err := NewFilter(&ConstExpr{IntField{25}, IntType}, OpGt, &FieldExpr{f}, hf)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif filt == nil {\n\t\tt.Fatalf(\"Filter returned nil\")\n\t}\n\n\tsa := CountAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = sa.Init(\"count\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&sa}, filt)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tcnt := tup.Fields[0].(IntField).Value\n\tif cnt != 1 {\n\t\tt.Errorf(\"unexpected count\")\n\t}\n}\n\nfunc TestAggRepeatedIteration(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\terr := hf.insertTuple(&t1, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\terr = hf.insertTuple(&t2, tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tsa := CountAggState{}\n\texpr := FieldExpr{t1.Desc.Fields[0]}\n\terr = sa.Init(\"count\", &expr)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tagg := NewAggregator([]AggState{&sa}, hf)\n\titer, err := agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tcnt := tup.Fields[0].(IntField).Value\n\tif cnt != 2 {\n\t\tt.Errorf(\"unexpected count\")\n\t}\n\titer, err = agg.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t}\n\ttup, err = iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"Expected non-null tuple\")\n\t}\n\tcnt2 := tup.Fields[0].(IntField).Value\n\tif cnt != cnt2 {\n\t\tt.Errorf(\"count changed on repeated iteration\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test agg_op_test.go"
        ]
    },
    {
        "instance_id": 8,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.3. Insertion and deletion",
        "exercise": "Exercise 3",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.3. Insertion and deletion\n\nNow that you have written all of the aggregations, you will implement the `InsertOp` and `DeleteOp` operators.\n\nFor plans that implement `insert` and `delete` queries, the top most operator is\na special `InsertOp` or `DeleteOp` operator that modifies the pages of a specific `DBFile`. These operators\nreturn the number of affected tuples. This is implemented by returning a single\ntuple with one integer field, containing the count.\n\n* *Insert*: This operator adds the tuples it reads from its child operator to\n  the `insertFile` specified in its constructor. It should use the\n  `insertFile.insertTuple()` method to do this.\n\n* *Delete*: This operator deletes the tuples it reads from its child operator\n  from the `deleteFile` specified in its constructor. It should use the\n  `deleteFile.deleteTuple()` method to do this.\n\n  Both of these operators should perform all of the inserts or deletes on the first invocation of the iterator, and then return the number of records inserted or deleted.  The returned tuple should have a single field \"count\" of type integer.\n  You will need to implement the constructors, `Descriptor()` and  `Iterator()` for `InsertOp` and `DeleteOp` operators.\n  The `Descriptor()` method should also return a descriptor with a single \"count\" field.\n\n**Exercise 3.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/insert_op.go\n* godb/delete_op.go\n\n------\n\nNote that the correctness of this exercise heavily depends on the correctness of your code for lab1, especially, `heapFile.insertTuple()` and `heapFile.deleteTuple()`.\nAt this point, your code should pass the unit tests in `insert_op_test.go` and `delete_op_test.go`.",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/insert_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/insert_op.go",
                "code_content": "package godb\n\nimport \"fmt\"\n\ntype InsertOp struct {\n\t// TODO: some code goes here\n}\n\n// Construct an insert operator that inserts the records in the child Operator\n// into the specified DBFile.\nfunc NewInsertOp(insertFile DBFile, child Operator) *InsertOp {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// The insert TupleDesc is a one column descriptor with an integer field named \"count\"\nfunc (i *InsertOp) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// Return an iterator function that inserts all of the tuples from the child\n// iterator into the DBFile passed to the constuctor and then returns a\n// one-field tuple with a \"count\" field indicating the number of tuples that\n// were inserted.  Tuples should be inserted using the [DBFile.insertTuple]\n// method.\nfunc (iop *InsertOp) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"InsertOp.Iterator not implemented\")\n}\n"
            },
            {
                "code_path": "godb/delete_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/delete_op.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\ntype DeleteOp struct {\n\t// TODO: some code goes here\n}\n\n// Construct a delete operator. The delete operator deletes the records in the\n// child Operator from the specified DBFile.\nfunc NewDeleteOp(deleteFile DBFile, child Operator) *DeleteOp {\n\t// TODO: some code goes here\n\treturn nil // replace me\n}\n\n// The delete TupleDesc is a one column descriptor with an integer field named\n// \"count\".\nfunc (i *DeleteOp) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n\n}\n\n// Return an iterator that deletes all of the tuples from the child iterator\n// from the DBFile passed to the constructor and then returns a one-field tuple\n// with a \"count\" field indicating the number of tuples that were deleted.\n// Tuples should be deleted using the [DBFile.deleteTuple] method.\nfunc (dop *DeleteOp) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"DeleteOp.Iterator not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "insert_op_test.go",
                "code_path": "godb/insert_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/insert_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"os\"\n\t\"testing\"\n)\n\nconst InsertTestFile string = \"InsertTestFile.dat\"\n\nfunc TestInsert(t *testing.T) {\n\ttd, t1, _, hf, bp, tid := makeTestVars(t)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t1, tid)\n\tbp.CommitTransaction(tid)\n\tos.Remove(InsertTestFile)\n\thf2, _ := NewHeapFile(InsertTestFile, &td, bp)\n\tif hf2 == nil {\n\t\tt.Fatalf(\"hf was nil\")\n\t}\n\ttid = NewTID()\n\tbp.BeginTransaction(tid)\n\tins := NewInsertOp(hf2, hf)\n\titer, _ := ins.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Errorf(err.Error())\n\t\treturn\n\t}\n\tif tup == nil {\n\t\tt.Errorf(\"insert did not return tuple\")\n\t\treturn\n\t}\n\tintField, ok := tup.Fields[0].(IntField)\n\tif !ok || len(tup.Fields) != 1 || intField.Value != 2 {\n\t\tt.Errorf(\"invalid output tuple\")\n\t\treturn\n\t}\n\tbp.CommitTransaction(tid)\n\ttid = NewTID()\n\tbp.BeginTransaction(tid)\n\n\tcnt := 0\n\titer, _ = hf2.Iterator(tid)\n\tfor {\n\t\ttup, err := iter()\n\n\t\tif err != nil {\n\t\t\tt.Errorf(err.Error())\n\t\t}\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tcnt = cnt + 1\n\t}\n\tif cnt != 2 {\n\t\tt.Errorf(\"insert failed, expected 2 tuples, got %d\", cnt)\n\t}\n}\n"
            },
            {
                "code_name": "delete_op_test.go",
                "code_path": "godb/delete_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/delete_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n)\n\n// This function is for _testing only_!  It is not part of the godb API.\nfunc BeginTransactionForTest(t *testing.T, bp *BufferPool) TransactionID {\n\tt.Helper()\n\ttid := NewTID()\n\terr := bp.BeginTransaction(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\treturn tid\n}\n\nfunc TestDelete(t *testing.T) {\n\t_, t1, t2, hf, bp, tid := makeTestVars(t)\n\n\tinsertTupleForTest(t, hf, &t1, tid)\n\tinsertTupleForTest(t, hf, &t2, tid)\n\n\tbp.CommitTransaction(tid)\n\tvar f FieldType = FieldType{\"age\", \"\", IntType}\n\tfilt, err := NewFilter(&ConstExpr{IntField{25}, IntType}, OpGt, &FieldExpr{f}, hf)\n\tif err != nil {\n\t\tt.Errorf(err.Error())\n\t}\n\tdop := NewDeleteOp(hf, filt)\n\tif dop == nil {\n\t\tt.Fatalf(\"delete op was nil\")\n\t}\n\n\ttid = BeginTransactionForTest(t, bp)\n\titer, _ := dop.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif tup == nil {\n\t\tt.Fatalf(\"insert did not return tuple\")\n\t}\n\tintField, ok := tup.Fields[0].(IntField)\n\tif !ok || len(tup.Fields) != 1 || intField.Value != 1 {\n\t\tt.Fatalf(\"invalid output tuple\")\n\t}\n\tbp.CommitTransaction(tid)\n\n\ttid = BeginTransactionForTest(t, bp)\n\n\titer, _ = hf.Iterator(tid)\n\n\tcnt := 0\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tcnt++\n\t}\n\tif cnt != 1 {\n\t\tt.Errorf(\"unexpected number of results after deletion\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test insert_op_test.go",
            "go test delete_op_test.go"
        ]
    },
    {
        "instance_id": 9,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.4. Projection",
        "exercise": "Exercise 4",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.4. Projection\n\n\nYou will now implement the projection operation. Project iterates through its child, selects some of each tuple's fields, and returns them. Optionally, you will need to support the `DISTINCT` keyword, meaning that identical tuples should be returned only once. For example, given a dataset like:\n\n```\nsam, 25, $100,000\ntim, 30, $75,000\nmike, 35, $50,000\nsam, 50, $150,000\n```\n\nIf the query is:\n```\nSELECT name FROM table\n```\n\nThe result should be:\n```\nsam\ntim\nmike\nsam\n```\n\nBut the following query:\n```\nSELECT DISTINCT name FROM table\n```\n\nShould instead produce:\n```\nsam\ntim\nmike\n```\n\n\nThe list of fields to select, their names to be outputted by, whether the operation is `DISTINCT`, and the child operator is provided to the `NewProjectOp` constructor:\n```\nfunc NewProjectOp(selectFields []Expr, outputNames []string, distinct bool, child Operator) (Operator, error) \n```\nHere, `selectFields` is a list of expressions that can be extracted from the child operator's tuples (as in previous operators), and `outputNames` records the names that will populate the `Fname` fields in the tuple descriptor of the projection operation.\n\n**Exercise 4.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/project_op.go\n\n------\n\nAt this point, your code should pass the unit tests in `project_op_test.go`. Passing `TestProjectDistinctOptional` is optional;  if you pass it, we will offer 5% additional extra credit on the lab.  Please be sure to describe how you implemented support for distinct in your writeup.",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/project_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/project_op.go",
                "code_content": "package godb\n\nimport \"fmt\"\n\ntype Project struct {\n\tselectFields []Expr // required fields for parser\n\toutputNames  []string\n\tchild        Operator\n\t// You may want to add additional fields here\n\t// TODO: some code goes here\n}\n\n// Construct a projection operator. It saves the list of selected field, child,\n// and the child op. Here, selectFields is a list of expressions that represents\n// the fields to be selected, outputNames are names by which the selected fields\n// are named (should be same length as selectFields; throws error if not),\n// distinct is for noting whether the projection reports only distinct results,\n// and child is the child operator.\nfunc NewProjectOp(selectFields []Expr, outputNames []string, distinct bool, child Operator) (Operator, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"NewProjectOp not implemented.\") // replace me\n}\n\n// Return a TupleDescriptor for this projection. The returned descriptor should\n// contain fields for each field in the constructor selectFields list with\n// outputNames as specified in the constructor.\n//\n// HINT: you can use expr.GetExprType() to get the field type\nfunc (p *Project) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n\n}\n\n// Project operator implementation. This function should iterate over the\n// results of the child iterator, projecting out the fields from each tuple. In\n// the case of distinct projection, duplicate tuples should be removed. To\n// implement this you will need to record in some data structure with the\n// distinct tuples seen so far. Note that support for the distinct keyword is\n// optional as specified in the lab 2 assignment.\nfunc (p *Project) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"Project.Iterator not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "project_op_test.go",
                "code_path": "godb/project_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/project_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n)\n\nfunc TestProject(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t2, tid)\n\t//fs := make([]FieldType, 1)\n\t//fs[0] = t1.Desc.Fields[0]\n\tvar outNames []string = make([]string, 1)\n\toutNames[0] = \"outf\"\n\tfieldExpr := FieldExpr{t1.Desc.Fields[0]}\n\tproj, _ := NewProjectOp([]Expr{&fieldExpr}, outNames, false, hf)\n\tif proj == nil {\n\t\tt.Fatalf(\"project was nil\")\n\t}\n\titer, _ := proj.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\ttup, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tif len(tup.Fields) != 1 || tup.Desc.Fields[0].Fname != \"outf\" {\n\t\tt.Errorf(\"invalid output tuple\")\n\t}\n\n}\n\nfunc TestProjectDistinctOptional(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t2, tid)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t2, tid)\n\n\t//fs := make([]FieldType, 1)\n\t//fs[0] = t1.Desc.Fields[0]\n\tvar outNames []string = make([]string, 1)\n\toutNames[0] = \"outf\"\n\tfieldExpr := FieldExpr{t1.Desc.Fields[0]}\n\tproj, _ := NewProjectOp([]Expr{&fieldExpr}, outNames, true, hf)\n\tif proj == nil {\n\t\tt.Fatalf(\"project was nil\")\n\t}\n\titer, _ := proj.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\tcnt := 0\n\tfor {\n\t\ttup, err := iter()\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tcnt = cnt + 1\n\t}\n\tif cnt != 2 {\n\t\tt.Errorf(\"expected two names, got %d\", cnt)\n\n\t}\n}\n\nfunc TestProjectOrdering(t *testing.T) {\n\thf, tup, td, bp, err := makeOrderByOrderingVars()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf.insertTuple(&tup, tid)\n\n\tvar outNames = []string{\"out1\", \"out2\"}\n\texprs := []Expr{&FieldExpr{td.Fields[2]}, &FieldExpr{td.Fields[0]}}\n\n\tproj, _ := NewProjectOp(exprs, outNames, false, hf)\n\tif proj == nil {\n\t\tt.Fatalf(\"project was nil\")\n\t}\n\titer, _ := proj.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\n\ttupOut, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tvar expectedDesc = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"out1\", Ftype: IntType},\n\t\t{Fname: \"out2\", Ftype: StringType},\n\t}}\n\n\tif !expectedDesc.equals(&tupOut.Desc) {\n\t\tt.Fatalf(\"Unexpected descriptor of projected tuple\")\n\t}\n\n}\n\nfunc TestProjectExtra(t *testing.T) {\n\t_, _, t1, _, _ := makeJoinOrderingVars(t)\n\tft1 := FieldType{\"a\", \"\", StringType}\n\tft2 := FieldType{\"b\", \"\", IntType}\n\toutTup, _ := t1.project([]FieldType{ft1})\n\tif (len(outTup.Fields)) != 1 {\n\t\tt.Fatalf(\"project returned %d fields, expected 1\", len(outTup.Fields))\n\t}\n\tv, ok := outTup.Fields[0].(StringField)\n\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return string\")\n\t}\n\tif v.Value != \"sam\" {\n\t\tt.Fatalf(\"project didn't return sam\")\n\n\t}\n\toutTup, _ = t1.project([]FieldType{ft2})\n\tif (len(outTup.Fields)) != 1 {\n\t\tt.Fatalf(\"project returned %d fields, expected 1\", len(outTup.Fields))\n\t}\n\tv2, ok := outTup.Fields[0].(IntField)\n\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return int\")\n\t}\n\tif v2.Value != 25 {\n\t\tt.Fatalf(\"project didn't return 25\")\n\n\t}\n\n\toutTup, _ = t1.project([]FieldType{ft2, ft1})\n\tif (len(outTup.Fields)) != 2 {\n\t\tt.Fatalf(\"project returned %d fields, expected 2\", len(outTup.Fields))\n\t}\n\tv, ok = outTup.Fields[1].(StringField)\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return string in second field\")\n\t}\n\tif v.Value != \"sam\" {\n\t\tt.Fatalf(\"project didn't return sam\")\n\n\t}\n\n\tv2, ok = outTup.Fields[0].(IntField)\n\tif !ok {\n\t\tt.Fatalf(\"project of name didn't return int in first field\")\n\t}\n\tif v2.Value != 25 {\n\t\tt.Fatalf(\"project didn't return 25\")\n\n\t}\n\n}\n\nfunc TestTupleProjectExtra(t *testing.T) {\n\tvar td = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"tq2\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq2\", Ftype: StringType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc: td,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"SFname1tq1\"},\n\t\t\tStringField{\"SFname2tq2\"},\n\t\t\tStringField{\"SFname1tq2\"},\n\t\t}}\n\n\tt2, err := t1.project([]FieldType{\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq1\", Ftype: StringType},\n\t\t{Fname: \"name2\", TableQualifier: \"tq2\", Ftype: StringType},\n\t\t{Fname: \"name1\", TableQualifier: \"tq2\", Ftype: StringType},\n\t})\n\n\tif err != nil {\n\t\tt.Fatalf(\"%v\", err)\n\t}\n\n\tif t2.Fields[0].(StringField).Value != \"SFname1tq1\" {\n\t\tt.Fatalf(\"tuple project extra wrong match\")\n\t}\n\n\tif t2.Fields[1].(StringField).Value != \"SFname2tq2\" {\n\t\tt.Fatalf(\"tuple project extra wrong match\")\n\t}\n\n\tif t2.Fields[2].(StringField).Value != \"SFname1tq1\" {\n\t\tt.Fatalf(\"tuple project extra wrong match\")\n\t}\n\tif t2.Fields[3].(StringField).Value != \"SFname2tq2\" {\n\t\tt.Fatalf(\"tuple project extra wrong match\")\n\t}\n\tif t2.Fields[4].(StringField).Value != \"SFname1tq2\" {\n\t\tt.Fatalf(\"tuple project extra wrong match\")\n\t}\n\n}\n"
            }
        ],
        "test_command": [
            "go test project_op_test.go"
        ]
    },
    {
        "instance_id": 10,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.5. Order By",
        "exercise": "Exercise 5",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.5. Order By\n\n\nYou will now implement the \"order by\" operation. It iterates through its child in a particular order. It needs to support ordering by more than one field, with each field in either ascending or descending order.   For example, consider the query:\n\n```\nSELECT name, age, salary\nFROM table\nORDER BY name ASC, age DESC\n```\n\nGiven a dataset like:\n```\nsam, 25, $100,000\ntim, 30, $75,000\nmike, 35, $50,000\nsam, 50, $150,000\n```\n\nThe above query should produce the result:\n```\nmike, 35, $50,000\nsam, 50, $150,000\nsam, 25, $100,000\ntim, 30, $75,000\n```\n\nThe list of fields to order by and the ascending/descending for each field provided to the `NewOrderBy` constructor:\n```\nfunc NewOrderBy(orderByFields []Expr, child Operator, ascending []bool) (*OrderBy, error) {\n```\nHere, `orderByFields` is a list of expressions that can be extracted from the child operator's tuples (as in previous operators), and the ascending bitmap indicates whether the *i*th field in the `orderByFields` list should be ascending (true) or descending(false).\n\n**Exercise 5.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/order_by_op.go\n\n------\n\nAt this point, your code should pass the unit tests in `order_by_test.go`.",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/order_by_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/order_by_op.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n)\n\ntype OrderBy struct {\n\torderBy []Expr // OrderBy should include these two fields (used by parser)\n\tchild   Operator\n\t// TODO: You may want to add additional fields here\n}\n\n// Construct an order by operator. Saves the list of field, child, and ascending\n// values for use in the Iterator() method. Here, orderByFields is a list of\n// expressions that can be extracted from the child operator's tuples, and the\n// ascending bitmap indicates whether the ith field in the orderByFields list\n// should be in ascending (true) or descending (false) order.\nfunc NewOrderBy(orderByFields []Expr, child Operator, ascending []bool) (*OrderBy, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"NewOrderBy not implemented.\") //replace me\n\n}\n\n// Return the tuple descriptor.\n//\n// Note that the order by just changes the order of the child tuples, not the\n// fields that are emitted.\nfunc (o *OrderBy) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\n// Return a function that iterates through the results of the child iterator in\n// ascending/descending order, as specified in the constructor.  This sort is\n// \"blocking\" -- it should first construct an in-memory sorted list of results\n// to return, and then iterate through them one by one on each subsequent\n// invocation of the iterator function.\n//\n// Although you are free to implement your own sorting logic, you may wish to\n// leverage the go sort package and the [sort.Sort] method for this purpose. To\n// use this you will need to implement three methods: Len, Swap, and Less that\n// the sort algorithm will invoke to produce a sorted list. See the first\n// example, example of SortMultiKeys, and documentation at:\n// https://pkg.go.dev/sort\nfunc (o *OrderBy) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"OrderBy.Iterator not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "order_by_test.go",
                "code_path": "godb/order_by_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/order_by_test.go",
                "code_content": "package godb\n\nimport (\n\t\"os\"\n\t\"testing\"\n)\n\nfunc makeOrderByOrderingVars() (DBFile, Tuple, TupleDesc, *BufferPool, error) {\n\tvar td = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"a\", Ftype: StringType},\n\t\t{Fname: \"b\", Ftype: IntType},\n\t\t{Fname: \"c\", Ftype: IntType},\n\t}}\n\n\tvar t = Tuple{\n\t\tDesc: td,\n\t\tFields: []DBValue{\n\t\t\tStringField{\"sam\"},\n\t\t\tIntField{25},\n\t\t\tIntField{5},\n\t\t}}\n\n\tbp, c, err := MakeTestDatabase(3, \"catalog.txt\")\n\tif err != nil {\n\t\treturn nil, t, td, nil, err\n\t}\n\n\tos.Remove(\"test.dat\")\n\thf, err := c.addTable(\"test\", td)\n\tif err != nil {\n\t\treturn hf, t, td, nil, err\n\t}\n\n\treturn hf, t, td, bp, nil\n}\n\n// test the order by operator, by asking it to sort the test database\n// in ascending and descending order and verifying the result\nfunc TestOrderBy(t *testing.T) {\n\t_, t1, t2, hf, _, tid := makeTestVars(t)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t2, tid)\n\tbs := make([]bool, 2)\n\tfor i := range bs {\n\t\tbs[i] = false\n\t}\n\t//order by name and then age, descending\n\texprs := make([]Expr, len(t1.Desc.Fields))\n\tfor i, f := range t1.Desc.Fields {\n\t\texprs[i] = &FieldExpr{f}\n\t}\n\toby, err := NewOrderBy(exprs, hf, bs)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer, _ := oby.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\tvar last string\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tfval := tup.Fields[0].(StringField).Value\n\t\tif last != \"\" {\n\t\t\tif fval > last {\n\t\t\t\tt.Fatalf(\"data was not descending, as expected\")\n\t\t\t}\n\t\t}\n\t\tlast = fval\n\t}\n\n\tfor i := range bs {\n\t\tbs[i] = true\n\t}\n\t//order by name and then age, ascending\n\toby, err = NewOrderBy(exprs, hf, bs)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer, _ = oby.Iterator(tid)\n\tlast = \"\"\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tfval := tup.Fields[0].(StringField).Value\n\t\tif last != \"\" {\n\t\t\tif fval < last {\n\t\t\t\tt.Fatalf(\"data was not ascending, as expected\")\n\t\t\t}\n\t\t}\n\t\tlast = fval\n\t}\n}\n\n// harder order by test that inserts 4 tuples, and alternates ascending vs descending\nfunc TestOrderByMultiField(t *testing.T) {\n\tvar td = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"name\", Ftype: StringType},\n\t\t{Fname: \"age\", Ftype: IntType},\n\t}}\n\n\tvar t1 = Tuple{\n\t\tDesc:   td,\n\t\tFields: []DBValue{StringField{\"sam\"}, IntField{25}},\n\t\tRid:    nil,\n\t}\n\n\tvar t2 = Tuple{\n\t\tDesc:   td,\n\t\tFields: []DBValue{StringField{\"tim\"}, IntField{44}},\n\t\tRid:    nil,\n\t}\n\n\tvar t3 = Tuple{\n\t\tDesc:   td,\n\t\tFields: []DBValue{StringField{\"mike\"}, IntField{88}},\n\t\tRid:    nil,\n\t}\n\n\tvar t4 = Tuple{\n\t\tDesc:   td,\n\t\tFields: []DBValue{StringField{\"sam\"}, IntField{26}},\n\t\tRid:    nil,\n\t}\n\n\tbp, c, err := MakeTestDatabase(2, \"catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tos.Remove(\"test.dat\")\n\thf, err := c.addTable(\"test\", td)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf.insertTuple(&t1, tid)\n\thf.insertTuple(&t2, tid)\n\thf.insertTuple(&t3, tid)\n\thf.insertTuple(&t4, tid)\n\n\t//order by name and then age, descending\n\tascDescs := [][]bool{{false, false}, {true, false}}\n\texpectedAnswers := [][]Tuple{{t2, t4, t1, t3}, {t3, t4, t1, t2}}\n\texprs := make([]Expr, len(t1.Desc.Fields))\n\tfor i, f := range t1.Desc.Fields {\n\t\texprs[i] = &FieldExpr{f}\n\t}\n\n\tfor i := 0; i < len(ascDescs); i++ {\n\t\tascDesc := ascDescs[i]\n\t\texpected := expectedAnswers[i]\n\t\tresult := []Tuple{}\n\t\toby, err := NewOrderBy(exprs, hf, ascDesc)\n\t\tif err != nil {\n\t\t\tt.Fatalf(err.Error())\n\t\t}\n\t\titer, _ := oby.Iterator(tid)\n\t\tif iter == nil {\n\t\t\tt.Fatalf(\"iter was nil\")\n\t\t}\n\n\t\tfor {\n\t\t\ttup, _ := iter()\n\t\t\tif tup == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tresult = append(result, *tup)\n\n\t\t}\n\t\tif len(result) != len(expected) {\n\t\t\tt.Fatalf(\"order by test %d produced different number of results than expected (%d got, expected %d)\", i, len(result), len(expected))\n\t\t}\n\t\tfor j, tup := range result {\n\t\t\tif !tup.equals(&expected[j]) {\n\t\t\t\tt.Fatalf(\"order by test %d got wrong tuple at position %d (expected %v, got %v)\", i, j, expected[j].Fields, tup.Fields)\n\t\t\t}\n\t\t}\n\t}\n\n\tbp.CommitTransaction(tid)\n}\n\nfunc TestOrderByFieldsOrder(t *testing.T) {\n\thf, tup, td, bp, err := makeOrderByOrderingVars()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf.insertTuple(&tup, tid)\n\n\tbs := make([]bool, 2)\n\tfor i := range bs {\n\t\tbs[i] = false\n\t}\n\n\texprs := []Expr{&FieldExpr{td.Fields[0]}, &FieldExpr{td.Fields[2]}}\n\n\toby, err := NewOrderBy(exprs, hf, bs)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\titer, _ := oby.Iterator(tid)\n\tif iter == nil {\n\t\tt.Fatalf(\"iter was nil\")\n\t}\n\n\tvar expectedDesc = TupleDesc{Fields: []FieldType{\n\t\t{Fname: \"a\", Ftype: StringType},\n\t\t{Fname: \"b\", Ftype: IntType},\n\t\t{Fname: \"c\", Ftype: IntType},\n\t}}\n\n\ttupOut, err := iter()\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\tif !expectedDesc.equals(&tupOut.Desc) {\n\t\tt.Fatalf(\"Unexpected descriptor of ordered tuple\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test order_by_test.go"
        ]
    },
    {
        "instance_id": 11,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.6. Limit",
        "exercise": "Exercise 6",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.6. Limit\n\nYou will now implement the limit operation. Limit iterates through its child and selects the first `n` tuples it sees. If the child returns `m < n` tuples, the limit operator only returns `m` tuples.\n\n**Exercise 6.**\n\nImplement the skeleton methods in:\n\n------\n\n* godb/limit_op.go\n\n------\n\nAt this point, your code should pass the unit tests in `limit_op_test.go`. ",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [
            {
                "code_path": "godb/limit_op.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/limit_op.go",
                "code_content": "package godb\n\nimport (\n\"fmt\"\n)\n\ntype LimitOp struct {\n\t// Required fields for parser\n\tchild     Operator\n\tlimitTups Expr\n\t// Add additional fields here, if needed\n}\n\n// Construct a new limit operator. lim is how many tuples to return and child is\n// the child operator.\nfunc NewLimitOp(lim Expr, child Operator) *LimitOp {\n\treturn &LimitOp{child, lim}\n}\n\n// Return a TupleDescriptor for this limit.\nfunc (l *LimitOp) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn &TupleDesc{} // replace me\n}\n\n// Limit operator implementation. This function should iterate over the results\n// of the child iterator, and limit the result set to the first [lim] tuples it\n// sees (where lim is specified in the constructor).\nfunc (l *LimitOp) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"LimitOp.Iterator not implemented\") // replace me\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "limit_op_test.go",
                "code_path": "godb/limit_op_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/limit_op_test.go",
                "code_content": "package godb\n\nimport (\n\t\"testing\"\n)\n\nfunc testLimitCount(t *testing.T, n int) {\n\tt.Helper()\n\t_, t1, t2, hf, bp, _ := makeTestVars(t)\n\n\tfor i := 0; i < n; i++ {\n\t\ttid := NewTID()\n\t\tbp.BeginTransaction(tid)\n\t\terr := hf.insertTuple(&t1, tid)\n\t\tif err != nil {\n\t\t\tt.Errorf(err.Error())\n\t\t\treturn\n\t\t}\n\t\terr = hf.insertTuple(&t2, tid)\n\t\tif err != nil {\n\t\t\tt.Errorf(err.Error())\n\t\t\treturn\n\t\t}\n\n\t\t// hack to force dirty pages to disk\n\t\t// because CommitTransaction may not be implemented\n\t\t// yet if this is called in lab 2\n\t\tif i%10 == 0 {\n\t\t\tbp.FlushAllPages()\n\t\t}\n\n\t\t//commit frequently to prevent buffer pool from filling\n\t\tbp.CommitTransaction(tid)\n\t}\n\n\t// check results\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\tlim := NewLimitOp(&ConstExpr{IntField{int64(n)}, IntType}, hf)\n\tif lim == nil {\n\t\tt.Fatalf(\"Op was nil\")\n\t\treturn\n\t}\n\titer, err := lim.Iterator(tid)\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t\treturn\n\t}\n\tif iter == nil {\n\t\tt.Fatalf(\"Iterator was nil\")\n\t\treturn\n\t}\n\n\tcnt := 0\n\tfor {\n\t\ttup, _ := iter()\n\t\tif tup == nil {\n\t\t\tbreak\n\t\t}\n\t\tcnt++\n\t}\n\tif cnt != n {\n\t\tt.Errorf(\"unexpected number of results\")\n\t}\n\n\tbp.CommitTransaction(tid)\n}\n\nfunc TestLimit5(t *testing.T) {\n\ttestLimitCount(t, 5)\n}\n\nfunc TestLimit50(t *testing.T) {\n\ttestLimitCount(t, 50)\n}\n\nfunc TestLimit100(t *testing.T) {\n\ttestLimitCount(t, 100)\n}\n"
            }
        ],
        "test_command": [
            "go test limit_op_test.go"
        ]
    },
    {
        "instance_id": 12,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 2: GoDB Operators",
        "part_name": "2.8. Query Parser",
        "exercise": "Exercise 7",
        "introduction": "In this lab assignment, you will write a set of operators for GoDB to\nimplement table modifications (e.g., insert and delete records), filters,\njoins, aggregates, etc. These will build on top of the foundation that you wrote\nin Lab 1 to provide you with a database system that can perform simple queries\nover multiple tables.\n\nYou do not need to implement transactions or locking in this lab.\n\nThe remainder of this document gives some suggestions about how to start coding,\ndescribes a set of exercises to help you work through the lab, and discusses how\nto hand in your code. This lab requires you to write a fair amount of code, so\nwe encourage you to **start early**!",
        "Description": "### 2.8. Query Parser\n\nBecause it's very cumbersome to compose operators to make queries like this, we've provided a parser for you.  This allows you to input SQL queries and get a result set.  We've also built a query shell that allows you to interact with the parser.  To run it, type `go run main.go` from the top-level godb directory in your terminal (if an error message pops up, yu may need to run some `go get` as the error message suggested).\nThis will display:\n\n```-bash ~/godb % go run main.go\nWelcome to\n\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591 \u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n    \u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\n\nType \\h for help\n\n>\n```\n\nTyping `\\h` will give a list of commands you can input; for example, `\\d` lists the tables and their schemas.  Tables are, by default, loaded from the file `catalog.txt`, but you can point to another catalog file.  Note that each table in the catalog is stored in a file called `<tablename>.dat`, where tablename is the name of the table. From this terminal, you can run `DROP`, `CREATE`, `INSERT`, `BEGIN`, `COMMIT/ROLLBACK`, and `SELECT` statements.  You can also load a CSV file into a table using the `\\l` command.\n\nThe parser supports most of SQL with some limitations, including:\n\n* No CTEs, window functions, recursive queries, or other SQL99 or later features (arbitrarily nested subqueries are fully supported)\n* No OUTER joins (all joins are INNER)\n* No USING clause for join predicates (you should write this to ON)\n* No correlated subqueries\n* No UPDATEs\n\n\nWhen you first run the console, it will load a small test catalog containing two identical tables of people and ages.  You can see the schemas of these tables using the `\\d` command.  If you have fully implemented the operators from the previous exercises (including DISTINCT) you should be able to pass this test.  Because these test queries use DISTINCT, we will not grade you on these particular queries but may have hidden test cases that run a few SQL queries against your lab, so you should be sure to confirm that at least simple queries run.  \n\nAs an example, we have loaded the ps1 mbta dataset into GoDB format.  You can download it from [here](https://www.dropbox.com/scl/fi/l27l17fg6mo3d4jjihmls/transitdb.zip?rlkey=890c1omvwevm6n4us10d7m11j).  Note that all columns are either strings or ints;  floats have been cast to ints in this database.\nDownload the `transitdb` folder (you may be asked to login or create Dropdox account) and put it in your top-level godb directory.\nAfterward, you can connect to over the console using the `\\c`\ncommand:\n```\n> \\c transitdb/transitdb.catalog\nLoaded transitdb/transitdb.catalog\ngated_station_entries (service_date string, time string, station_id string, line_id string, gated_entries int)\nlines (line_id string, line_name string)\nroutes (route_id int, line_id string, first_station_id string, last_station_id string, direction int, direction_desc string, route_name string)\nstations (station_id string, station_name string)\nrail_ridership (season string, line_id string, direction int, time_period_id string, station_id string, total_ons int, total_offs int, number_service_days int, average_ons int, average_offs int, average_flow int)\nstation_orders (route_id int, station_id string, stop_order int, distance_from_last_station_miles int)\ntime_periods (time_period_id string, day_type string, time_period string, period_start_time string, period_end_time string)\n```\n\nOnce it is loaded, you should be able to run a query. For example, to find the first and last station of each line, you can write:\n``` \n> SELECT line_name,\n>        direction_desc,\n>        s1.station_name AS first_station,\n>        s2.station_name AS last_station\n> FROM routes\n> JOIN lines ON lines.line_id = routes.line_id\n> JOIN stations s1 ON first_station_id = s1.station_id\n> JOIN stations s2 ON last_station_id = s2.station_id\n> ORDER BY line_name ASC, direction_desc ASC, first_station ASC, last_station ASC;\n          line_name          |        direction_desc       |        first_station        |         last_station        |\n         \"Blue Line\"         |             East            |           Bowdoin           |          Wonderland         |\n         \"Blue Line\"         |             West            |          Wonderland         |           Bowdoin           |\n         \"Green Line\"        |             East            |       \"Boston College\"      |     \"Government Center\"     |\n         \"Green Line\"        |             East            |      \"Cleveland Circle\"     |     \"Government Center\"     |\n         \"Green Line\"        |             East            |        \"Heath Street\"       |           Lechmere          |\n         \"Green Line\"        |             East            |          Riverside          |       \"North Station\"       |\n         \"Green Line\"        |             West            |     \"Government Center\"     |       \"Boston College\"      |\n         \"Green Line\"        |             West            |     \"Government Center\"     |      \"Cleveland Circle\"     |\n         \"Green Line\"        |             West            |       \"North Station\"       |          Riverside          |\n         \"Green Line\"        |             West            |           Lechmere          |        \"Heath Street\"       |\n      \"Mattapan Trolley\"     |           Inbound           |           Mattapan          |           Ashmont           |\n      \"Mattapan Trolley\"     |           Outbound          |           Ashmont           |           Mattapan          |\n        \"Orange Line\"        |            North            |        \"Forest Hills\"       |         \"Oak Grove\"         |\n        \"Orange Line\"        |            South            |         \"Oak Grove\"         |        \"Forest Hills\"       |\n          \"Red Line\"         |            North            |           Ashmont           |           Alewife           |\n          \"Red Line\"         |            North            |          Braintree          |           Alewife           |\n          \"Red Line\"         |            South            |           Alewife           |           Ashmont           |\n          \"Red Line\"         |            South            |           Alewife           |          Braintree          |\n(18 results)\n57.01075ms\n```\n\nYou can also view the query plan generated for the query by appending the \"EXPLAIN\" keyword to a query, e.g.:\n```\n> explain SELECT line_name,\n>        direction_desc,\n>        s1.station_name AS first_station,\n>        s2.station_name AS last_station\n> FROM routes\n> JOIN lines ON lines.line_id = routes.line_id\n> JOIN stations s1 ON first_station_id = s1.station_id\n> JOIN stations s2 ON last_station_id = s2.station_id\n> ORDER BY line_name ASC, direction_desc ASC, first_station ASC, last_station ASC;\n\nOrder By line_name,direction_desc,first_station,last_station,\n    Project lines.line_name,routes.direction_desc,s1.station_name,s2.station_name, -> [line_name direction_desc first_station last_station]\n        Join, routes.last_station_id == s2.station_id\n            Join, routes.first_station_id == s1.station_id\n                Join, lines.line_id == routes.line_id\n                    Heap Scan transitdb/lines.dat\n                    Heap Scan transitdb/routes.dat\n                Heap Scan transitdb/stations.dat\n            Heap Scan transitdb/stations.dat\n```\n\n**Exercise 7.**\n\nRun a few queries against the transitdb to make sure your operator implementations are working.  \n\nYou should also be able to pass `TestParseEasy` in `easy_parser_test.go`.  This test runs a few SQL queries against the `catalog.txt` catalog that we have provided.  Note that it works by comparing your results to a set of saved CSV files in the `savedresults` directory.",
        "repo/location": "$ cd go-db-hw-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab2.md",
        "codes": [],
        "test_codes": [
            {
                "code_name": "easy_parser_test.go",
                "code_path": "godb/easy_parser_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/easy_parser_test.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n)\n\ntype Query struct {\n\tSQL     string\n\tOrdered bool\n}\n\nfunc TestParseEasy(t *testing.T) {\n\tqueries := []Query{\n\t\t{SQL: \"select sum(age) as s from t group by t.name having s > 30\", Ordered: false},\n\t\t{SQL: \"select sum(age + 10) , sum(age) from t\", Ordered: false},\n\t\t{SQL: \"select min(age) + max(age) from t\", Ordered: false},\n\t\t{SQL: \"select * from t order by t.age, t.name limit 1+2\", Ordered: true},\n\t\t{SQL: \"select t.name, t.age from t join t2 on t.name = t2.name, t2 as t3 where t.age < 50 and t3.age = t.age order by t.age asc, t.name asc\", Ordered: true},\n\t\t{SQL: \"select sq(sq(5)) from t\", Ordered: false},\n\t\t{SQL: \"select 1, name from t\", Ordered: false},\n\t\t{SQL: \"select age, name from t\", Ordered: false},\n\t\t{SQL: \"select t.name, sum(age) totage from t group by t.name\", Ordered: false},\n\t\t{SQL: \"select t.name, t.age from t join t2 on t.name = t2.name where t.age < 50\", Ordered: false},\n\t\t{SQL: \"select name from (select x.name from (select t.name from t) x)y order by name asc\", Ordered: true},\n\t\t{SQL: \"select age, count(*) from t group by age\", Ordered: false},\n\t}\n\tsave := false        //set save to true to save the output of the current test run as the correct answer\n\tprintOutput := false //print the result set during testing\n\n\tbp, c, err := MakeParserTestDatabase(10)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to create test database, %s\", err.Error())\n\t}\n\n\tqNo := 0\n\tfor _, query := range queries {\n\t\ttid := BeginTransactionForTest(t, bp)\n\t\tqNo++\n\n\t\tqType, plan, err := Parse(c, query.SQL)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"failed to parse, q=%s, %s\", query.SQL, err.Error())\n\t\t}\n\t\tif plan == nil {\n\t\t\tt.Fatalf(\"plan was nil\")\n\t\t}\n\t\tif qType != IteratorType {\n\t\t\tcontinue\n\t\t}\n\n\t\tvar outfile *HeapFile\n\t\tvar outfile_csv *os.File\n\t\tvar resultSet []*Tuple\n\t\tfname := fmt.Sprintf(\"savedresults/q%d-easy-result.csv\", qNo)\n\n\t\tif save {\n\t\t\tos.Remove(fname)\n\t\t\toutfile_csv, err = os.OpenFile(fname, os.O_RDWR|os.O_CREATE, 0644)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"failed to open CSV file (%s)\", err.Error())\n\t\t\t}\n\t\t\t//outfile, _ = NewHeapFile(fname, plan.Descriptor(), bp)\n\t\t} else {\n\t\t\tfname_bin := fmt.Sprintf(\"savedresults/q%d-easy-result.dat\", qNo)\n\t\t\tos.Remove(fname_bin)\n\t\t\tdesc := plan.Descriptor()\n\t\t\tif desc == nil {\n\t\t\t\tt.Fatalf(\"descriptor was nil\")\n\t\t\t}\n\n\t\t\toutfile, _ = NewHeapFile(fname_bin, desc, bp)\n\t\t\tif outfile == nil {\n\t\t\t\tt.Fatalf(\"heapfile was nil\")\n\t\t\t}\n\t\t\tf, err := os.Open(fname)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"csv file with results was nil (%s)\", err.Error())\n\t\t\t}\n\t\t\terr = outfile.LoadFromCSV(f, true, \",\", false)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(err.Error())\n\t\t\t}\n\n\t\t\tresultIter, err := outfile.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(err.Error())\n\t\t\t}\n\t\t\tfor {\n\t\t\t\ttup, err := resultIter()\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Fatalf(err.Error())\n\t\t\t\t}\n\n\t\t\t\tif tup != nil {\n\t\t\t\t\tresultSet = append(resultSet, tup)\n\t\t\t\t} else {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif printOutput || save {\n\t\t\tfmt.Printf(\"Doing %s\\n\", query.SQL)\n\t\t\titer, err := plan.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"%s\", err.Error())\n\n\t\t\t}\n\t\t\tnresults := 0\n\t\t\tif save {\n\t\t\t\tfmt.Fprintf(outfile_csv, \"%s\\n\", plan.Descriptor().HeaderString(false))\n\t\t\t}\n\t\t\tfmt.Printf(\"%s\\n\", plan.Descriptor().HeaderString(true))\n\t\t\tfor {\n\t\t\t\ttup, err := iter()\n\t\t\t\tif err != nil {\n\t\t\t\t\tt.Errorf(\"%s\", err.Error())\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tif tup == nil {\n\t\t\t\t\tbreak\n\t\t\t\t} else {\n\t\t\t\t\tfmt.Printf(\"%s\\n\", tup.PrettyPrintString(true))\n\t\t\t\t}\n\t\t\t\tnresults++\n\t\t\t\tif save {\n\t\t\t\t\tfmt.Fprintf(outfile_csv, \"%s\\n\", tup.PrettyPrintString(false))\n\t\t\t\t\t//outfile.insertTuple(tup, tid)\n\t\t\t\t}\n\t\t\t}\n\t\t\tfmt.Printf(\"(%d results)\\n\\n\", nresults)\n\t\t}\n\t\tif save {\n\t\t\tbp.FlushAllPages()\n\t\t\toutfile.bufPool.CommitTransaction(tid)\n\t\t\toutfile_csv.Close()\n\t\t} else {\n\t\t\titer, err := plan.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"%s\", err.Error())\n\t\t\t}\n\t\t\tif query.Ordered {\n\t\t\t\terr = CheckIfOutputMatches(iter, resultSet)\n\t\t\t} else {\n\t\t\t\terr = CheckIfOutputMatchesUnordered(iter, resultSet)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"query '%s' did not match expected result set: %v\", query.SQL, err)\n\t\t\t\tverbose := true\n\t\t\t\tif verbose {\n\t\t\t\t\tfmt.Print(\"Expected: \\n\")\n\t\t\t\t\tfor _, r := range resultSet {\n\t\t\t\t\t\tfmt.Printf(\"%s\\n\", r.PrettyPrintString(true))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test easy_parser_test.go"
        ]
    },
    {
        "instance_id": 13,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 3: GoDB Transactions",
        "part_name": "2.6. Lock Lifetime",
        "exercise": "Exercise 1",
        "introduction": "In this lab, you will implement a simple locking-based transaction system in GoDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.\n\nThe remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.",
        "Description": "### 2.6. Lock Lifetime\n\nYou will need to implement strict two-phase locking. This means that transactions should acquire the appropriate type of lock on any object before accessing that object and shouldn't release any locks until after the transaction is committed.\n\nFortunately, the GoDB design is such that it is possible to obtain locks on pages in  `BufferPool.GetPage()`  before you read or modify them. So, rather than adding calls to locking routines in each of your operators, you should acquire locks in  `GetPage()`.   You will implement releasing of locks when you implement `CommitTransaction()`  and `AbortTransaction()` below.\n\nYou will need to acquire a  _shared_  lock on any page (or tuple) before you read it, and you will need to acquire an  _exclusive_  lock on any page (or tuple) before you write it. You will notice that we are already passing around  `RWPerm`  variables in the BufferPool; these variables indicate the type of lock that the caller would like to have on the object being accessed (we have given you code for the  `RWPerm`  type.)\n\n\n----------\n\nOur testing system relies on the godb implementation returning an error when the transaction is aborted (due to deadlocks etc.). If the transaction is aborted, your implementation is not responsible for restarting the transaction. Simply return an error and the test suite (called/user of the system) will restarte the transaction. Before you start implementing anything for this lab, check that `TestTransactionTid` passes. This test relies on the implementation we have provided you for `NewTID()` which the rest of the system and the tests depend on. If it does not pass, contact the course staff. At this point, `TestTransaction` will not terminate since `insertTuple` returns an error for a buffer pool full with dirty pages, not an aborted transaction (see `readXaction` and `writeXaction` in `transaction_test.go`). This part will execute normally after you implement exercises 1 and 2.\n\nBefore you start working on lab3, you may also find that the following tests already pass. This is normal as they should work for a sequential implementation. After you add transaction related features, these tests should still pass. There is a small portion of credit assigned for them.\n* `TestLockingAcquireReadLocksOnSampePage`\n* `TestLockingAcquireReadWriteLocksOnTwoPages`\n* `TestLockingAcquireWriteLocksOnTwoPages`\n* `TestLockingAcquireReadLocksOnTwoPages`\n* `TestLockingUpgrade`\n* `TestLockingAcquireWriteAndReadLocks`\n* `TestTransactionTwice`\n* `TestTransactionCommit`\n* `TestTransactionSingleThread`\n\n**Exercise 1.**\n\nWrite the methods that acquire transactional locks in BufferPool. Assuming you are using page-level locking, you will need to modify `GetPage`  to block and acquire the desired lock (specified by `RWPerm`) before returning a page.   `GetPage` receives a `TransactionID` that is attempting to acquire the lock.  You will want to allocate data structures that keep track of the shared and exclusive locks each transaction is currently holding.  \n\nPlease note that unlike in previous tests,  there will be multiple threads concurrently calling `GetPage()` during this test.  Use `sync.Mutex` or the `sync.Map`  construct to prevent race conditions.  Think about what happens if two threads simultaneously try to read or evict a page.  The simplest approach (which we recommend) is:\n\n- Associate a `Mutex` with your buffer pool.  \n    - Acquire this mutex before you access any of the data structures you used to keep track of which pages are locked;  this will ensure only one thread is trying to use the data structures in the buffer pool to acquire a page lock at a time.  \n        - If you successfully acquire the page lock, you should release the buffer pool mutex after lock acquisition.  \n        - If you fail to acquire the lock, you will block.  \n            - You will need to release the mutex before blocking (to allow another thread/transaction to attempt to acquire the lock)\n            - Attempt to re-acquire the mutex before trying to re-acquire the lock.",
        "repo/location": "$ cd go-db-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab3.md",
        "codes": [
            {
                "code_path": "godb/buffer_pool.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/buffer_pool.go",
                "code_content": "package godb\n\n//BufferPool provides methods to cache pages that have been read from disk.\n//It has a fixed capacity to limit the total amount of memory used by GoDB.\n//It is also the primary way in which transactions are enforced, by using page\n//level locking (you will not need to worry about this until lab3).\n\nimport (\n\t\"fmt\"\n)\n\n// Permissions used to when reading / locking pages\ntype RWPerm int\n\nconst (\n\tReadPerm  RWPerm = iota\n\tWritePerm RWPerm = iota\n)\n\ntype BufferPool struct {\n\t// TODO: some code goes here\n}\n\n// Create a new BufferPool with the specified number of pages\nfunc NewBufferPool(numPages int) (*BufferPool, error) {\n\treturn &BufferPool{}, fmt.Errorf(\"NewBufferPool not implemented\")\n}\n\n// Testing method -- iterate through all pages in the buffer pool\n// and flush them using [DBFile.flushPage]. Does not need to be thread/transaction safe.\n// Mark pages as not dirty after flushing them.\nfunc (bp *BufferPool) FlushAllPages() {\n\t// TODO: some code goes here\n}\n\n// Abort the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk so it is sufficient to just\n// release locks to abort. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) AbortTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Commit the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk, so prior to releasing locks you\n// should iterate through pages and write them to disk.  In GoDB lab3 we assume\n// that the system will not crash while doing this, allowing us to avoid using a\n// WAL. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) CommitTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Begin a new transaction. You do not need to implement this for lab 1.\n//\n// Returns an error if the transaction is already running.\nfunc (bp *BufferPool) BeginTransaction(tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// Retrieve the specified page from the specified DBFile (e.g., a HeapFile), on\n// behalf of the specified transaction. If a page is not cached in the buffer pool,\n// you can read it from disk uing [DBFile.readPage]. If the buffer pool is full (i.e.,\n// already stores numPages pages), a page should be evicted.  Should not evict\n// pages that are dirty, as this would violate NO STEAL. If the buffer pool is\n// full of dirty pages, you should return an error. Before returning the page,\n// attempt to lock it with the specified permission.  If the lock is\n// unavailable, should block until the lock is free. If a deadlock occurs, abort\n// one of the transactions in the deadlock. For lab 1, you do not need to\n// implement locking or deadlock detection. You will likely want to store a list\n// of pages in the BufferPool in a map keyed by the [DBFile.pageKey].\nfunc (bp *BufferPool) GetPage(file DBFile, pageNo int, tid TransactionID, perm RWPerm) (Page, error) {\n\treturn nil, fmt.Errorf(\"GetPage not implemented\")\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "locking_test.go",
                "code_path": "godb/locking_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/locking_test.go",
                "code_content": "package godb\n\nimport (\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype LockGrabber struct {\n\tbp   *BufferPool\n\ttid  TransactionID\n\tfile DBFile\n\tpgNo int\n\tperm RWPerm\n\n\tacq          bool\n\terr          error\n\talock, elock sync.Mutex\n}\n\nfunc NewLockGrabber(bp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm) *LockGrabber {\n\treturn &LockGrabber{bp, tid, file, pgNo, perm,\n\t\tfalse, nil, sync.Mutex{}, sync.Mutex{}}\n}\n\nfunc (lg *LockGrabber) run() {\n\t// Try to get the page from the buffer pool.\n\t_, err := lg.bp.GetPage(lg.file, lg.pgNo, lg.tid, lg.perm)\n\tif err == nil {\n\t\tlg.alock.Lock()\n\t\tlg.acq = true\n\t\tlg.alock.Unlock()\n\t} else {\n\t\tlg.elock.Lock()\n\t\tlg.err = err\n\t\tlg.elock.Unlock()\n\n\t\tlg.bp.AbortTransaction(lg.tid)\n\t}\n}\n\nfunc (lg *LockGrabber) acquired() bool {\n\tlg.alock.Lock()\n\tdefer lg.alock.Unlock()\n\treturn lg.acq\n}\n\nfunc (lg *LockGrabber) getError() error {\n\tlg.elock.Lock()\n\tdefer lg.elock.Unlock()\n\treturn lg.err\n}\n\nfunc startGrabber(bp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm) *LockGrabber {\n\tlg := NewLockGrabber(bp, tid, file, pgNo, perm)\n\tgo lg.run()\n\treturn lg\n}\n\nfunc grabLock(t *testing.T,\n\tbp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm,\n\texpected bool) {\n\n\tlg := startGrabber(bp, tid, file, pgNo, perm)\n\n\ttime.Sleep(100 * time.Millisecond)\n\n\tvar acquired bool = lg.acquired()\n\tif expected != acquired {\n\t\tt.Errorf(\"Expected %t, found %t\", expected, acquired)\n\t}\n\n\t// TODO how to kill stalling lg?\n}\n\nfunc metaLockTester(t *testing.T, bp *BufferPool,\n\ttid1 TransactionID, file1 DBFile, pgNo1 int, perm1 RWPerm,\n\ttid2 TransactionID, file2 DBFile, pgNo2 int, perm2 RWPerm,\n\texpected bool) {\n\tbp.GetPage(file1, pgNo1, tid1, perm1)\n\tgrabLock(t, bp, tid2, file2, pgNo2, perm2, expected)\n}\n\nfunc lockingTestSetUp(t *testing.T) (*BufferPool, *HeapFile, TransactionID, TransactionID) {\n\tbp, hf, tid1, tid2, _ := transactionTestSetUp(t)\n\treturn bp, hf, tid1, tid2\n}\n\nfunc TestAcquireReadLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 0, ReadPerm,\n\t\ttrue)\n}\n\nfunc TestAcquireReadWriteLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 0, WritePerm,\n\t\tfalse)\n}\n\nfunc TestAcquireWriteReadLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid2, hf, 0, ReadPerm,\n\t\tfalse)\n}\n\nfunc TestAcquireReadWriteLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireWriteLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireReadLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 1, ReadPerm,\n\t\ttrue)\n}\n\nfunc TestLockUpgrade(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttrue)\n\tmetaLockTester(t, bp,\n\t\ttid2, hf, 1, ReadPerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireWriteAndReadLocks(t *testing.T) {\n\tbp, hf, tid1, _ := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttrue)\n}\n"
            }
        ],
        "test_command": [
            "go test locking_test.go"
        ]
    },
    {
        "instance_id": 14,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 3: GoDB Transactions",
        "part_name": "2.6. Lock Lifetime",
        "exercise": "Exercise 2",
        "introduction": "In this lab, you will implement a simple locking-based transaction system in GoDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.\n\nThe remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.",
        "Description": "### 2.6. Lock Lifetime\n\nYou will need to implement strict two-phase locking. This means that transactions should acquire the appropriate type of lock on any object before accessing that object and shouldn't release any locks until after the transaction is committed.\n\nFortunately, the GoDB design is such that it is possible to obtain locks on pages in  `BufferPool.GetPage()`  before you read or modify them. So, rather than adding calls to locking routines in each of your operators, you should acquire locks in  `GetPage()`.   You will implement releasing of locks when you implement `CommitTransaction()`  and `AbortTransaction()` below.\n\nYou will need to acquire a  _shared_  lock on any page (or tuple) before you read it, and you will need to acquire an  _exclusive_  lock on any page (or tuple) before you write it. You will notice that we are already passing around  `RWPerm`  variables in the BufferPool; these variables indicate the type of lock that the caller would like to have on the object being accessed (we have given you code for the  `RWPerm`  type.)\n\n\n----------\n\nOur testing system relies on the godb implementation returning an error when the transaction is aborted (due to deadlocks etc.). If the transaction is aborted, your implementation is not responsible for restarting the transaction. Simply return an error and the test suite (called/user of the system) will restarte the transaction. Before you start implementing anything for this lab, check that `TestTransactionTid` passes. This test relies on the implementation we have provided you for `NewTID()` which the rest of the system and the tests depend on. If it does not pass, contact the course staff. At this point, `TestTransaction` will not terminate since `insertTuple` returns an error for a buffer pool full with dirty pages, not an aborted transaction (see `readXaction` and `writeXaction` in `transaction_test.go`). This part will execute normally after you implement exercises 1 and 2.\n\nBefore you start working on lab3, you may also find that the following tests already pass. This is normal as they should work for a sequential implementation. After you add transaction related features, these tests should still pass. There is a small portion of credit assigned for them.\n* `TestLockingAcquireReadLocksOnSampePage`\n* `TestLockingAcquireReadWriteLocksOnTwoPages`\n* `TestLockingAcquireWriteLocksOnTwoPages`\n* `TestLockingAcquireReadLocksOnTwoPages`\n* `TestLockingUpgrade`\n* `TestLockingAcquireWriteAndReadLocks`\n* `TestTransactionTwice`\n* `TestTransactionCommit`\n* `TestTransactionSingleThread`\n\n\n**Exercise 2.**\n\nImplement the  `BeginTransaction()`, `CommitTransaction()`  and `AbortTransaction()` methods in  `BufferPool`.  \n\n`BeginTransaction()` may or may not need to do anything depending on your design choices -- you may want to store the transaction id in a list of running transactions.\n\nWhen you commit, you should flush dirty pages associated with the transaction to disk. When you abort, you should revert any changes made by the transaction by restoring the page to its on-disk state (which can be done simply by discarding the page from memory since we never write dirty pages back to disk).\n\nWhether the transaction commits or aborts, you should also release any state the  `BufferPool`  keeps regarding the transaction, including releasing any locks that the transaction held.\n\nAs with previous methods, you will need to use mutexes or other synchronization to ensure correctness when two transactions simultaneously attempt to abort or commit.  In our implementation, we used the `Mutex` associated with our buffer pool to protect the entire body of each of these three methods.\n\nAt this point, your code should pass the tests in `locking_test.go`, `TestTransactionTwice`, and `TestTransaction{Commit, Abort}` unit tests and the  `TestAbortEviction` system test. You may find the `Test{One, Two, Five}Threads` and `TestAllDirtyFails` system tests illustrative, but they will likely fail until you complete the next exercises.",
        "repo/location": "$ cd go-db-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab3.md",
        "codes": [
            {
                "code_path": "godb/buffer_pool.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/buffer_pool.go",
                "code_content": "package godb\n\n//BufferPool provides methods to cache pages that have been read from disk.\n//It has a fixed capacity to limit the total amount of memory used by GoDB.\n//It is also the primary way in which transactions are enforced, by using page\n//level locking (you will not need to worry about this until lab3).\n\nimport (\n\t\"fmt\"\n)\n\n// Permissions used to when reading / locking pages\ntype RWPerm int\n\nconst (\n\tReadPerm  RWPerm = iota\n\tWritePerm RWPerm = iota\n)\n\ntype BufferPool struct {\n\t// TODO: some code goes here\n}\n\n// Create a new BufferPool with the specified number of pages\nfunc NewBufferPool(numPages int) (*BufferPool, error) {\n\treturn &BufferPool{}, fmt.Errorf(\"NewBufferPool not implemented\")\n}\n\n// Testing method -- iterate through all pages in the buffer pool\n// and flush them using [DBFile.flushPage]. Does not need to be thread/transaction safe.\n// Mark pages as not dirty after flushing them.\nfunc (bp *BufferPool) FlushAllPages() {\n\t// TODO: some code goes here\n}\n\n// Abort the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk so it is sufficient to just\n// release locks to abort. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) AbortTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Commit the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk, so prior to releasing locks you\n// should iterate through pages and write them to disk.  In GoDB lab3 we assume\n// that the system will not crash while doing this, allowing us to avoid using a\n// WAL. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) CommitTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Begin a new transaction. You do not need to implement this for lab 1.\n//\n// Returns an error if the transaction is already running.\nfunc (bp *BufferPool) BeginTransaction(tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// Retrieve the specified page from the specified DBFile (e.g., a HeapFile), on\n// behalf of the specified transaction. If a page is not cached in the buffer pool,\n// you can read it from disk uing [DBFile.readPage]. If the buffer pool is full (i.e.,\n// already stores numPages pages), a page should be evicted.  Should not evict\n// pages that are dirty, as this would violate NO STEAL. If the buffer pool is\n// full of dirty pages, you should return an error. Before returning the page,\n// attempt to lock it with the specified permission.  If the lock is\n// unavailable, should block until the lock is free. If a deadlock occurs, abort\n// one of the transactions in the deadlock. For lab 1, you do not need to\n// implement locking or deadlock detection. You will likely want to store a list\n// of pages in the BufferPool in a map keyed by the [DBFile.pageKey].\nfunc (bp *BufferPool) GetPage(file DBFile, pageNo int, tid TransactionID, perm RWPerm) (Page, error) {\n\treturn nil, fmt.Errorf(\"GetPage not implemented\")\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "locking_test.go",
                "code_path": "godb/locking_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/locking_test.go",
                "code_content": "package godb\n\nimport (\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\ntype LockGrabber struct {\n\tbp   *BufferPool\n\ttid  TransactionID\n\tfile DBFile\n\tpgNo int\n\tperm RWPerm\n\n\tacq          bool\n\terr          error\n\talock, elock sync.Mutex\n}\n\nfunc NewLockGrabber(bp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm) *LockGrabber {\n\treturn &LockGrabber{bp, tid, file, pgNo, perm,\n\t\tfalse, nil, sync.Mutex{}, sync.Mutex{}}\n}\n\nfunc (lg *LockGrabber) run() {\n\t// Try to get the page from the buffer pool.\n\t_, err := lg.bp.GetPage(lg.file, lg.pgNo, lg.tid, lg.perm)\n\tif err == nil {\n\t\tlg.alock.Lock()\n\t\tlg.acq = true\n\t\tlg.alock.Unlock()\n\t} else {\n\t\tlg.elock.Lock()\n\t\tlg.err = err\n\t\tlg.elock.Unlock()\n\n\t\tlg.bp.AbortTransaction(lg.tid)\n\t}\n}\n\nfunc (lg *LockGrabber) acquired() bool {\n\tlg.alock.Lock()\n\tdefer lg.alock.Unlock()\n\treturn lg.acq\n}\n\nfunc (lg *LockGrabber) getError() error {\n\tlg.elock.Lock()\n\tdefer lg.elock.Unlock()\n\treturn lg.err\n}\n\nfunc startGrabber(bp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm) *LockGrabber {\n\tlg := NewLockGrabber(bp, tid, file, pgNo, perm)\n\tgo lg.run()\n\treturn lg\n}\n\nfunc grabLock(t *testing.T,\n\tbp *BufferPool, tid TransactionID, file DBFile, pgNo int, perm RWPerm,\n\texpected bool) {\n\n\tlg := startGrabber(bp, tid, file, pgNo, perm)\n\n\ttime.Sleep(100 * time.Millisecond)\n\n\tvar acquired bool = lg.acquired()\n\tif expected != acquired {\n\t\tt.Errorf(\"Expected %t, found %t\", expected, acquired)\n\t}\n\n\t// TODO how to kill stalling lg?\n}\n\nfunc metaLockTester(t *testing.T, bp *BufferPool,\n\ttid1 TransactionID, file1 DBFile, pgNo1 int, perm1 RWPerm,\n\ttid2 TransactionID, file2 DBFile, pgNo2 int, perm2 RWPerm,\n\texpected bool) {\n\tbp.GetPage(file1, pgNo1, tid1, perm1)\n\tgrabLock(t, bp, tid2, file2, pgNo2, perm2, expected)\n}\n\nfunc lockingTestSetUp(t *testing.T) (*BufferPool, *HeapFile, TransactionID, TransactionID) {\n\tbp, hf, tid1, tid2, _ := transactionTestSetUp(t)\n\treturn bp, hf, tid1, tid2\n}\n\nfunc TestAcquireReadLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 0, ReadPerm,\n\t\ttrue)\n}\n\nfunc TestAcquireReadWriteLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 0, WritePerm,\n\t\tfalse)\n}\n\nfunc TestAcquireWriteReadLocksOnSamePage(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid2, hf, 0, ReadPerm,\n\t\tfalse)\n}\n\nfunc TestAcquireReadWriteLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireWriteLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireReadLocksOnTwoPages(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid2, hf, 1, ReadPerm,\n\t\ttrue)\n}\n\nfunc TestLockUpgrade(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttrue)\n\tmetaLockTester(t, bp,\n\t\ttid2, hf, 1, ReadPerm,\n\t\ttid2, hf, 1, WritePerm,\n\t\ttrue)\n}\n\nfunc TestAcquireWriteAndReadLocks(t *testing.T) {\n\tbp, hf, tid1, _ := lockingTestSetUp(t)\n\tmetaLockTester(t, bp,\n\t\ttid1, hf, 0, WritePerm,\n\t\ttid1, hf, 0, ReadPerm,\n\t\ttrue)\n}\n"
            }
        ],
        "test_command": [
            "go test locking_test.go"
        ]
    },
    {
        "instance_id": 15,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 3: GoDB Transactions",
        "part_name": "2.7.  Changes to Methods Outside of Buffer Pool",
        "exercise": "Exercise 3",
        "introduction": "In this lab, you will implement a simple locking-based transaction system in GoDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.\n\nThe remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.",
        "Description": "### 2.7.  Changes to Methods Outside of Buffer Pool\n\nDouble check that your implementation of  `HeapFile.insertTuple()`  and  `HeapFile.deleteTuple()`, as well as the implementation of the iterator returned by  `HeapFile.Iterator()`   access pages using  `BufferPool.GetPage()`. Double check that these different uses of  `GetPage()`  pass the correct permissions object (e.g.,  `WritePerm`  or  `ReadPerm`). You may also wish to double check that your implementation of  `HeapFile.insertTuple()`  and  `HeapFile.deleteTuple()`  call  `setDirty()`  on any of the pages they access (you should have done this when you implemented this code in lab 1.)\n\nYou will also need to ensure that your methods behave properly under concurrency.  Transactional locking will prevent methods like `insertTuple` or `deleteTuple` from being called on the same `HeapPage` object by two different transactions (and hence two different threads), but your `HeapFile` itself may have shared variables that need to be protected with mutexes.   For example, your heap file implementation may use a variable to track the number of pages or the next page to insert into;  you will want to ensure that threads are isolated from each other when one or both of them are updating these variables.   There also may be race conditions that you will need to think through.  For example, in your implementation, you will want to ensure that two threads do not simultaneously try to insert a new tuple that adds a new page to the HeapFile (e.g. because two transactions try to do an insert into a heap file with no empty slots on any pages).  \n\n\n----------\n\n\n**Exercise 3.**\n\nAdd synchronization primitives like mutexes throughout GoDB. For most implementations, the primary code to be concerned about is in HeapFile.  Some (but not necessarily all) actions that you should verify work properly:\n\n-   Reading tuples off of pages during your Iterator.  Note that it is okay for two threads to read the same variable at the same time -- its concurrent modification by both threads or modification by one and reading by another that is problematic.  Also, recall that transactional locking will prevent one transaction from inserting into a page while another is reading from it.\n-   Inserting and deleting tuples through HeapFile methods.  \n-   Adding a new page to a  `HeapFile`. When do you physically write the page to disk? Are there race conditions with other transactions (on other threads) that might need special attention at the HeapFile level, regardless of page-level locking?\n-   Looking for an empty slot into which you can insert tuples. \n\nIn the staff implementation, we also added a `Mutex` `m` to our HeapFile.  We then locked and unlocked `m` in `insertTuple` and `deleteTuple` as we needed. This is because we want to avoid two inserts/deletes modifying shared heapFile variables, for example, variables that keep track of the last page inserted into and the total number of pages. We didn't need to acquire the mutex during our iterator because we know that no other transaction will modify a page while we are scanning it, thanks to the page locks.\n\nThere are no specific test cases for this exercise because the places where synchronization needs to be added are dependent on your implementation.",
        "repo/location": "$ cd go-db-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab3.md",
        "codes": [
            {
                "code_path": "godb/heap_file.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/heap_file.go",
                "code_content": "package godb\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// A HeapFile is an unordered collection of tuples.\n//\n// HeapFile is a public class because external callers may wish to instantiate\n// database tables using the method [LoadFromCSV]\ntype HeapFile struct {\n\t// TODO: some code goes here\n\t// HeapFile should include the fields below;  you may want to add\n\t// additional fields\n\tbufPool *BufferPool\n}\n\n// Create a HeapFile.\n// Parameters\n// - fromFile: backing file for the HeapFile.  May be empty or a previously created heap file.\n// - td: the TupleDesc for the HeapFile.\n// - bp: the BufferPool that is used to store pages read from the HeapFile\n// May return an error if the file cannot be opened or created.\nfunc NewHeapFile(fromFile string, td *TupleDesc, bp *BufferPool) (*HeapFile, error) {\n\t// TODO: some code goes here\n\treturn &HeapFile{}, fmt.Errorf(\"NewHeapFile not implemented\") //replace me\n}\n\n// Return the name of the backing file\nfunc (f *HeapFile) BackingFile() string {\n\t// TODO: some code goes here\n\treturn \"\" //replace me\n}\n\n// Return the number of pages in the heap file\nfunc (f *HeapFile) NumPages() int {\n\t// TODO: some code goes here\n\treturn 0 //replace me\n}\n\n// Load the contents of a heap file from a specified CSV file.  Parameters are as follows:\n// - hasHeader:  whether or not the CSV file has a header\n// - sep: the character to use to separate fields\n// - skipLastField: if true, the final field is skipped (some TPC datasets include a trailing separator on each line)\n// Returns an error if the field cannot be opened or if a line is malformed\n// We provide the implementation of this method, but it won't work until\n// [HeapFile.insertTuple] and some other utility functions are implemented\nfunc (f *HeapFile) LoadFromCSV(file *os.File, hasHeader bool, sep string, skipLastField bool) error {\n\tscanner := bufio.NewScanner(file)\n\tcnt := 0\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tfields := strings.Split(line, sep)\n\t\tif skipLastField {\n\t\t\tfields = fields[0 : len(fields)-1]\n\t\t}\n\t\tnumFields := len(fields)\n\t\tcnt++\n\t\tdesc := f.Descriptor()\n\t\tif desc == nil || desc.Fields == nil {\n\t\t\treturn GoDBError{MalformedDataError, \"Descriptor was nil\"}\n\t\t}\n\t\tif numFields != len(desc.Fields) {\n\t\t\treturn GoDBError{MalformedDataError, fmt.Sprintf(\"LoadFromCSV:  line %d (%s) does not have expected number of fields (expected %d, got %d)\", cnt, line, len(f.Descriptor().Fields), numFields)}\n\t\t}\n\t\tif cnt == 1 && hasHeader {\n\t\t\tcontinue\n\t\t}\n\t\tvar newFields []DBValue\n\t\tfor fno, field := range fields {\n\t\t\tswitch f.Descriptor().Fields[fno].Ftype {\n\t\t\tcase IntType:\n\t\t\t\tfield = strings.TrimSpace(field)\n\t\t\t\tfloatVal, err := strconv.ParseFloat(field, 64)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn GoDBError{TypeMismatchError, fmt.Sprintf(\"LoadFromCSV: couldn't convert value %s to int, tuple %d\", field, cnt)}\n\t\t\t\t}\n\t\t\t\tintValue := int(floatVal)\n\t\t\t\tnewFields = append(newFields, IntField{int64(intValue)})\n\t\t\tcase StringType:\n\t\t\t\tif len(field) > StringLength {\n\t\t\t\t\tfield = field[0:StringLength]\n\t\t\t\t}\n\t\t\t\tnewFields = append(newFields, StringField{field})\n\t\t\t}\n\t\t}\n\t\tnewT := Tuple{*f.Descriptor(), newFields, nil}\n\t\ttid := NewTID()\n\t\tbp := f.bufPool\n\t\tf.insertTuple(&newT, tid)\n\n\t\t// Force dirty pages to disk. CommitTransaction may not be implemented\n\t\t// yet if this is called in lab 1 or 2.\n\t\tbp.FlushAllPages()\n\n\t}\n\treturn nil\n}\n\n// Read the specified page number from the HeapFile on disk. This method is\n// called by the [BufferPool.GetPage] method when it cannot find the page in its\n// cache.\n//\n// This method will need to open the file supplied to the constructor, seek to\n// the appropriate offset, read the bytes in, and construct a [heapPage] object,\n// using the [heapPage.initFromBuffer] method.\nfunc (f *HeapFile) readPage(pageNo int) (Page, error) {\n\t// TODO: some code goes here\n\treturn nil, fmt.Errorf(\"readPage not implemented\")\n}\n\n// Add the tuple to the HeapFile. This method should search through pages in the\n// heap file, looking for empty slots and adding the tuple in the first empty\n// slot if finds.\n//\n// If none are found, it should create a new [heapPage] and insert the tuple\n// there, and write the heapPage to the end of the HeapFile (e.g., using the\n// [flushPage] method.)\n//\n// To iterate through pages, it should use the [BufferPool.GetPage method]\n// rather than directly reading pages itself. For lab 1, you do not need to\n// worry about concurrent transactions modifying the Page or HeapFile. We will\n// add support for concurrent modifications in lab 3.\n//\n// The page the tuple is inserted into should be marked as dirty.\nfunc (f *HeapFile) insertTuple(t *Tuple, tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"insertTuple not implemented\") //replace me\n}\n\n// Remove the provided tuple from the HeapFile.\n//\n// This method should use the [Tuple.Rid] field of t to determine which tuple to\n// remove. The Rid field should be set when the tuple is read using the\n// [Iterator] method, or is otherwise created (as in tests). Note that Rid is an\n// empty interface, so you can supply any object you wish. You will likely want\n// to identify the heap page and slot within the page that the tuple came from.\n//\n// The page the tuple is deleted from should be marked as dirty.\nfunc (f *HeapFile) deleteTuple(t *Tuple, tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"deleteTuple not implemented\") //replace me\n}\n\n// Method to force the specified page back to the backing file at the\n// appropriate location. This will be called by BufferPool when it wants to\n// evict a page. The Page object should store information about its offset on\n// disk (e.g., that it is the ith page in the heap file), so you can determine\n// where to write it back.\nfunc (f *HeapFile) flushPage(p Page) error {\n\t// TODO: some code goes here\n\treturn fmt.Errorf(\"flushPage not implemented\") //replace me\n}\n\n// [Operator] descriptor method -- return the TupleDesc for this HeapFile\n// Supplied as argument to NewHeapFile.\nfunc (f *HeapFile) Descriptor() *TupleDesc {\n\t// TODO: some code goes here\n\treturn nil //replace me\n\n}\n\n// [Operator] iterator method\n// Return a function that iterates through the records in the heap file\n// Note that this method should read pages from the HeapFile using the\n// BufferPool method GetPage, rather than reading pages directly,\n// since the BufferPool caches pages and manages page-level locking state for\n// transactions\n// You should esnure that Tuples returned by this method have their Rid object\n// set appropriate so that [deleteTuple] will work (see additional comments there).\n// Make sure to set the returned tuple's TupleDescriptor to the TupleDescriptor of\n// the HeapFile. This allows it to correctly capture the table qualifier.\nfunc (f *HeapFile) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\t// TODO: some code goes here\n\treturn func() (*Tuple, error) {\n\treturn nil, fmt.Errorf(\"heap_file.Iterator not implemented\")\n\t}, nil\n}\n\n// internal strucuture to use as key for a heap page\ntype heapHash struct {\n\tFileName string\n\tPageNo   int\n}\n\n// This method returns a key for a page to use in a map object, used by\n// BufferPool to determine if a page is cached or not.  We recommend using a\n// heapHash struct as the key for a page, although you can use any struct that\n// does not contain a slice or a map that uniquely identifies the page.\nfunc (f *HeapFile) pageKey(pgNo int) any {\n\t// TODO: some code goes here\n\treturn nil\n}\n"
            }
        ],
        "test_codes": [],
        "test_command": []
    },
    {
        "instance_id": 16,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 3: GoDB Transactions",
        "part_name": "2.8. Implementing NO STEAL",
        "exercise": "Exercise 4",
        "introduction": "In this lab, you will implement a simple locking-based transaction system in GoDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.\n\nThe remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.",
        "Description": "### 2.8. Implementing NO STEAL\n\nModifications from a transaction are written to disk only after it commits. This means we can abort a transaction by discarding the dirty pages and rereading them from the disk. Thus, we must not evict dirty pages. This policy is called NO STEAL.\n\n----------\n\n**Exercise 4.**\n\nDouble-check that you don't evict dirty pages from the buffer pool.  We will test this later in `TestAllDirtyFails` but you probably cannot pass this test case yet.",
        "repo/location": "$ cd go-db-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab3.md",
        "codes": [],
        "test_codes": [
            {
                "code_name": "transaction_test.go",
                "code_path": "godb/transaction_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/transaction_test.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"os\"\n\t\"sync\"\n\t\"testing\"\n\t\"time\"\n)\n\n// This test does not have credit and serves merely as a sanity check since\n// NewTID() should have been implemented for you.\nfunc TestTransactionTid(t *testing.T) {\n\ttid := NewTID()\n\ttid2 := NewTID()\n\tvar tid3 = tid\n\tif tid == tid2 {\n\t\tt.Errorf(\"different transactions have same id\")\n\t}\n\tif tid != tid3 {\n\t\tt.Errorf(\"same transactions have different id\")\n\t}\n}\n\nconst numConcurrentThreads int = 20\n\nvar c chan int = make(chan int, numConcurrentThreads*2)\n\nfunc readXaction(hf DBFile, bp *BufferPool, wg *sync.WaitGroup) {\n\tfor {\n\tstart:\n\t\ttid := NewTID()\n\t\tbp.BeginTransaction(tid)\n\t\tpgCnt1 := hf.NumPages()\n\t\tit, _ := hf.Iterator(tid)\n\t\tcnt1 := 0\n\n\t\tfor {\n\t\t\tt, err := it()\n\t\t\tif err != nil {\n\t\t\t\t// Assume this is because of a deadlock, restart txn\n\t\t\t\ttime.Sleep(time.Duration(rand.Intn(8)) * 100 * time.Microsecond)\n\t\t\t\tgoto start\n\t\t\t}\n\t\t\tif t == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcnt1++\n\t\t}\n\n\t\tit, _ = hf.Iterator(tid)\n\t\tcnt2 := 0\n\t\tfor {\n\t\t\tt, err := it()\n\t\t\tif err != nil {\n\t\t\t\t// Assume this is because of a deadlock, restart txn\n\t\t\t\ttime.Sleep(time.Duration(rand.Intn(8)) * 100 * time.Microsecond)\n\t\t\t\tgoto start\n\t\t\t}\n\t\t\tif t == nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tcnt2++\n\t\t}\n\t\tif cnt1 == cnt2 || pgCnt1 != hf.NumPages() {\n\t\t\t//fmt.Printf(\"read same number of tuples both iterators (%d)\\n\", cnt1)\n\t\t\tc <- 1\n\t\t} else {\n\t\t\tfmt.Printf(\"ERROR: read different number of tuples both iterators (%d, %d)\\n\", cnt1, cnt2)\n\t\t\tc <- 0\n\t\t}\n\t\tbp.CommitTransaction(tid)\n\t\twg.Done()\n\t\treturn\n\t}\n}\n\nfunc writeXaction(hf DBFile, bp *BufferPool, writeTuple Tuple, wg *sync.WaitGroup) {\n\tfor {\n\tstart:\n\t\ttid := NewTID()\n\t\tbp.BeginTransaction(tid)\n\t\tfor i := 0; i < 10; i++ {\n\t\t\terr := hf.insertTuple(&writeTuple, tid)\n\t\t\tif err != nil {\n\t\t\t\t// Assume this is because of a deadlock, restart txn\n\t\t\t\ttime.Sleep(time.Duration(rand.Intn(8)) * 100 * time.Microsecond)\n\t\t\t\tgoto start\n\t\t\t}\n\t\t}\n\t\tbp.CommitTransaction(tid)\n\t\tbreak\n\t}\n\tc <- 1\n\twg.Done()\n}\n\nfunc TestTransactions(t *testing.T) {\n\t_, t1, t2, _, _, _ := makeTestVars(t)\n\tbp, catalog, err := MakeTestDatabase(20, \"catalog.txt\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\thf, err := catalog.GetTable(\"t\")\n\tif err != nil {\n\t\tt.Fatalf(err.Error())\n\t}\n\tvar wg sync.WaitGroup\n\n\tfor i := 0; i < 1000; i++ {\n\t\terr := hf.insertTuple(&t1, tid)\n\t\tif err != nil {\n\t\t\tfmt.Print(err.Error())\n\t\t\tt.Errorf(\"transaction test failed\")\n\t\t}\n\t\terr = hf.insertTuple(&t2, tid)\n\t\tif err != nil {\n\t\t\tfmt.Print(err.Error())\n\t\t\tt.Errorf(\"transaction test failed\")\n\t\t}\n\t}\n\tbp.CommitTransaction(tid)\n\n\twg.Add(numConcurrentThreads * 2)\n\n\tfor i := 0; i < numConcurrentThreads; i++ {\n\t\tgo readXaction(hf, bp, &wg)\n\t\t//time.Sleep(2 * time.Millisecond)\n\t\tgo writeXaction(hf, bp, t1, &wg)\n\t\ttime.Sleep(10 * time.Millisecond)\n\t}\n\n\twg.Wait()\n\n\tfor i := 0; i < numConcurrentThreads*2; i++ {\n\t\tval := <-c\n\t\tif val == 0 {\n\t\t\tt.Errorf(\"transaction test failed\")\n\t\t}\n\t}\n\n\twg.Add(1)\n\tgo readXaction(hf, bp, &wg)\n\twg.Wait()\n}\n\nfunc transactionTestSetUpVarLen(t *testing.T, tupCnt int, pgCnt int) (*BufferPool, *HeapFile, TransactionID, TransactionID, Tuple, Tuple) {\n\t_, t1, t2, hf, bp, _ := makeTestVars(t)\n\n\tcsvFile, err := os.Open(fmt.Sprintf(\"txn_test_%d_%d.csv\", tupCnt, pgCnt))\n\tif err != nil {\n\t\tt.Fatalf(\"error opening test file\")\n\t}\n\thf.LoadFromCSV(csvFile, false, \",\", false)\n\tif hf.NumPages() != pgCnt {\n\t\tt.Fatalf(\"error making test vars; unexpected number of pages\")\n\t}\n\n\ttid1 := NewTID()\n\tbp.BeginTransaction(tid1)\n\ttid2 := NewTID()\n\tbp.BeginTransaction(tid2)\n\treturn bp, hf, tid1, tid2, t1, t2\n}\n\nfunc transactionTestSetUp(t *testing.T) (*BufferPool, *HeapFile, TransactionID, TransactionID, Tuple) {\n\tbp, hf, tid1, tid2, t1, _ := transactionTestSetUpVarLen(t, 300, 3)\n\treturn bp, hf, tid1, tid2, t1\n}\n\nfunc TestTransactionTwice(t *testing.T) {\n\tbp, hf, tid1, tid2, _ := transactionTestSetUp(t)\n\tbp.GetPage(hf, 0, tid1, ReadPerm)\n\tbp.GetPage(hf, 1, tid1, WritePerm)\n\tbp.CommitTransaction(tid1)\n\n\tbp.GetPage(hf, 0, tid2, WritePerm)\n\tbp.GetPage(hf, 1, tid2, WritePerm)\n}\n\nfunc testTransactionComplete(t *testing.T, commit bool) {\n\tbp, hf, tid1, tid2, t1 := transactionTestSetUp(t)\n\n\tpg, _ := bp.GetPage(hf, 2, tid1, WritePerm)\n\theapp := pg.(*heapPage)\n\theapp.insertTuple(&t1)\n\theapp.setDirty(tid1, true)\n\n\tif commit {\n\t\tbp.CommitTransaction(tid1)\n\t} else {\n\t\tbp.AbortTransaction(tid1)\n\t}\n\n\tbp.FlushAllPages()\n\n\tpg, _ = bp.GetPage(hf, 2, tid2, WritePerm)\n\theapp = pg.(*heapPage)\n\titer := heapp.tupleIter()\n\n\tfound := false\n\tfor tup, err := iter(); tup != nil || err != nil; tup, err = iter() {\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Iterator error\")\n\t\t}\n\t\tif t1.equals(tup) {\n\t\t\tfound = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif found != commit {\n\t\tt.Errorf(\"Expected %t, found %t\", commit, found)\n\t}\n}\n\nfunc TestTransactionCommit(t *testing.T) {\n\ttestTransactionComplete(t, true)\n}\n\nfunc TestTransactionAbort(t *testing.T) {\n\ttestTransactionComplete(t, false)\n}\n\n// placeholder op for a singleton tuple\ntype Singleton struct {\n\ttup Tuple\n\tran bool\n}\n\nfunc (i *Singleton) Descriptor() *TupleDesc {\n\treturn &i.tup.Desc\n}\n\nfunc (i *Singleton) Iterator(tid TransactionID) (func() (*Tuple, error), error) {\n\treturn func() (*Tuple, error) {\n\t\tif i.ran {\n\t\t\treturn nil, nil\n\t\t}\n\t\ti.ran = true\n\t\treturn &i.tup, nil\n\t}, nil\n}\n\n// Run threads transactions, each each of which reads a single tuple from a\n// page, deletes the tuple, and re-inserts it with an incremented value. There\n// will be deadlocks, so your deadlock handling will have to be correct to allow\n// all transactions to be committed and the value to be incremented threads\n// times.\nfunc validateTransactions(t *testing.T, threads int) {\n\tbp, hf, _, _, _, t2 := transactionTestSetUpVarLen(t, 1, 1)\n\n\tvar startWg, readyWg sync.WaitGroup\n\tstartChan := make(chan struct{})\n\n\t// sleep for an increasingly long time after deadlocks. this backoff helps avoid starvation\n\tnDeadlocks := 0\n\tvar nDeadlocksMutex sync.Mutex\n\tsleepAfterDeadlock := func(thrId int, err error) {\n\t\tnDeadlocksMutex.Lock()\n\t\tnDeadlocks++\n\t\tt.Logf(\"thread %d operation failed: %v deadlock #%v\", thrId, err, nDeadlocks)\n\t\tsleepTime := time.Duration(rand.Intn(int(nDeadlocks) + 1))\n\t\tnDeadlocksMutex.Unlock()\n\t\ttime.Sleep(sleepTime * time.Millisecond)\n\t}\n\n\tincrementer := func(thrId int) {\n\t\t// Signal that this goroutine is ready\n\t\treadyWg.Done()\n\n\t\t// Wait for the signal to start\n\t\t<-startChan\n\n\t\tfor tid := TransactionID(0); ; bp.AbortTransaction(tid) {\n\t\t\ttid = NewTID()\n\t\t\tbp.BeginTransaction(tid)\n\t\t\titer1, err := hf.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\treadTup, err := iter1()\n\t\t\tif err != nil {\n\t\t\t\tsleepAfterDeadlock(thrId, err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tvar writeTup = Tuple{\n\t\t\t\tDesc: readTup.Desc,\n\t\t\t\tFields: []DBValue{\n\t\t\t\t\treadTup.Fields[0],\n\t\t\t\t\tIntField{readTup.Fields[1].(IntField).Value + 1},\n\t\t\t\t}}\n\n\t\t\tdop := NewDeleteOp(hf, hf)\n\t\t\titerDel, err := dop.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tdelCnt, err := iterDel()\n\t\t\tif err != nil {\n\t\t\t\tsleepAfterDeadlock(thrId, err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif delCnt.Fields[0].(IntField).Value != 1 {\n\t\t\t\tt.Errorf(\"Delete Op should return 1\")\n\t\t\t}\n\t\t\tiop := NewInsertOp(hf, &Singleton{writeTup, false})\n\t\t\titerIns, err := iop.Iterator(tid)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tinsCnt, err := iterIns()\n\t\t\tif err != nil {\n\t\t\t\tsleepAfterDeadlock(thrId, err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif insCnt.Fields[0].(IntField).Value != 1 {\n\t\t\t\tt.Errorf(\"Insert Op should return 1\")\n\t\t\t}\n\n\t\t\tbp.CommitTransaction(tid)\n\t\t\tbreak //exit on success, so we don't do terminal abort\n\t\t}\n\t\tstartWg.Done()\n\t}\n\n\t// Prepare goroutines\n\treadyWg.Add(threads)\n\tstartWg.Add(threads)\n\tfor i := 0; i < threads; i++ {\n\t\tgo incrementer(i)\n\t}\n\n\t// Wait for all goroutines to be ready\n\treadyWg.Wait()\n\n\t// Start all goroutines at once\n\tclose(startChan)\n\n\t// Wait for all goroutines to finish\n\tstartWg.Wait()\n\n\ttid := NewTID()\n\tbp.BeginTransaction(tid)\n\titer, _ := hf.Iterator(tid)\n\ttup, _ := iter()\n\n\tdiff := tup.Fields[1].(IntField).Value - t2.Fields[1].(IntField).Value\n\tif diff != int64(threads) {\n\t\tt.Errorf(\"Expected #increments = %d, found %d\", threads, diff)\n\t}\n}\n\nfunc TestTransactionSingleThread(t *testing.T) {\n\tvalidateTransactions(t, 1)\n}\n\nfunc TestTransactionTwoThreads(t *testing.T) {\n\tvalidateTransactions(t, 2)\n}\n\nfunc TestTransactionFiveThreads(t *testing.T) {\n\tvalidateTransactions(t, 5)\n}\n\nfunc TestTransactionAllDirtyFails(t *testing.T) {\n\tif os.Getenv(\"LAB\") == \"5\" {\n\t\tt.Skip(\"Test is valid up through Lab 4. Skipping.\")\n\t}\n\ttd, t1, _, hf, bp, tid := makeTestVars(t)\n\n\tfor hf.NumPages() < 3 {\n\t\thf.insertTuple(&t1, tid)\n\t\tif hf.NumPages() == 0 {\n\t\t\tt.Fatalf(\"Heap file should have at least one page after insertion.\")\n\t\t}\n\t}\n\tbp.CommitTransaction(tid) // make three clean pages\n\n\tos.Remove(TestingFile2)\n\thf2, _ := NewHeapFile(TestingFile2, &td, bp)\n\ttid2 := NewTID()\n\tbp.BeginTransaction(tid2)\n\n\tfor hf2.NumPages() < 3 { // make three dirty pages\n\t\thf2.insertTuple(&t1, tid2)\n\t\tif hf2.NumPages() == 0 {\n\t\t\tt.Fatalf(\"Heap file should have at least one page after insertion.\")\n\t\t}\n\t}\n\n\t_, err := bp.GetPage(hf, 0, tid2, ReadPerm) // since bp capacity = 3, should return error due to all dirty pages\n\tif err == nil {\n\t\tt.Errorf(\"Expected error due to all dirty pages\")\n\t}\n}\n\nfunc TestTransactionAbortEviction(t *testing.T) {\n\ttupExists := func(t0 Tuple, tid TransactionID, hf *HeapFile) (bool, error) {\n\t\titer, err := hf.Iterator(tid)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tfor tup, err := iter(); tup != nil; tup, err = iter() {\n\t\t\tif err != nil {\n\t\t\t\treturn false, err\n\t\t\t}\n\t\t\tif t0.equals(tup) {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t}\n\t\treturn false, nil\n\t}\n\n\t_, t1, _, hf, bp, tid := makeTestVars(t)\n\thf.insertTuple(&t1, tid)\n\tif exists, err := tupExists(t1, tid, hf); !(exists == true && err == nil) {\n\t\tt.Errorf(\"Tuple should exist\")\n\t}\n\tbp.AbortTransaction(tid)\n\n\ttid2 := NewTID()\n\tbp.BeginTransaction(tid2)\n\n\t// tuple should not exist after abort\n\tif exists, err := tupExists(t1, tid2, hf); !(exists == false && err == nil) {\n\t\tt.Errorf(\"Tuple should not exist\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test transaction_test.go"
        ]
    },
    {
        "instance_id": 17,
        "course": "6.5830/6.5831: Database Systems",
        "year": "Fall 2024",
        "index": "Lab 3: GoDB Transactions",
        "part_name": "2.9. Deadlocks and Aborts",
        "exercise": "Exercise 5",
        "introduction": "In this lab, you will implement a simple locking-based transaction system in GoDB. You will need to add lock and unlock calls at the appropriate places in your code, as well as code to track the locks held by each transaction and grant locks to transactions as they are needed.\n\nThe remainder of this document describes what is involved in adding transaction support and provides a basic outline of how you might add this support to your database.",
        "Description": "### 2.9. Deadlocks and Aborts\n\nIt is possible for transactions in GoDB to deadlock -- if you do not understand why, we recommend reading about deadlocks in the reading on Concurrency Control and Recovery (i.e., the reading for Lecture 10 and 11). You will need to detect this situation and return an error.\n\nThere are many possible ways to detect a deadlock. A simple method would be to implement a timeout policy that aborts a transaction if it has not been completed after a given period of time. For a better solution, you may implement cycle-detection in a dependency graph data structure as shown in lecture. In this scheme, you would check for cycles in a dependency graph periodically or whenever you attempt to grant a new lock, and abort something if a cycle exists. After you have detected that a deadlock exists, you must decide how to improve the situation. Assume you have detected a deadlock while transaction  _t_  is waiting for a lock. In theory, you could abort  **all**  transactions that  _t_  is waiting for; this may result in a large amount of work being undone, but you can guarantee that  _t_  will make progress. Alternately, you may decide to abort  _t_  to give other transactions a chance to make progress. This means that the end-user will have to retry transaction  _t_.\n\nAnother approach is to use global orderings of transactions to avoid building the wait-for graph. This is sometimes preferred for performance reasons, but transactions that could have succeeded can be aborted by mistake under this scheme. Examples include the WAIT-DIE and WOUND-WAIT schemes.\n\n----------\n\n**Exercise 5.**\n\nImplement deadlock detection or prevention in  `BufferPool.GetPage()`. You have many design decisions for your deadlock handling system, but it is not necessary to do something highly sophisticated. We expect you to do better than a simple timeout on each transaction. A good starting point will be to implement cycle-detection in a wait-for graph before every lock request, and you will receive full credit for such an implementation. Please describe your choices in the lab writeup and list the pros and cons of your choice compared to the alternatives.\n\nYou should ensure that your code aborts transactions properly when a deadlock occurs, which means calling `AbortTransaction()` and returning an error. You are not expected to automatically restart a transaction which fails due to a deadlock -- you can assume that higher-level code will take care of this. \n\nYou will need to be careful about acquiring and releasing mutexes here -- if `AbortTransaction` also acquires the buffer pool mutex, your `GetPage` will need to release the mutex before calling `AbortTransaction.`\n\nWe have provided some (not-so-unit) tests in  `deadlock_test.go`. They are a bit involved, so they may take more than a few seconds to run (depending on your policy). If they seem to hang indefinitely, then you probably have an unresolved deadlock. These tests construct simple deadlock situations that your code should be able to escape.\n\nNote that there are two timing parameters near the top of  `deadlock_test.go`; these determine the frequency at which the test checks if locks have been acquired and the waiting time before an aborted transaction is restarted. You may observe different performance characteristics by tweaking these parameters if you use a timeout-based detection method.\n\nYour code should now should pass the `Test{One, Two, Five}Threads` and `TestAllDirtyFails` tests (which may also run for quite a long time depending on your implementation).\n\nAt this point, you should have a recoverable database, in the sense that if the database system crashes (at a point other than  `CommitTransaction()` or `AbortTransaction()`) or if the user explicitly aborts a transaction, the effects of any running transaction will not be visible after the system restarts (or the transaction aborts.) You may wish to verify this by running some transactions and explicitly killing the database server.",
        "repo/location": "$ cd go-db-2024\n$ git pull upstream main",
        "dependency": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
        ],
        "link": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/lab3.md",
        "codes": [
            {
                "code_path": "godb/buffer_pool.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/buffer_pool.go",
                "code_content": "package godb\n\n//BufferPool provides methods to cache pages that have been read from disk.\n//It has a fixed capacity to limit the total amount of memory used by GoDB.\n//It is also the primary way in which transactions are enforced, by using page\n//level locking (you will not need to worry about this until lab3).\n\nimport (\n\t\"fmt\"\n)\n\n// Permissions used to when reading / locking pages\ntype RWPerm int\n\nconst (\n\tReadPerm  RWPerm = iota\n\tWritePerm RWPerm = iota\n)\n\ntype BufferPool struct {\n\t// TODO: some code goes here\n}\n\n// Create a new BufferPool with the specified number of pages\nfunc NewBufferPool(numPages int) (*BufferPool, error) {\n\treturn &BufferPool{}, fmt.Errorf(\"NewBufferPool not implemented\")\n}\n\n// Testing method -- iterate through all pages in the buffer pool\n// and flush them using [DBFile.flushPage]. Does not need to be thread/transaction safe.\n// Mark pages as not dirty after flushing them.\nfunc (bp *BufferPool) FlushAllPages() {\n\t// TODO: some code goes here\n}\n\n// Abort the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk so it is sufficient to just\n// release locks to abort. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) AbortTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Commit the transaction, releasing locks. Because GoDB is FORCE/NO STEAL, none\n// of the pages tid has dirtied will be on disk, so prior to releasing locks you\n// should iterate through pages and write them to disk.  In GoDB lab3 we assume\n// that the system will not crash while doing this, allowing us to avoid using a\n// WAL. You do not need to implement this for lab 1.\nfunc (bp *BufferPool) CommitTransaction(tid TransactionID) {\n\t// TODO: some code goes here\n}\n\n// Begin a new transaction. You do not need to implement this for lab 1.\n//\n// Returns an error if the transaction is already running.\nfunc (bp *BufferPool) BeginTransaction(tid TransactionID) error {\n\t// TODO: some code goes here\n\treturn nil\n}\n\n// Retrieve the specified page from the specified DBFile (e.g., a HeapFile), on\n// behalf of the specified transaction. If a page is not cached in the buffer pool,\n// you can read it from disk uing [DBFile.readPage]. If the buffer pool is full (i.e.,\n// already stores numPages pages), a page should be evicted.  Should not evict\n// pages that are dirty, as this would violate NO STEAL. If the buffer pool is\n// full of dirty pages, you should return an error. Before returning the page,\n// attempt to lock it with the specified permission.  If the lock is\n// unavailable, should block until the lock is free. If a deadlock occurs, abort\n// one of the transactions in the deadlock. For lab 1, you do not need to\n// implement locking or deadlock detection. You will likely want to store a list\n// of pages in the BufferPool in a map keyed by the [DBFile.pageKey].\nfunc (bp *BufferPool) GetPage(file DBFile, pageNo int, tid TransactionID, perm RWPerm) (Page, error) {\n\treturn nil, fmt.Errorf(\"GetPage not implemented\")\n}\n"
            }
        ],
        "test_codes": [
            {
                "code_name": "deadlock_test.go",
                "code_path": "godb/deadlock_test.go",
                "code_url": "https://github.com/MIT-DB-Class/go-db-2024/blob/main/godb/deadlock_test.go",
                "code_content": "package godb\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"testing\"\n\t\"time\"\n)\n\nconst POLL_INTERVAL = 100 * time.Millisecond\nconst WAIT_INTERVAL = 200 * time.Millisecond\n\n/**\n* Not-so-unit test to construct a deadlock situation.\n* t1 acquires p0.read; t2 acquires p1.read; t1 attempts p1.write; t2\n* attempts p0.write. Rinse and repeat.\n */\nfunc TestDeadlockReadWrite(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\n\tlg1Read := startGrabber(bp, tid1, hf, 0, ReadPerm)\n\tlg2Read := startGrabber(bp, tid2, hf, 1, ReadPerm)\n\n\ttime.Sleep(POLL_INTERVAL)\n\n\tlg1Write := startGrabber(bp, tid1, hf, 1, WritePerm)\n\tlg2Write := startGrabber(bp, tid2, hf, 0, WritePerm)\n\n\tfor {\n\t\ttime.Sleep(POLL_INTERVAL)\n\n\t\tif lg1Write.acquired() && lg2Write.acquired() {\n\t\t\tt.Errorf(\"Should not both get write lock\")\n\t\t}\n\t\tif lg1Write.acquired() != lg2Write.acquired() {\n\t\t\tbreak\n\t\t}\n\n\t\tif lg1Write.getError() != nil {\n\t\t\tbp.AbortTransaction(tid1) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid1 = NewTID()\n\t\t\tlg1Read = startGrabber(bp, tid1, hf, 0, ReadPerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg1Write = startGrabber(bp, tid1, hf, 1, WritePerm)\n\t\t}\n\n\t\tif lg2Write.getError() != nil {\n\t\t\tbp.AbortTransaction(tid2) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid2 = NewTID()\n\t\t\tlg2Read = startGrabber(bp, tid2, hf, 1, ReadPerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg2Write = startGrabber(bp, tid2, hf, 0, WritePerm)\n\t\t}\n\t}\n\n\tif lg1Read == nil || lg2Read == nil {\n\t\tfmt.Println(\"should not be nil\")\n\t}\n}\n\n/**\n * Not-so-unit test to construct a deadlock situation.\n * t1 acquires p0.write; t2 acquires p1.write; t1 attempts p1.write; t2\n * attempts p0.write.\n */\nfunc TestDeadlockWriteWrite(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\n\tlg1WriteA := startGrabber(bp, tid1, hf, 0, WritePerm)\n\tlg2WriteA := startGrabber(bp, tid2, hf, 1, WritePerm)\n\n\ttime.Sleep(POLL_INTERVAL)\n\n\tlg1WriteB := startGrabber(bp, tid1, hf, 1, WritePerm)\n\tlg2WriteB := startGrabber(bp, tid2, hf, 0, WritePerm)\n\n\tfor {\n\t\ttime.Sleep(POLL_INTERVAL)\n\n\t\tif lg1WriteB.acquired() && lg2WriteB.acquired() {\n\t\t\tt.Errorf(\"Should not both get write lock\")\n\t\t}\n\t\tif lg1WriteB.acquired() != lg2WriteB.acquired() {\n\t\t\tbreak\n\t\t}\n\n\t\tif lg1WriteB.getError() != nil {\n\t\t\tbp.AbortTransaction(tid1) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid1 = NewTID()\n\t\t\tlg1WriteA = startGrabber(bp, tid1, hf, 0, WritePerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg1WriteB = startGrabber(bp, tid1, hf, 1, WritePerm)\n\t\t}\n\n\t\tif lg2WriteB.getError() != nil {\n\t\t\tbp.AbortTransaction(tid2) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid2 = NewTID()\n\t\t\tlg2WriteA = startGrabber(bp, tid2, hf, 1, WritePerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg2WriteB = startGrabber(bp, tid2, hf, 0, WritePerm)\n\t\t}\n\t}\n\n\tif lg1WriteA == nil || lg2WriteA == nil {\n\t\tfmt.Println(\"should not be nil\")\n\t}\n}\n\n/**\n * Not-so-unit test to construct a deadlock situation.\n * t1 acquires p0.read; t2 acquires p0.read; t1 attempts to upgrade to\n * p0.write; t2 attempts to upgrade to p0.write\n */\nfunc TestDeadlockUpgradeWrite(t *testing.T) {\n\tbp, hf, tid1, tid2 := lockingTestSetUp(t)\n\n\tlg1Read := startGrabber(bp, tid1, hf, 0, ReadPerm)\n\tlg2Read := startGrabber(bp, tid2, hf, 0, ReadPerm)\n\n\ttime.Sleep(POLL_INTERVAL)\n\n\tlg1Write := startGrabber(bp, tid1, hf, 0, WritePerm)\n\tlg2Write := startGrabber(bp, tid2, hf, 0, WritePerm)\n\n\tfor {\n\t\ttime.Sleep(POLL_INTERVAL)\n\n\t\tif lg1Write.acquired() && lg2Write.acquired() {\n\t\t\tt.Errorf(\"Should not both get write lock\")\n\t\t}\n\t\tif lg1Write.acquired() != lg2Write.acquired() {\n\t\t\tbreak\n\t\t}\n\n\t\tif lg1Write.getError() != nil {\n\t\t\tbp.AbortTransaction(tid1) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid1 = NewTID()\n\t\t\tlg1Read = startGrabber(bp, tid1, hf, 0, ReadPerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg1Write = startGrabber(bp, tid1, hf, 0, WritePerm)\n\t\t}\n\n\t\tif lg2Write.getError() != nil {\n\t\t\tbp.AbortTransaction(tid2) // at most abort twice; should be able to abort twice\n\t\t\ttime.Sleep(time.Duration((float64(WAIT_INTERVAL) * rand.Float64())))\n\n\t\t\ttid2 = NewTID()\n\t\t\tlg2Read = startGrabber(bp, tid2, hf, 0, ReadPerm)\n\t\t\ttime.Sleep(POLL_INTERVAL)\n\t\t\tlg2Write = startGrabber(bp, tid2, hf, 0, WritePerm)\n\t\t}\n\t}\n\n\tif lg1Read == nil || lg2Read == nil {\n\t\tfmt.Println(\"should not be nil\")\n\t}\n}\n"
            }
        ],
        "test_command": [
            "go test deadlock_test.go"
        ]
    }
]